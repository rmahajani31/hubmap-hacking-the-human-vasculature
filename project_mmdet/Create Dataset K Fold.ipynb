{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "456a3a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import shutil\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d99b5bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "generate_all_datset_annots = True\n",
    "generate_pseudo_labels = True\n",
    "keep_all_in_train = False\n",
    "tile_categories = ['blood_vessel']\n",
    "base_data_dir = 'dataset1_files' if not generate_all_datset_annots else 'all_dataset_files'\n",
    "base_data_name = 'all_dataset1' if not generate_all_datset_annots else 'all_dataset'\n",
    "pseudo_label_name = '' if not generate_pseudo_labels else '_pseudo_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc99008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 2\n",
    "input_imgs_path = f'{base_path}/train'\n",
    "\n",
    "for i in range(num_folds):\n",
    "    output_dir = f'{base_path}/{base_data_dir}/{base_data_name}{pseudo_label_name}_mmdet_fold_{i}'\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.mkdir(output_dir)\n",
    "    os.mkdir(f'{output_dir}/train_images')\n",
    "    os.mkdir(f'{output_dir}/validation_images')\n",
    "    os.mkdir(f'{output_dir}/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ee1232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coords):\n",
    "    p = Polygon(coords)\n",
    "    return p.area\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e65eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_annots(tile_categories):\n",
    "    categories = []\n",
    "    for idx, tc in enumerate(tile_categories):\n",
    "        categories.append({'id': idx, 'name': tc})\n",
    "    return categories\n",
    "def create_image_annots(input_imgs_names):\n",
    "    image_annots = []\n",
    "    img_name_to_id = dict()\n",
    "    input_img_names = sorted(input_imgs_names)\n",
    "    for idx, img_name in enumerate(input_img_names):\n",
    "        img = cv2.imread(f'{input_imgs_path}/{img_name}.tif')\n",
    "        height, width = img.shape[:2]\n",
    "        image_annots.append({'file_name': f'{img_name}.tif', 'height': height, 'width': width, 'id': idx})\n",
    "        img_name_to_id[img_name] = idx\n",
    "    return image_annots, img_name_to_id\n",
    "def create_seg_annots(tgt_tile_dicts, img_name_to_id):\n",
    "    annotations = []\n",
    "    annot_id = 0\n",
    "    for tile_dict in tgt_tile_dicts:\n",
    "        cur_img_name = tile_dict['id']\n",
    "        cur_annots = tile_dict['annotations']\n",
    "        for annot in cur_annots:\n",
    "            if annot['type'] not in tile_categories:\n",
    "                continue\n",
    "            coords = annot['coordinates'][0]\n",
    "            segmentation = [[pt for pair in coords for pt in pair]]\n",
    "            area = calculate_area(coords)\n",
    "            image_id = img_name_to_id[cur_img_name]\n",
    "            min_x = min(coords, key=lambda x: x[0])[0]\n",
    "            max_x = max(coords, key=lambda x: x[0])[0]\n",
    "            min_y = min(coords, key=lambda x: x[1])[1]\n",
    "            max_y = max(coords, key=lambda x: x[1])[1]\n",
    "            bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "            category_id = tile_categories.index(annot['type'])\n",
    "            annotations.append({'segmentation': segmentation, 'area': area, 'iscrowd': 0, 'image_id': image_id, 'bbox': bbox, 'category_id': category_id, 'id': annot_id})\n",
    "#             annotations.append({'iscrowd': 0, 'image_id': image_id, 'bbox': bbox, 'category_id': category_id, 'id': annot_id})\n",
    "            annot_id += 1\n",
    "    return annotations\n",
    "\n",
    "def create_seg_annots_pred(tgt_tile_dicts):\n",
    "    annotations = []\n",
    "    image_ids = []\n",
    "    for tile_dict in tgt_tile_dicts:\n",
    "        cur_img_name = tile_dict['img_path'].split('/')[-1]\n",
    "        cur_img_id = tile_dict['img_path'].split('/')[-1].split('.')[0]\n",
    "        annot_id = 0\n",
    "        image_ids.append({'file_name': cur_img_name, 'height': 512, 'width': 512, 'id': 0})\n",
    "        for label, bbox in zip(tile_dict['labels'].tolist(), tile_dict['bboxes'].tolist()):\n",
    "            annotations.append({'iscrowd': 0, 'image_id': cur_img_id, 'bbox': bbox, \n",
    "                                'category_id': label, 'id': annot_id, 'area': bbox[2]*bbox[3]})\n",
    "            annot_id += 1\n",
    "    return image_ids, annotations\n",
    "\n",
    "def change_annotation_format(train_annotations, start_id):\n",
    "    all_annotations = train_annotations['annotations']\n",
    "    changed_annotation = []\n",
    "    index = start_id + 1\n",
    "    for annotation in all_annotations:\n",
    "        tmp = {'iscrowd': 0,\n",
    "                  'image_id': annotation['image_id'],\n",
    "                  'bbox': annotation['bbox'],\n",
    "                  'category_id': annotation['category_id'],\n",
    "                  'id': index,\n",
    "                  'area': annotation['bbox'][2]*annotation['bbox'][3]}\n",
    "        changed_annotation.append(tmp)\n",
    "        index += 1\n",
    "    return changed_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fceb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/cleaned_polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57a39e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tiles_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3cdb86c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000e79e206b7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10240</td>\n",
       "      <td>29184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00176a88fdb0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14848</td>\n",
       "      <td>25088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00359ab8338b</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6656</td>\n",
       "      <td>9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00488ca285ee</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8192</td>\n",
       "      <td>37888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>004fb033dd09</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>20480</td>\n",
       "      <td>31232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j\n",
       "1  000e79e206b7           6        3  10240  29184\n",
       "3  00176a88fdb0           7        3  14848  25088\n",
       "6  00359ab8338b           8        3   6656   9216\n",
       "7  00488ca285ee           9        3   8192  37888\n",
       "9  004fb033dd09           7        3  20480  31232"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "# tile_df_annotated.head()\n",
    "tile_df_pseudo_label = tile_df[tile_df['dataset'] == 3]\n",
    "tile_df_pseudo_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89074215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633\n"
     ]
    }
   ],
   "source": [
    "dataset_1_tile_ids = sorted(tile_df_annotated.loc[tile_df_annotated['dataset']==1, 'id'].values)\n",
    "all_dataset_tile_ids = sorted(tile_df_annotated.loc[:, 'id'].values)\n",
    "pseudo_label_tile_ids = sorted(tile_df_pseudo_label.loc[:, 'id'].values)\n",
    "tgt_tile_dicts = [x for x in tiles_dicts if x['id'] in dataset_1_tile_ids] if not generate_all_datset_annots else tiles_dicts\n",
    "print(len(tgt_tile_dicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04926a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400\n",
      "422\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "tgt_dataset_tile_ids = dataset_1_tile_ids if not generate_all_datset_annots else all_dataset_tile_ids\n",
    "if (generate_pseudo_labels):\n",
    "    tgt_dataset_tile_ids = pseudo_label_tile_ids\n",
    "random.shuffle(tgt_dataset_tile_ids)\n",
    "random.shuffle(dataset_1_tile_ids)\n",
    "print(len(tgt_dataset_tile_ids))\n",
    "print(len(dataset_1_tile_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6510253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size is 211\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# fold_size = int(math.ceil(len(tgt_dataset_tile_ids) / num_folds))\n",
    "fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds))\n",
    "print(f'Fold size is {fold_size}')\n",
    "categories = create_category_annots(tile_categories)\n",
    "for i in range(num_folds):\n",
    "    output_dir = f'{base_path}/{base_data_dir}/{base_data_name}{pseudo_label_name}_mmdet_fold_{i}'\n",
    "    \n",
    "#     cur_validation_slice = tgt_dataset_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(tgt_dataset_tile_ids))]\n",
    "    cur_validation_slice = dataset_1_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(dataset_1_tile_ids))]\n",
    "    cur_training_slice = list(set(tgt_dataset_tile_ids) - set(cur_validation_slice)) if not keep_all_in_train else tgt_dataset_tile_ids\n",
    "    if (generate_pseudo_labels == True):\n",
    "        cur_validation_slice = cur_training_slice\n",
    "    for img_name in cur_validation_slice:\n",
    "        shutil.copy(f'{input_imgs_path}/{img_name}.tif', f'{output_dir}/validation_images/{img_name}.tif')\n",
    "    for img_name in cur_training_slice:\n",
    "        shutil.copy(f'{input_imgs_path}/{img_name}.tif', f'{output_dir}/train_images/{img_name}.tif')\n",
    "    \n",
    "    if (generate_pseudo_labels == False):\n",
    "        val_images, val_img_name_to_id = create_image_annots(cur_validation_slice)\n",
    "        train_images, train_img_name_to_id = create_image_annots(cur_training_slice)\n",
    "\n",
    "        val_segmentation_annots = create_seg_annots([x for x in tgt_tile_dicts if x['id'] in cur_validation_slice], val_img_name_to_id)\n",
    "        train_segmentation_annots = create_seg_annots([x for x in tgt_tile_dicts if x['id'] in cur_training_slice], train_img_name_to_id)\n",
    "\n",
    "        val_final_annots = {'categories': categories, 'images': val_images, 'annotations': val_segmentation_annots}\n",
    "        train_final_annots = {'categories': categories, 'images': train_images, 'annotations': train_segmentation_annots}\n",
    "\n",
    "        with open(f'{output_dir}/annotations/validation_annotations.json', 'w') as f:\n",
    "            json.dump(val_final_annots, f)\n",
    "        with open(f'{output_dir}/annotations/train_annotations.json', 'w') as f:\n",
    "            json.dump(train_final_annots, f)\n",
    "    else:\n",
    "        val_images, val_img_name_to_id = create_image_annots(cur_validation_slice)\n",
    "\n",
    "        val_segmentation_annots = create_seg_annots([x for x in tgt_tile_dicts if x['id'] in cur_validation_slice], val_img_name_to_id)\n",
    "\n",
    "        val_final_annots = {'categories': categories, 'images': val_images, 'annotations': val_segmentation_annots}\n",
    " \n",
    "        with open(f'{output_dir}/annotations/validation_annotations.json', 'w') as f:\n",
    "            json.dump(val_final_annots, f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d057551b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../all_dataset_files/all_dataset_pseudo_labels_mmdet_fold_0/validation_images/07bdbe578ded.tif'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "output_dir = f'{base_path}/{base_data_dir}/{base_data_name}{pseudo_label_name}_mmdet_fold_0'\n",
    "orig_dir = f'{base_path}/{base_data_dir}/all_dataset_mmdet_fold_0'\n",
    "\n",
    "if os.path.isdir(f'{orig_dir}/validation_images'):\n",
    "    shutil.rmtree(f'{orig_dir}/validation_images')\n",
    "\n",
    "for train_img in os.listdir(f'{orig_dir}/train_images'):\n",
    "    shutil.copyfile(f'{orig_dir}/train_images/{train_img}', f'{output_dir}/train_images/{train_img}')\n",
    "for val_img in os.listdir(f'{orig_dir}/validation_images'):\n",
    "    shutil.copyfile(f'{orig_dir}/validation_images/{val_img}', f'{output_dir}/validation_images/{val_img}')\n",
    "shutil.copyfile(f'{orig_dir}/annotations/validation_annotations.json', f'{output_dir}/annotations/validation_annotations.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ded823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pseudo_label_pkl = 'val_preds_yolo_05.pkl'\n",
    "\n",
    "with open(f'{base_path}/project_mmdet/{val_pseudo_label_pkl}', 'rb') as f:\n",
    "    pseudo_annotations = pickle.load(f)\n",
    "pseudo_imgs, pseudo_annotation_dicts = create_seg_annots_pred(pseudo_lables)\n",
    "\n",
    "with open(f'{orig_dir}/annotations/train_annotations.json', 'r') as f:\n",
    "    train_annotations = json.load(f)\n",
    "    \n",
    "train_annotation_dicts = change_annotation_format(train_annotations, len(pseudo_annotations))\n",
    "val_final_annots = {'categories': train_annotations['categories'], \n",
    "                    'images': train_annotations['images'] + pseudo_imgs, \n",
    "                    'annotations': train_annotation_dicts + pseudo_annotation_dicts}\n",
    "with open(f'{output_dir}/annotations/train_annotations.json', 'w') as f:\n",
    "    json.dump(val_final_annots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6c11cf17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '0006ff2aa7cd.tif', 'height': 512, 'width': 512, 'id': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_annotations['images'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d958b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "407139c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_dir}/annotations/train_annotations.json', 'r') as f:\n",
    "    final_train_annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6489cde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['categories', 'images', 'annotations'])\n",
      "[{'id': 0, 'name': 'blood_vessel'}]\n",
      "{'file_name': '0006ff2aa7cd.tif', 'height': 512, 'width': 512, 'id': 0}\n",
      "{'iscrowd': 0, 'image_id': 0, 'bbox': [272, 73, 19, 36], 'category_id': 0, 'id': 5401}\n"
     ]
    }
   ],
   "source": [
    "print(final_train_annotations.keys())\n",
    "print(final_train_annotations['categories'])\n",
    "print(final_train_annotations['images'][0])\n",
    "print(final_train_annotations['annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63f2673c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ffb3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26f427e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e2c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c97ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seg_annots_pred(tgt_tile_dicts):\n",
    "    for tile_dict in tgt_tile_dicts:\n",
    "        cur_img_name = tile_dict['img_path'].split('/')[-1].split('.')[0]\n",
    "        annotations = []\n",
    "        annot_id = 0\n",
    "        for label, bbox in zip(tile_dict['labels'].tolist(), tile_dict['bboxes'].tolist()):\n",
    "            annotations.append({'iscrowd': 0, 'image_id': cur_img_name, 'bbox': bbox, 'category_id': label, 'id': annot_id})\n",
    "            annot_id += 1\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3107d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "with open(f'{base_path}/{base_data_dir}/{base_data_name}_mmdet_fold_{i}/annotations/train_annotations.json', 'r') as f:\n",
    "    train_annots = json.load(f)\n",
    "with open(f'{base_path}/{base_data_dir}/{base_data_name}_mmdet_fold_{i}/annotations/validation_annotations.json', 'r') as f:\n",
    "    validation_annots = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_annots.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_to_segs = dict()\n",
    "\n",
    "for annot in train_annots['annotations']:\n",
    "    image_id = annot['image_id']\n",
    "    segmentation = annot['segmentation'][0]\n",
    "    if image_id not in img_to_segs:\n",
    "        img_to_segs[image_id] = [segmentation]\n",
    "    else:\n",
    "        img_to_segs[image_id].append(segmentation)\n",
    "for image_id in img_to_segs.keys():\n",
    "    segmentations = img_to_segs[image_id]\n",
    "    if len(segmentations) > 0:\n",
    "        for i in range(len(segmentations)):\n",
    "            for j in range(i+1, len(segmentations)):\n",
    "                if segmentations[i]==segmentations[j]:\n",
    "                    print(f'Found duplicate annots for image {image_id}!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759694f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc27936",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "train_img_ids = set()\n",
    "train_seg_img_ids = set()\n",
    "for annot in train_annots['images']:\n",
    "    train_img_ids.add(annot['id'])\n",
    "for annot in train_annots['annotations']:\n",
    "    train_seg_img_ids.add(annot['image_id'])\n",
    "    categories.add(annot['category_id'])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "validation_img_ids = set()\n",
    "validation_seg_img_ids = set()\n",
    "for annot in validation_annots['images']:\n",
    "    validation_img_ids.add(annot['id'])\n",
    "for annot in validation_annots['annotations']:\n",
    "    validation_seg_img_ids.add(annot['image_id'])\n",
    "    categories.add(annot['category_id'])\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_img_ids), len(validation_img_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfc8972",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "train_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_train_mmdet_fold_{i}/images'\n",
    "train_img_files = os.listdir(train_imgs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db119255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet",
   "language": "python",
   "name": "mmdet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
