{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900cdf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import shutil\n",
    "from shapely.geometry import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4a1806",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "generate_all_datset_annots = True\n",
    "tile_categories = ['blood_vessel', 'glomerulus', 'unsure']\n",
    "base_data_dir = 'dataset1_files' if not generate_all_datset_annots else 'all_dataset_files'\n",
    "base_data_name = 'all_dataset1' if not generate_all_datset_annots else 'all_dataset'\n",
    "input_imgs_path = f'{base_path}/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87dfc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = f'{base_path}/{base_data_dir}/{base_data_name}_mmdet'\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "os.mkdir(output_dir)\n",
    "os.mkdir(f'{output_dir}/train_images')\n",
    "os.mkdir(f'{output_dir}/validation_images')\n",
    "os.mkdir(f'{output_dir}/annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d252b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coords):\n",
    "    p = Polygon(coords)\n",
    "    return p.area\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4742561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_category_annots(tile_categories):\n",
    "    categories = []\n",
    "    for idx, tc in enumerate(tile_categories):\n",
    "        categories.append({'id': idx, 'name': tc})\n",
    "    return categories\n",
    "def create_image_annots(input_imgs_names):\n",
    "    image_annots = []\n",
    "    img_name_to_id = dict()\n",
    "    input_img_names = sorted(input_imgs_names)\n",
    "    for idx, img_name in enumerate(input_img_names):\n",
    "        img = cv2.imread(f'{input_imgs_path}/{img_name}.tif')\n",
    "        height, width = img.shape[:2]\n",
    "        image_annots.append({'file_name': f'{img_name}.tif', 'height': height, 'width': width, 'id': idx})\n",
    "        img_name_to_id[img_name] = idx\n",
    "    return image_annots, img_name_to_id\n",
    "def create_seg_annots(tgt_tile_dicts, img_name_to_id):\n",
    "    annotations = []\n",
    "    annot_id = 0\n",
    "    for tile_dict in tgt_tile_dicts:\n",
    "        cur_img_name = tile_dict['id']\n",
    "        cur_annots = tile_dict['annotations']\n",
    "        for annot in cur_annots:\n",
    "            if annot['type'] not in tile_categories:\n",
    "                continue\n",
    "            coords = annot['coordinates'][0]\n",
    "            segmentation = [[pt for pair in coords for pt in pair]]\n",
    "            area = calculate_area(coords)\n",
    "            image_id = img_name_to_id[cur_img_name]\n",
    "            min_x = min(coords, key=lambda x: x[0])[0]\n",
    "            max_x = max(coords, key=lambda x: x[0])[0]\n",
    "            min_y = min(coords, key=lambda x: x[1])[1]\n",
    "            max_y = max(coords, key=lambda x: x[1])[1]\n",
    "            bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "            category_id = tile_categories.index(annot['type'])\n",
    "            annotations.append({'segmentation': segmentation, 'area': area, 'iscrowd': 0, 'image_id': image_id, 'bbox': bbox, 'category_id': category_id, 'id': annot_id})\n",
    "            annot_id += 1\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ca23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4da4d800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>blood_vessel</th>\n",
       "      <th>glomerulus</th>\n",
       "      <th>unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ff2aa7cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16896</td>\n",
       "      <td>16420</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00168d1b7522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14848</td>\n",
       "      <td>14884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0033bbc76b6b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>43008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003504460b3a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8192</td>\n",
       "      <td>11776</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004daf1cbe75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6144</td>\n",
       "      <td>11264</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j  blood_vessel  glomerulus  \\\n",
       "0  0006ff2aa7cd           2        2  16896  16420             8           1   \n",
       "1  00168d1b7522           2        2  14848  14884             1           1   \n",
       "2  0033bbc76b6b           1        1  10240  43008             3           0   \n",
       "3  003504460b3a           3        2   8192  11776             7           0   \n",
       "4  004daf1cbe75           3        2   6144  11264            10           1   \n",
       "\n",
       "   unsure  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed576c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_tile_ids = sorted(tile_df_annotated.loc[tile_df_annotated['dataset']==1, 'id'].values)\n",
    "all_dataset_tile_ids = sorted(tile_df_annotated.loc[:, 'id'].values)\n",
    "tgt_tile_dicts = [x for x in tiles_dicts if x['id'] in dataset_1_tile_ids] if not generate_all_datset_annots else tiles_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "109aca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "tgt_dataset_tile_ids = dataset_1_tile_ids if not generate_all_datset_annots else all_dataset_tile_ids\n",
    "random.shuffle(dataset_1_tile_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ffac20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "fold_size = int(math.ceil(len(tgt_dataset_tile_ids) / 5))\n",
    "output_dir = f'{base_path}/{base_data_dir}/{base_data_name}_mmdet'\n",
    "categories = create_category_annots(tile_categories)\n",
    "\n",
    "if generate_all_datset_annots:\n",
    "    cur_validation_slice = dataset_1_tile_ids\n",
    "    cur_training_slice = list(set(tgt_dataset_tile_ids) - set(dataset_1_tile_ids))\n",
    "else:\n",
    "    cur_validation_slice = tgt_dataset_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(tgt_dataset_tile_ids))]\n",
    "    cur_training_slice = list(set(tgt_dataset_tile_ids) - set(cur_validation_slice))\n",
    "\n",
    "for img_name in cur_validation_slice:\n",
    "    shutil.copy(f'{input_imgs_path}/{img_name}.tif', f'{output_dir}/validation_images/{img_name}.tif')\n",
    "for img_name in cur_training_slice:\n",
    "    shutil.copy(f'{input_imgs_path}/{img_name}.tif', f'{output_dir}/train_images/{img_name}.tif')\n",
    "\n",
    "val_images, val_img_name_to_id = create_image_annots(cur_validation_slice)\n",
    "train_images, train_img_name_to_id = create_image_annots(cur_training_slice)\n",
    "\n",
    "val_segmentation_annots = create_seg_annots([x for x in tgt_tile_dicts if x['id'] in cur_validation_slice], val_img_name_to_id)\n",
    "train_segmentation_annots = create_seg_annots([x for x in tgt_tile_dicts if x['id'] in cur_training_slice], train_img_name_to_id)\n",
    "\n",
    "val_final_annots = {'categories': categories, 'images': val_images, 'annotations': val_segmentation_annots}\n",
    "train_final_annots = {'categories': categories, 'images': train_images, 'annotations': train_segmentation_annots}\n",
    "\n",
    "with open(f'{output_dir}/annotations/validation_annotations.json', 'w') as f:\n",
    "    json.dump(val_final_annots, f)\n",
    "with open(f'{output_dir}/annotations/train_annotations.json', 'w') as f:\n",
    "    json.dump(train_final_annots, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2addff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "open-mmlab-latest",
   "language": "python",
   "name": "open-mmlab-latest"
=======
   "display_name": "mmdet",
   "language": "python",
   "name": "mmdet"
>>>>>>> 84a6af0aed66be101f88d76b202b5e94c7ab7eef
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
