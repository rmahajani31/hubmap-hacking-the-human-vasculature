{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2c22e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:15.168956Z",
     "iopub.status.busy": "2023-06-07T03:57:15.167985Z",
     "iopub.status.idle": "2023-06-07T03:57:20.037282Z",
     "shell.execute_reply": "2023-06-07T03:57:20.036264Z",
     "shell.execute_reply.started": "2023-06-07T03:57:15.168918Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch.nn as nn\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37a87902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.039109Z",
     "iopub.status.busy": "2023-06-07T03:57:20.038648Z",
     "iopub.status.idle": "2023-06-07T03:57:20.136628Z",
     "shell.execute_reply": "2023-06-07T03:57:20.135569Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.039077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2685d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.139089Z",
     "iopub.status.busy": "2023-06-07T03:57:20.138573Z",
     "iopub.status.idle": "2023-06-07T03:57:20.143910Z",
     "shell.execute_reply": "2023-06-07T03:57:20.142782Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.139055Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "x_train_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset1_imgs')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset1_masks')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset2_imgs')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset2_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf14b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.148146Z",
     "iopub.status.busy": "2023-06-07T03:57:20.147738Z",
     "iopub.status.idle": "2023-06-07T03:57:20.161932Z",
     "shell.execute_reply": "2023-06-07T03:57:20.161116Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.148069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 422, 1211, 1211)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(x_train_dir)), len(os.listdir(y_train_dir)), len(os.listdir(x_valid_dir)), len(os.listdir(y_valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a8c26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.163643Z",
     "iopub.status.busy": "2023-06-07T03:57:20.163316Z",
     "iopub.status.idle": "2023-06-07T03:57:20.171336Z",
     "shell.execute_reply": "2023-06-07T03:57:20.169410Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.163613Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ffb5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.173020Z",
     "iopub.status.busy": "2023-06-07T03:57:20.172759Z",
     "iopub.status.idle": "2023-06-07T03:57:20.186633Z",
     "shell.execute_reply": "2023-06-07T03:57:20.185450Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.172999Z"
    }
   },
   "outputs": [],
   "source": [
    "class HubMapDataset(BaseDataset):\n",
    "    \"\"\"Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['unlabelled', 'blood_vessel']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return self.masks_fps[i], image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3646a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.189306Z",
     "iopub.status.busy": "2023-06-07T03:57:20.189056Z",
     "iopub.status.idle": "2023-06-07T03:57:20.199276Z",
     "shell.execute_reply": "2023-06-07T03:57:20.198453Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.189284Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "  train_transform = [\n",
    "    albu.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=90),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.2, scale_limit=0, rotate_limit=0),\n",
    "    albu.ShiftScaleRotate(shift_limit=0, scale_limit=0.2, rotate_limit=0),\n",
    "    albu.Flip(),\n",
    "    albu.RandomBrightnessContrast(),\n",
    "    albu.RandomResizedCrop(height=512, width=512, scale=(0.8, 1.0), p=1)\n",
    "  ]\n",
    "  return albu.Compose(train_transform)\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e337b8b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.202137Z",
     "iopub.status.busy": "2023-06-07T03:57:20.201701Z",
     "iopub.status.idle": "2023-06-07T03:57:20.212712Z",
     "shell.execute_reply": "2023-06-07T03:57:20.212138Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.202106Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = ['unlabelled', 'blood_vessel']\n",
    "ENCODER = 'efficientnet-b7'\n",
    "ENCODER_WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05d2782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.214981Z",
     "iopub.status.busy": "2023-06-07T03:57:20.213834Z",
     "iopub.status.idle": "2023-06-07T03:57:22.861085Z",
     "shell.execute_reply": "2023-06-07T03:57:22.860125Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.214949Z"
    }
   },
   "outputs": [],
   "source": [
    "data_parallel = False\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,        \n",
    "    encoder_weights=ENCODER_WEIGHTS,     \n",
    "    in_channels=3,                  \n",
    "    classes=len(CLASSES)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model = nn.DataParallel(model) if data_parallel else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de917e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.862921Z",
     "iopub.status.busy": "2023-06-07T03:57:22.862437Z",
     "iopub.status.idle": "2023-06-07T03:57:22.868984Z",
     "shell.execute_reply": "2023-06-07T03:57:22.868048Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.862889Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bf572f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.871025Z",
     "iopub.status.busy": "2023-06-07T03:57:22.870385Z",
     "iopub.status.idle": "2023-06-07T03:57:22.887537Z",
     "shell.execute_reply": "2023-06-07T03:57:22.886666Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.870990Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = HubMapDataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = HubMapDataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d969355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.890654Z",
     "iopub.status.busy": "2023-06-07T03:57:22.889712Z",
     "iopub.status.idle": "2023-06-07T03:57:22.941275Z",
     "shell.execute_reply": "2023-06-07T03:57:22.940239Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.890622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 512, 512) (2, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "_, image, mask = train_dataset[0]\n",
    "print(image.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a705d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.945580Z",
     "iopub.status.busy": "2023-06-07T03:57:22.945282Z",
     "iopub.status.idle": "2023-06-07T03:57:26.268133Z",
     "shell.execute_reply": "2023-06-07T03:57:26.267164Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.945555Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "class IoUScore(Metric):\n",
    "    def __init__(self, threshold=0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"intersection_back\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"union_back\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"intersection_fore\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"union_fore\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"num_images\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds = (preds > self.threshold).int()\n",
    "        intersection_back = torch.logical_and(preds[:,0,:,:], target[:,0,:,:]).sum()\n",
    "        union_back = torch.logical_or(preds[:,0,:,:], target[:,0,:,:]).sum()\n",
    "        intersection_fore = torch.logical_and(preds[:,1,:,:], target[:,1,:,:]).sum()\n",
    "        union_fore = torch.logical_or(preds[:,1,:,:], target[:,1,:,:]).sum()\n",
    "\n",
    "        self.intersection_back += intersection_back\n",
    "        self.union_back += union_back\n",
    "        self.intersection_fore += intersection_fore\n",
    "        self.union_fore += union_fore\n",
    "\n",
    "    def compute(self):\n",
    "        iou_back = (self.intersection_back.float() / self.union_back.float())\n",
    "        iou_fore = (self.intersection_fore.float() / self.union_fore.float())\n",
    "        self.intersection_back = 0\n",
    "        self.union_back = 0\n",
    "        self.intersection_fore = 0\n",
    "        self.union_fore = 0\n",
    "        return iou_back,iou_fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02a01aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, targets, threshold=0.5, smooth=1e-5, class_weights=None):\n",
    "    preds_probs = torch.softmax(preds, dim=1)\n",
    "    preds_flat = preds_probs.view(preds_probs.shape[0], preds_probs.shape[1], -1)\n",
    "    targets_flat = targets.view(targets.shape[0], targets.shape[1], -1)\n",
    "    intersection_vals = preds_flat * targets_flat\n",
    "    intersection_sum = intersection_vals.sum(dim=(-1,0))\n",
    "    denom_sum = preds_flat.sum(dim=(-1,0)) + targets_flat.sum(dim=(-1,0))\n",
    "    dice_coeffs = (2 * intersection_sum + smooth) / (denom_sum + smooth)\n",
    "    if class_weights is not None:\n",
    "        dice_coeffs = dice_coeffs * class_weights\n",
    "    dice_coeff = torch.mean(dice_coeffs)\n",
    "#     print(f'Shapes: {preds.requires_grad}, {preds_probs.shape}, {preds_probs.requires_grad}, {preds_flat.shape}, {preds_flat.requires_grad}, {targets_flat.shape}, {targets_flat.requires_grad}, {intersection_vals.shape}, {intersection_vals.requires_grad}, {intersection_sum.shape}, {intersection_sum.requires_grad}, {denom_sum.shape}, {denom_sum.requires_grad}, {dice_coeffs.shape}, {dice_coeffs.requires_grad}, {dice_coeff.shape}, {dice_coeffs.requires_grad}')\n",
    "    return 1 - dice_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ac12f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:26.270748Z",
     "iopub.status.busy": "2023-06-07T03:57:26.269595Z",
     "iopub.status.idle": "2023-06-07T03:57:27.247770Z",
     "shell.execute_reply": "2023-06-07T03:57:27.246768Z",
     "shell.execute_reply.started": "2023-06-07T03:57:26.270713Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "metrics = [\n",
    "    IoUScore(threshold=0.5).to(DEVICE),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34e7b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:27.249961Z",
     "iopub.status.busy": "2023-06-07T03:57:27.249364Z",
     "iopub.status.idle": "2023-06-07T03:57:27.262769Z",
     "shell.execute_reply": "2023-06-07T03:57:27.261720Z",
     "shell.execute_reply.started": "2023-06-07T03:57:27.249925Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Training loop\n",
    "def train_epoch(model, metrics, optimizer, device, dataloader, class_weights=[0.01,0.99]):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "    class_weights = class_weights.to(device)\n",
    "    print(f'Processing a total of {num_batches} batches in training')\n",
    "    # Iterate over the training dataset\n",
    "    for batch_idx, (f, inputs, targets) in tqdm(enumerate(dataloader)):        \n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "#         print(f'input and output shapes: {inputs.shape}, {outputs.shape}, {targets.shape}')\n",
    "#         print(f'Outputs min: {torch.min(outputs)}, Outputs max: {torch.max(outputs)}')\n",
    "        loss = dice_loss(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics\n",
    "        for metric in metrics:\n",
    "            metric.update(torch.softmax(outputs, dim=1), targets)\n",
    "        total_loss += loss\n",
    "\n",
    "    # Get the metric values\n",
    "    metric_values = [float(total_loss)/num_batches] + [metric.compute() for metric in metrics]\n",
    "    return metric_values\n",
    "\n",
    "# Validation loop\n",
    "def valid_epoch(model, metrics, device, dataloader):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    print(f'Processing a total of {num_batches} batches in validation')\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation dataset\n",
    "        for batch_idx, (f, inputs, targets) in tqdm(enumerate(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = dice_loss(outputs, targets, class_weights=[0.01,0.99])\n",
    "\n",
    "            # Compute metrics\n",
    "            for metric in metrics:\n",
    "                metric.update(torch.softmax(outputs, dim=1), targets)\n",
    "            total_loss += loss\n",
    "\n",
    "    # Get the metric values\n",
    "    metric_values = [float(total_loss)/num_batches] + [metric.compute() for metric in metrics]\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fffd9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:27.265083Z",
     "iopub.status.busy": "2023-06-07T03:57:27.264623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a total of 106 batches in training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:03,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:04,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [00:05,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [00:06,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: True, torch.Size([4, 2, 512, 512]), True, torch.Size([4, 2, 262144]), True, torch.Size([4, 2, 262144]), False, torch.Size([4, 2, 262144]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([2]), True, torch.Size([]), True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.44s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "max_iou = 0\n",
    "num_epochs = 50\n",
    "if os.path.exists('./models/model_stats_unet_dataset1.txt'):\n",
    "  os.remove('./models/model_stats_unet_dataset1.txt')\n",
    "fp = open('./models/model_stats_unet_dataset1.txt', 'a')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    train_metrics = train_epoch(model, metrics, optimizer, DEVICE, train_loader)\n",
    "    print(f'=========Finished Training Epoch {epoch} in {float(time.time()-start_time)/60}==========')\n",
    "    # Validation\n",
    "    start_time = time.time()\n",
    "    valid_metrics = valid_epoch(model, metrics, DEVICE, valid_loader)\n",
    "    print(f'=========Finished Validation Epoch {epoch} {float(time.time()-start_time)/60}in =========')\n",
    "    \n",
    "    save_interval = 10\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model, f'./models/model_{epoch}_unet_dataset1.pth')\n",
    "    \n",
    "    cur_validation_iou = 0.5*valid_metrics[1][0] + 0.5*valid_metrics[1][1]\n",
    "    if cur_validation_iou > max_iou:\n",
    "      print(f'Saving model with IoU: {cur_validation_iou}...')\n",
    "      torch.save(model, './models/best_model_unet_dataset1.pth')\n",
    "      with open('./models/best_model_unet_dataset1.txt', 'w') as f:\n",
    "        f.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "      max_iou = cur_validation_iou\n",
    "    # Print or log the metrics for each epoch\n",
    "    print(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "    fp.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\\n\")\n",
    "    fp.flush()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb3273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HubMapEnv",
   "language": "python",
   "name": "hubmapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
