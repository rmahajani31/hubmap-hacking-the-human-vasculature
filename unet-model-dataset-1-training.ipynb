{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2c22e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:15.168956Z",
     "iopub.status.busy": "2023-06-07T03:57:15.167985Z",
     "iopub.status.idle": "2023-06-07T03:57:20.037282Z",
     "shell.execute_reply": "2023-06-07T03:57:20.036264Z",
     "shell.execute_reply.started": "2023-06-07T03:57:15.168918Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import torch.nn as nn\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a87902",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.039109Z",
     "iopub.status.busy": "2023-06-07T03:57:20.038648Z",
     "iopub.status.idle": "2023-06-07T03:57:20.136628Z",
     "shell.execute_reply": "2023-06-07T03:57:20.135569Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.039077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2685d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.139089Z",
     "iopub.status.busy": "2023-06-07T03:57:20.138573Z",
     "iopub.status.idle": "2023-06-07T03:57:20.143910Z",
     "shell.execute_reply": "2023-06-07T03:57:20.142782Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.139055Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "x_train_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset1_imgs')\n",
    "y_train_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset1_masks')\n",
    "\n",
    "x_valid_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset2_imgs')\n",
    "y_valid_dir = os.path.join(DATA_DIR, 'dataset1_files/all_dataset2_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cf14b5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.148146Z",
     "iopub.status.busy": "2023-06-07T03:57:20.147738Z",
     "iopub.status.idle": "2023-06-07T03:57:20.161932Z",
     "shell.execute_reply": "2023-06-07T03:57:20.161116Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.148069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422, 422, 1211, 1211)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(x_train_dir)), len(os.listdir(y_train_dir)), len(os.listdir(x_valid_dir)), len(os.listdir(y_valid_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a8c26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.163643Z",
     "iopub.status.busy": "2023-06-07T03:57:20.163316Z",
     "iopub.status.idle": "2023-06-07T03:57:20.171336Z",
     "shell.execute_reply": "2023-06-07T03:57:20.169410Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.163613Z"
    }
   },
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98ffb5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.173020Z",
     "iopub.status.busy": "2023-06-07T03:57:20.172759Z",
     "iopub.status.idle": "2023-06-07T03:57:20.186633Z",
     "shell.execute_reply": "2023-06-07T03:57:20.185450Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.172999Z"
    }
   },
   "outputs": [],
   "source": [
    "class HubMapDataset(BaseDataset):\n",
    "    \"\"\"Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['unlabelled', 'blood_vessel']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return self.masks_fps[i], image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d3646a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.189306Z",
     "iopub.status.busy": "2023-06-07T03:57:20.189056Z",
     "iopub.status.idle": "2023-06-07T03:57:20.199276Z",
     "shell.execute_reply": "2023-06-07T03:57:20.198453Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.189284Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "  train_transform = [\n",
    "    albu.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=90),\n",
    "    albu.ShiftScaleRotate(shift_limit=0.2, scale_limit=0, rotate_limit=0),\n",
    "    albu.ShiftScaleRotate(shift_limit=0, scale_limit=0.2, rotate_limit=0),\n",
    "    albu.Flip(),\n",
    "    albu.RandomBrightnessContrast(),\n",
    "    albu.RandomResizedCrop(height=512, width=512, scale=(0.8, 1.0), p=1),\n",
    "    albu.ColorJitter()\n",
    "  ]\n",
    "  return albu.Compose(train_transform)\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e337b8b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.202137Z",
     "iopub.status.busy": "2023-06-07T03:57:20.201701Z",
     "iopub.status.idle": "2023-06-07T03:57:20.212712Z",
     "shell.execute_reply": "2023-06-07T03:57:20.212138Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.202106Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = ['unlabelled', 'blood_vessel']\n",
    "ENCODER = 'efficientnet-b7'\n",
    "ENCODER_WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c05d2782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:20.214981Z",
     "iopub.status.busy": "2023-06-07T03:57:20.213834Z",
     "iopub.status.idle": "2023-06-07T03:57:22.861085Z",
     "shell.execute_reply": "2023-06-07T03:57:22.860125Z",
     "shell.execute_reply.started": "2023-06-07T03:57:20.214949Z"
    }
   },
   "outputs": [],
   "source": [
    "data_parallel = False\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,        \n",
    "    encoder_weights=ENCODER_WEIGHTS,     \n",
    "    in_channels=3,                  \n",
    "    classes=len(CLASSES)\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model = nn.DataParallel(model) if data_parallel else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de917e24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.862921Z",
     "iopub.status.busy": "2023-06-07T03:57:22.862437Z",
     "iopub.status.idle": "2023-06-07T03:57:22.868984Z",
     "shell.execute_reply": "2023-06-07T03:57:22.868048Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.862889Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5bf572f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.871025Z",
     "iopub.status.busy": "2023-06-07T03:57:22.870385Z",
     "iopub.status.idle": "2023-06-07T03:57:22.887537Z",
     "shell.execute_reply": "2023-06-07T03:57:22.886666Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.870990Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = HubMapDataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "valid_dataset = HubMapDataset(\n",
    "    x_valid_dir, \n",
    "    y_valid_dir, \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d969355",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.890654Z",
     "iopub.status.busy": "2023-06-07T03:57:22.889712Z",
     "iopub.status.idle": "2023-06-07T03:57:22.941275Z",
     "shell.execute_reply": "2023-06-07T03:57:22.940239Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.890622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 512, 512) (2, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "_, image, mask = train_dataset[0]\n",
    "print(image.shape, mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a705d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:22.945580Z",
     "iopub.status.busy": "2023-06-07T03:57:22.945282Z",
     "iopub.status.idle": "2023-06-07T03:57:26.268133Z",
     "shell.execute_reply": "2023-06-07T03:57:26.267164Z",
     "shell.execute_reply.started": "2023-06-07T03:57:22.945555Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchmetrics import Metric\n",
    "class IoUScore(Metric):\n",
    "    def __init__(self, threshold=0.5, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "        self.threshold = threshold\n",
    "        self.add_state(\"intersection_back\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"union_back\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"intersection_fore\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"union_fore\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"num_images\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds = (preds > self.threshold).int()\n",
    "        intersection_back = torch.logical_and(preds[:,0,:,:], target[:,0,:,:]).sum()\n",
    "        union_back = torch.logical_or(preds[:,0,:,:], target[:,0,:,:]).sum()\n",
    "        intersection_fore = torch.logical_and(preds[:,1,:,:], target[:,1,:,:]).sum()\n",
    "        union_fore = torch.logical_or(preds[:,1,:,:], target[:,1,:,:]).sum()\n",
    "\n",
    "        self.intersection_back += intersection_back\n",
    "        self.union_back += union_back\n",
    "        self.intersection_fore += intersection_fore\n",
    "        self.union_fore += union_fore\n",
    "\n",
    "    def compute(self):\n",
    "        iou_back = (self.intersection_back.float() / self.union_back.float())\n",
    "        iou_fore = (self.intersection_fore.float() / self.union_fore.float())\n",
    "        self.intersection_back = 0\n",
    "        self.union_back = 0\n",
    "        self.intersection_fore = 0\n",
    "        self.union_fore = 0\n",
    "        return iou_back,iou_fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02a01aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(preds, targets, class_weights, threshold=0.5, smooth=1e-5):\n",
    "    preds_probs = torch.softmax(preds, dim=1)\n",
    "    preds_flat = preds_probs.view(preds_probs.shape[0], preds_probs.shape[1], -1)\n",
    "    targets_flat = targets.view(targets.shape[0], targets.shape[1], -1)\n",
    "    intersection_vals = preds_flat * targets_flat\n",
    "    intersection_sum = intersection_vals.sum(dim=(-1,0))\n",
    "    denom_sum = preds_flat.sum(dim=(-1,0)) + targets_flat.sum(dim=(-1,0))\n",
    "    dice_coeffs = (2 * intersection_sum + smooth) / (denom_sum + smooth)\n",
    "    dice_coeff = torch.sum(dice_coeffs * class_weights) / torch.sum(class_weights)\n",
    "    return 1 - dice_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32ac12f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:26.270748Z",
     "iopub.status.busy": "2023-06-07T03:57:26.269595Z",
     "iopub.status.idle": "2023-06-07T03:57:27.247770Z",
     "shell.execute_reply": "2023-06-07T03:57:27.246768Z",
     "shell.execute_reply.started": "2023-06-07T03:57:26.270713Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "metrics = [\n",
    "    IoUScore(threshold=0.5).to(DEVICE),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a34e7b5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:27.249961Z",
     "iopub.status.busy": "2023-06-07T03:57:27.249364Z",
     "iopub.status.idle": "2023-06-07T03:57:27.262769Z",
     "shell.execute_reply": "2023-06-07T03:57:27.261720Z",
     "shell.execute_reply.started": "2023-06-07T03:57:27.249925Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Training loop\n",
    "def train_epoch(model, metrics, optimizer, device, dataloader, class_weights=[0.05,1]):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32, requires_grad=False)\n",
    "    class_weights = class_weights.to(device)\n",
    "    print(f'Processing a total of {num_batches} batches in training')\n",
    "    # Iterate over the training dataset\n",
    "    for batch_idx, (f, inputs, targets) in tqdm(enumerate(dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "#         print(f'input and output shapes: {inputs.shape}, {outputs.shape}, {targets.shape}')\n",
    "#         print(f'Outputs min: {torch.min(outputs)}, Outputs max: {torch.max(outputs)}')\n",
    "        loss = dice_loss(outputs, targets, class_weights)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute metrics\n",
    "        for metric in metrics:\n",
    "            metric.update(torch.softmax(outputs, dim=1), targets)\n",
    "        total_loss += loss\n",
    "    # Get the metric values\n",
    "    metric_values = [float(total_loss)/num_batches] + [metric.compute() for metric in metrics]\n",
    "    return metric_values\n",
    "\n",
    "def valid_epoch(model, metrics, device, dataloader, class_weights=[0.05,1]):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32, requires_grad=False)\n",
    "    class_weights = class_weights.to(device)\n",
    "    print(f'Processing a total of {num_batches} batches in validation')\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation dataset\n",
    "        for batch_idx, (f, inputs, targets) in tqdm(enumerate(dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = dice_loss(outputs, targets, class_weights)\n",
    "\n",
    "            # Compute metrics\n",
    "            for metric in metrics:\n",
    "                metric.update(torch.softmax(outputs, dim=1), targets)\n",
    "            total_loss += loss\n",
    "\n",
    "    # Get the metric values\n",
    "    metric_values = [float(total_loss)/num_batches] + [metric.compute() for metric in metrics]\n",
    "    return metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "290cf05f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cur_validation_iou' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(cur_train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     21\u001b[0m valid_loader \u001b[38;5;241m=\u001b[39m DataLoader(cur_valid_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mcur_validation_iou\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cur_train_dataset), \u001b[38;5;28mlen\u001b[39m(cur_valid_dataset))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cur_validation_iou' is not defined"
     ]
    }
   ],
   "source": [
    "## This is a block to run training with cross validation\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Subset\n",
    "num_folds = 5\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "num_epochs = 50\n",
    "\n",
    "for i in range(0, num_folds):\n",
    "  if os.path.exists(f'./models/model_stats_unet_dataset1_fold_{i}.txt'):\n",
    "    os.remove(f'./models/model_stats_unet_dataset1_fold_{i}.txt')\n",
    "\n",
    "for fold, (train_indices, valid_indices) in enumerate(kfold.split(train_dataset)):\n",
    "  cur_train_dataset = Subset(train_dataset, train_indices)\n",
    "  cur_valid_dataset = Subset(train_dataset, valid_indices)\n",
    "  train_loader = DataLoader(cur_train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "  valid_loader = DataLoader(cur_valid_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "  max_iou = 0\n",
    "  print(len(cur_train_dataset), len(cur_valid_dataset))\n",
    "  for epoch in range(num_epochs):\n",
    "      # Training\n",
    "      start_time = time.time()\n",
    "      train_metrics = train_epoch(model, metrics, optimizer, DEVICE, train_loader)\n",
    "      print(f'=========Finished Training Epoch {epoch} in {float(time.time()-start_time)/60}==========')\n",
    "      # Validation\n",
    "      start_time = time.time()\n",
    "      valid_metrics = valid_epoch(model, metrics, DEVICE, valid_loader)\n",
    "      print(f'=========Finished Validation Epoch {epoch} {float(time.time()-start_time)/60}in =========')\n",
    "\n",
    "      cur_validation_iou = 0.5*valid_metrics[1][0] + 0.5*valid_metrics[1][1]\n",
    "      if cur_validation_iou > max_iou:\n",
    "        print(f'Saving model with IoU: {cur_validation_iou}...')\n",
    "        torch.save(model, f'./models/best_model_unet_dataset1_fold_{i}.pth')\n",
    "        with open(f'./models/best_model_unet_dataset1_fold_{i}.txt', 'w') as f:\n",
    "          f.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "        max_iou = cur_validation_iou\n",
    "      # Print or log the metrics for each epoch\n",
    "      print(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "      with open(f'./models/model_stats_unet_dataset1_fold_{i}.txt', 'a') as fp:\n",
    "        fp.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\\n\")\n",
    "        fp.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95fffd9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T03:57:27.265083Z",
     "iopub.status.busy": "2023-06-07T03:57:27.264623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a total of 409 batches in training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x7f238c57b7d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rmahajani31/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/tqdm/std.py\", line 1179, in __iter__\n",
      "    yield obj\n",
      "  File \"/home/rmahajani31/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 681) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "0it [00:08, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 13\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=========Finished Training Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==========\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Validation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 18\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, metrics, optimizer, device, dataloader, class_weights)\u001b[0m\n\u001b[1;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#         print(f'input and output shapes: {inputs.shape}, {outputs.shape}, {targets.shape}')\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         print(f'Outputs min: {torch.min(outputs)}, Outputs max: {torch.max(outputs)}')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         loss \u001b[38;5;241m=\u001b[39m dice_loss(outputs, targets, class_weights)\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/segmentation_models_pytorch/base/model.py:29\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sequentially pass `x` trough model`s encoder, decoder and heads\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m---> 29\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[1;32m     32\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/segmentation_models_pytorch/encoders/efficientnet.py:73\u001b[0m, in \u001b[0;36mEfficientNetEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     71\u001b[0m             drop_connect \u001b[38;5;241m=\u001b[39m drop_connect_rate \u001b[38;5;241m*\u001b[39m block_number \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks)\n\u001b[1;32m     72\u001b[0m             block_number \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 73\u001b[0m             x \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_connect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/efficientnet_pytorch/model.py:109\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    106\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn0(x)\n\u001b[1;32m    107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(x)\n\u001b[0;32m--> 109\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depthwise_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bn1(x)\n\u001b[1;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swish(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/HubMapEnv/lib/python3.10/site-packages/efficientnet_pytorch/utils.py:275\u001b[0m, in \u001b[0;36mConv2dStaticSamePadding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    274\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatic_padding(x)\n\u001b[0;32m--> 275\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## This is a block to run training without cross validation\n",
    "import time\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "max_iou = 0\n",
    "num_epochs = 50\n",
    "if os.path.exists('./models/model_stats_unet_dataset1.txt'):\n",
    "  os.remove('./models/model_stats_unet_dataset1.txt')\n",
    "fp = open('./models/model_stats_unet_dataset1.txt', 'a')\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    start_time = time.time()\n",
    "    train_metrics = train_epoch(model, metrics, optimizer, DEVICE, train_loader)\n",
    "    print(f'=========Finished Training Epoch {epoch} in {float(time.time()-start_time)/60}==========')\n",
    "    # Validation\n",
    "    start_time = time.time()\n",
    "    valid_metrics = valid_epoch(model, metrics, DEVICE, valid_loader)\n",
    "    print(f'=========Finished Validation Epoch {epoch} {float(time.time()-start_time)/60}in =========')\n",
    "    \n",
    "    save_interval = 10\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model, f'./models/model_{epoch}_unet_dataset1.pth')\n",
    "    \n",
    "    cur_validation_iou = 0.5*valid_metrics[1][0] + 0.5*valid_metrics[1][1]\n",
    "    if cur_validation_iou > max_iou:\n",
    "      print(f'Saving model with IoU: {cur_validation_iou}...')\n",
    "      torch.save(model, './models/best_model_unet_dataset1.pth')\n",
    "      with open('./models/best_model_unet_dataset1.txt', 'w') as f:\n",
    "        f.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "      max_iou = cur_validation_iou\n",
    "    # Print or log the metrics for each epoch\n",
    "    print(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\")\n",
    "    fp.write(f\"Epoch {epoch}: Train Loss={train_metrics[0]}, Validation Loss={valid_metrics[0]}, Train IoU Back={train_metrics[1][0]}, Train IoU Fore={train_metrics[1][1]}, Validation IoU Back={valid_metrics[1][0]}, Validation IoU Fore={valid_metrics[1][1]}\\n\")\n",
    "    fp.flush()\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb3273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HubMapEnv",
   "language": "python",
   "name": "hubmapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
