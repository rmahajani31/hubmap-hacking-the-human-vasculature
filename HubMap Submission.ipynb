{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdba8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as BaseDataset\n",
    "import albumentations as albu\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "import base64\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5947d34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29ad2d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './'\n",
    "\n",
    "x_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "y_test_dir = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "suffix = 'test_real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d098c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa94c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HubMapDataset(BaseDataset):\n",
    "    \"\"\"Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['unlabelled', 'blood_vessel']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return self.images_fps[i], image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "591ec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_augmentation():\n",
    "    train_transform = [\n",
    "\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "\n",
    "        albu.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
    "\n",
    "        albu.PadIfNeeded(min_height=512, min_width=352, always_apply=True, border_mode=0),\n",
    "        albu.RandomCrop(height=512, width=352, always_apply=True),\n",
    "\n",
    "        albu.GaussNoise(p=0.2),\n",
    "        albu.Perspective(p=0.5),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.CLAHE(p=1),\n",
    "                albu.RandomBrightnessContrast(p=1),\n",
    "                albu.RandomGamma(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.Sharpen(p=1),\n",
    "                albu.Blur(blur_limit=3, p=1),\n",
    "                albu.MotionBlur(blur_limit=3, p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.RandomBrightnessContrast(p=1),\n",
    "                albu.HueSaturationValue(p=1),\n",
    "            ],\n",
    "            p=0.9,\n",
    "        ),\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        albu.PadIfNeeded(512, 512)\n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')\n",
    "\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        albu.Lambda(image=preprocessing_fn),\n",
    "        albu.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ]\n",
    "    return albu.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2e8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['unlabelled', 'blood_vessel']\n",
    "ENCODER = 'efficientnet-b7'\n",
    "ENCODER_WEIGHTS = 'imagenet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba29c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "602f68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "from collections import OrderedDict\n",
    "data_parallel_model = True\n",
    "model_path = './models/unet-dataset1-batch-size-8-models/best_model_unet_dataset1.pth'\n",
    "if data_parallel_model:\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    checkpoint_state = checkpoint.state_dict()\n",
    "    modified_checkpoint_state = OrderedDict()\n",
    "    for key, value in checkpoint_state.items():\n",
    "      new_key = key[len('module.'):]\n",
    "      modified_checkpoint_state[new_key] = value\n",
    "    best_model = torch.load('./models/starter_model.pth', map_location=torch.device('cpu'))\n",
    "    best_model.load_state_dict(modified_checkpoint_state)\n",
    "    best_model = best_model.to(DEVICE)\n",
    "else:\n",
    "    best_model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    best_model = best_model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69218f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['unlabelled', 'blood_vessel']\n",
    "test_dataset = HubMapDataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    "    classes=CLASSES,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad3713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import base64\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import zlib\n",
    "\n",
    "def extract_polygon_masks(mask):\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    masks = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        epsilon = 0.01 * cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        if approx.shape[0] >= 3:\n",
    "            polygon_mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(polygon_mask, [approx], 0, 1, -1)\n",
    "            masks.append(polygon_mask.astype('bool'))\n",
    "    \n",
    "    return masks\n",
    "\n",
    "def encode_binary_mask(mask: np.ndarray) -> t.Text:\n",
    "  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "\n",
    "  # check input mask --\n",
    "  if mask.dtype != np.bool_:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n",
    "        mask.dtype)\n",
    "\n",
    "  mask = np.squeeze(mask)\n",
    "  if len(mask.shape) != 2:\n",
    "    raise ValueError(\n",
    "        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n",
    "        mask.shape)\n",
    "  \n",
    "  # convert input mask to expected COCO API input --\n",
    "  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "  mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "  mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "  # RLE encode mask --\n",
    "  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "  # compress and base64 encoding --\n",
    "  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "  base64_str = base64.b64encode(binary_str)\n",
    "  return base64_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14bff0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_submission(model, device, dataloader, suffix):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    print(f'Processing a total of {num_batches} images for submission')\n",
    "    submission_dicts = []\n",
    "    start_time = time.time()\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the validation dataset\n",
    "        for batch_idx, (img_file, inputs, targets) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            softmaxed_outputs = torch.softmax(outputs, dim=1)\n",
    "            outputs = softmaxed_outputs[:,1,:,:].numpy()\n",
    "            outputs_thresh = (outputs > 0.5).astype('uint8')\n",
    "            for i in range(len(outputs_thresh)):\n",
    "              cur_dict = dict()\n",
    "              img_id = img_file[i].split('/')[-1].split('.')[0]\n",
    "              cur_dict['id'] = img_id\n",
    "              cur_dict['height'] = 512\n",
    "              cur_dict['width'] = 512\n",
    "              prediction_string = ''\n",
    "              polygon_masks = extract_polygon_masks(outputs_thresh[i,:,:])\n",
    "              for polygon_mask in polygon_masks:\n",
    "                polygon_mask_conf = round(((polygon_mask * outputs[i,:,:]).sum())/(polygon_mask.sum()), 2)\n",
    "                polygon_mask_string = encode_binary_mask(polygon_mask.astype('bool')).decode('utf-8')\n",
    "                prediction_string += f'0 {polygon_mask_conf} {polygon_mask_string} '\n",
    "              cur_dict['prediction_string'] = prediction_string.strip()\n",
    "              submission_dicts.append(cur_dict)\n",
    "            if batch_idx % 10 == 0:\n",
    "              print(f'On batch {batch_idx} and finished in {float(time.time()-start_time)/60} minutes')\n",
    "        submission_df = pd.DataFrame.from_dict(submission_dicts)\n",
    "        submission_df.to_csv(f'./submissions/submission_{suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af55f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./submissions'):\n",
    "  os.mkdir('./submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3d440d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing a total of 1 images for submission\n",
      "On batch 0 and finished in 0.028425848484039305 minutes\n"
     ]
    }
   ],
   "source": [
    "generate_submission(best_model, DEVICE, test_loader, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ground_truth_map_files(tiles_dicts_new, x_test_dir, suffix):\n",
    "  bbox_dicts = []\n",
    "  segfile_dicts = []\n",
    "  labels_info = set()\n",
    "  img_width = 512\n",
    "  img_height = 512\n",
    "  print(f'Processing a total of {len(tiles_dicts_new)} tiles')\n",
    "  start_time = time.time()\n",
    "  for idx, tiles_dict in enumerate(tiles_dicts_new):\n",
    "    img_id = tiles_dict['id']\n",
    "    base_image = cv2.imread(f'{x_test_dir}/{img_id}.png')\n",
    "    for annot in tiles_dict['annotations']:\n",
    "      if annot['type'] == 'blood_vessel':\n",
    "        blood_vessel_masked_image = np.zeros((512, 512))\n",
    "        cur_dict = dict()\n",
    "        cur_segfile_dict = dict()\n",
    "        cur_dict['ImageID'] = img_id\n",
    "        cur_dict['LabelName'] = annot['type']\n",
    "        coords = annot['coordinates'][0]\n",
    "        cv2.fillPoly(blood_vessel_masked_image, pts=[np.array(coords)], color=1)\n",
    "        encoded_mask = encode_binary_mask(blood_vessel_masked_image.astype('bool')).decode('utf-8')\n",
    "        x_vals = [x[0] for x in coords]\n",
    "        y_vals = [x[1] for x in coords]\n",
    "        x_min = float(min(x_vals))/img_width\n",
    "        x_max = float(max(x_vals))/img_width\n",
    "        y_min = float(min(y_vals))/img_height\n",
    "        y_max = float(max(y_vals))/img_height\n",
    "        cur_dict['XMin'] = x_min\n",
    "        cur_dict['XMax'] = x_max\n",
    "        cur_dict['YMin'] = y_min\n",
    "        cur_dict['YMax'] = y_max\n",
    "        cur_dict['IsGroupOf'] = 0\n",
    "        cur_segfile_dict['ImageID'] = img_id\n",
    "        cur_segfile_dict['LabelName'] = annot['type']\n",
    "        cur_segfile_dict['ImageWidth'] = img_width\n",
    "        cur_segfile_dict['ImageHeight'] = img_height\n",
    "        cur_segfile_dict['XMin'] = x_min\n",
    "        cur_segfile_dict['XMax'] = x_max\n",
    "        cur_segfile_dict['YMin'] = y_min\n",
    "        cur_segfile_dict['YMax'] = y_max\n",
    "        cur_segfile_dict['IsGroupOf'] = 0\n",
    "        cur_segfile_dict['Mask'] = encoded_mask\n",
    "        bbox_dicts.append(cur_dict)\n",
    "        segfile_dicts.append(cur_segfile_dict)\n",
    "        cur_labels_info = (img_id, annot['type'], 1)\n",
    "        if cur_labels_info not in labels_info:\n",
    "          labels_info.add(cur_labels_info)\n",
    "    if idx % 50 == 0:\n",
    "      print(f'Finished {idx} tiles in {float(time.time()-start_time)/60} minutes')\n",
    "  bbox_dicts_df = pd.DataFrame.from_dict(bbox_dicts)\n",
    "  bbox_dicts_df.to_csv(f'./map_input_data/segmentation_bbox_{suffix}.csv', index=False)\n",
    "  labels_info_df = pd.DataFrame(list(labels_info), columns=['ImageID', 'LabelName', 'Confidence'])\n",
    "  labels_info_df.to_csv(f'./map_input_data/segmentation_labels_{suffix}.csv', index=False)\n",
    "  segfile_df = pd.DataFrame.from_dict(segfile_dicts)\n",
    "  segfile_df.to_csv(f'./map_input_data/segmentation_masks_{suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a01cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./map_input_data'):\n",
    "  os.mkdir('./map_input_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a64f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeaf532",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_ids = [x.split('.')[0] for x in os.listdir(x_test_dir)]\n",
    "tiles_dicts_new = [x for x in tiles_dicts if x['id'] in tgt_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ground_truth_map_files(tiles_dicts_new, x_test_dir, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08285800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_parts(pred_string):\n",
    "  pred_parts = pred_string.split()\n",
    "  pred_parts_arr = []\n",
    "  for i in range(0, len(pred_parts), 3):\n",
    "    pred_parts_arr.append(pred_parts[i:i+3])\n",
    "  return pred_parts_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prediction_map_file(submission_df, suffix):\n",
    "  non_empty_pred_mask = submission_df.apply(lambda x: x['prediction_string']!='', axis=1)\n",
    "  submission_df = submission_df[non_empty_pred_mask].dropna(subset=['prediction_string'], axis=0)\n",
    "  submission_df = submission_df.rename(columns={'id': 'ImageID', 'height': 'ImageHeight', 'width': 'ImageWidth'})\n",
    "  submission_df['prediction_string'] = submission_df['prediction_string'].apply(create_pred_parts)\n",
    "  submission_df = submission_df.explode('prediction_string')\n",
    "  submission_df[['LabelName', 'Score', 'Mask']] = submission_df['prediction_string'].apply(pd.Series)\n",
    "  submission_df['LabelName'] = submission_df['LabelName'].astype(str).replace('0', 'blood_vessel')\n",
    "  submission_df = submission_df.drop('prediction_string', axis=1)\n",
    "  submission_df.to_csv(f'./map_input_data/seg_preds_{suffix}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ebc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(f'./submissions/submission_{suffix}.csv')\n",
    "generate_prediction_map_file(submission_df, suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ab776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HubMapEnv",
   "language": "python",
   "name": "hubmapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
