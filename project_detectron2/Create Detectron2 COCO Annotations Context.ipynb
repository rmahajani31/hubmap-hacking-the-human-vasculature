{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93399e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "base_path = '../'\n",
    "input_imgs_dir = f'{base_path}/all_dataset_files/all_dataset_imgs'\n",
    "input_masks_dir = f'{base_path}/all_dataset_files/all_dataset_masks'\n",
    "input_annots_dir = f'{base_path}/all_dataset_files/all_dataset_annotations'\n",
    "vis_output_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_vis'\n",
    "\n",
    "if not os.path.exists(vis_output_imgs_dir):\n",
    "  os.mkdir(vis_output_imgs_dir)\n",
    "\n",
    "modes = ['train', 'validation', 'validation_custom']\n",
    "\n",
    "for i in range(num_folds):\n",
    "  for mode in modes:\n",
    "    output_imgs_dir_fold = f'{base_path}/dataset1_files/all_dataset1_{mode}_imgs_context_fold_{i}' if mode != 'validation_custom' else f'{base_path}/dataset1_files/all_dataset1_validation_imgs_context_fold_{i}'\n",
    "    output_annots_dir_fold = f'{base_path}/dataset1_files/all_dataset1_{mode}_annotations_context_fold_{i}'\n",
    "    if not os.path.exists(output_imgs_dir_fold):\n",
    "      os.mkdir(output_imgs_dir_fold)\n",
    "    if not os.path.exists(output_annots_dir_fold):\n",
    "      os.mkdir(output_annots_dir_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coordinates):\n",
    "    num_points = len(coordinates)\n",
    "    if num_points < 3:\n",
    "        return 0\n",
    "\n",
    "    area = 0\n",
    "    for i in range(num_points - 1):\n",
    "        x_i, y_i = coordinates[i]\n",
    "        x_iplus1, y_iplus1 = coordinates[i + 1]\n",
    "        area += (x_i * y_iplus1) - (x_iplus1 * y_i)\n",
    "\n",
    "    x_n, y_n = coordinates[-1]\n",
    "    x_0, y_0 = coordinates[0]\n",
    "    area += (x_n * y_0) - (x_0 * y_n)\n",
    "\n",
    "    area = abs(area / 2)\n",
    "    return area\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0746f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e29f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8dab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = tile_df_annotated.loc[tile_df_annotated['dataset']==1]\n",
    "dataset_1_tile_ids = sorted(dataset_1.loc[:, 'id'].values)\n",
    "dataset_1_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[dataset_1['source_wsi']==1, ['i', 'j', 'id']].values}\n",
    "dataset_1_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[dataset_1['source_wsi']==2, ['i', 'j', 'id']].values}\n",
    "reverse_dataset_1_wsi_1_pos_dict = {v:k for k,v in dataset_1_wsi_1_pos_dict.items()}\n",
    "reverse_dataset_1_wsi_2_pos_dict = {v:k for k,v in dataset_1_wsi_2_pos_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb461124",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = tile_df_annotated.loc[tile_df_annotated['dataset']==2]\n",
    "dataset_2_tile_ids = sorted(dataset_2.loc[:, 'id'].values)\n",
    "dataset_2_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_2.loc[dataset_2['source_wsi']==1, ['i', 'j', 'id']].values}\n",
    "dataset_2_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_2.loc[dataset_2['source_wsi']==2, ['i', 'j', 'id']].values}\n",
    "reverse_dataset_2_wsi_1_pos_dict = {v:k for k,v in dataset_2_wsi_1_pos_dict.items()}\n",
    "reverse_dataset_2_wsi_2_pos_dict = {v:k for k,v in dataset_2_wsi_2_pos_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf90c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "## Below is the code to create variability by merging adjacent tiles\n",
    "def get_relevant_annots(tgt_tile_dicts):\n",
    "  final_tile_dicts = dict()\n",
    "  for tile_dict in tgt_tile_dicts:\n",
    "    img_id = tile_dict['id']\n",
    "    final_annots = []\n",
    "    for annot in tile_dict['annotations']:\n",
    "      if annot['type'] == 'blood_vessel':\n",
    "        final_annots.append(annot['coordinates'][0])\n",
    "    final_tile_dicts[img_id] = final_annots\n",
    "  return final_tile_dicts\n",
    "def get_adjacent_tiles(i, j, img_id, adjacent_tile_dict, dataset_1_pos_dict):\n",
    "  adjacent_tile_dict[img_id] = dict()\n",
    "  keys = ['U', 'B', 'L', 'R', 'BL', 'BR', 'TL', 'TR']\n",
    "  for k in keys:\n",
    "    tgt_img_id = None\n",
    "    if k == 'U':\n",
    "      pos_to_check = (i, j-512)\n",
    "    elif k == 'B':\n",
    "      pos_to_check = (i, j+512)\n",
    "    elif k == 'L':\n",
    "      pos_to_check = (i-512, j)\n",
    "    elif k == 'R':\n",
    "      pos_to_check = (i+512, j)\n",
    "    elif k == 'BL':\n",
    "      pos_to_check = (i-512, j+512)\n",
    "    elif k == 'BR':\n",
    "      pos_to_check = (i+512, j+512)\n",
    "    elif k == 'TL':\n",
    "      pos_to_check = (i-512, j-512)\n",
    "    elif k == 'TR':\n",
    "      pos_to_check = (i+512, j-512)\n",
    "    if pos_to_check in dataset_1_pos_dict:\n",
    "      tgt_img_id = dataset_1_pos_dict[pos_to_check]\n",
    "    adjacent_tile_dict[img_id][k] = tgt_img_id\n",
    "  return adjacent_tile_dict\n",
    "def single_shift_polygon(seg_array_1, seg_array_2, shifting_threshold, shift_type, border_eps=1):\n",
    "    polygon_regions = []\n",
    "    num_polygons_1 = len(seg_array_1)\n",
    "    num_polygons_2 = len(seg_array_2)\n",
    "    \n",
    "    combined_array_1 = []\n",
    "    combined_array_2 = []\n",
    "    for i in range(num_polygons_1):\n",
    "        polygon_1 = seg_array_1[i]\n",
    "        new_polygon = []\n",
    "        for point in polygon_1:\n",
    "            x, y = point\n",
    "            if shift_type == 'R':\n",
    "              if x >= math.ceil(shifting_threshold*512):\n",
    "                  new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "                  new_y = y\n",
    "                  new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'B':\n",
    "              if y >= math.ceil(shifting_threshold*512):\n",
    "                new_x = x\n",
    "                new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'L':\n",
    "              if x <= math.floor((1-shifting_threshold)*512):\n",
    "                new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "                new_y = y\n",
    "                new_polygon.append([new_x, new_y])\n",
    "        if len(new_polygon) > 0:\n",
    "          combined_array_1.append(new_polygon)\n",
    "    \n",
    "    polygon_regions.append(combined_array_1)\n",
    "    \n",
    "    for i in range(num_polygons_2):\n",
    "        polygon_2 = seg_array_2[i]\n",
    "        new_polygon = []\n",
    "        for point in polygon_2:\n",
    "            x, y = point\n",
    "            if shift_type == 'R':\n",
    "              if x <= math.ceil(shifting_threshold*512):\n",
    "                new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "                new_y = y\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'B':\n",
    "              if y <= math.ceil(shifting_threshold*512):\n",
    "                new_x = x\n",
    "                new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'L':\n",
    "              if x >= math.floor((1-shifting_threshold)*512):\n",
    "                  new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "                  new_y = y\n",
    "                  new_polygon.append([new_x, new_y])\n",
    "        if len(new_polygon) > 0:\n",
    "          combined_array_2.append(new_polygon)\n",
    "    \n",
    "    polygon_regions.append(combined_array_2)\n",
    "    \n",
    "    return polygon_regions\n",
    "\n",
    "def double_shift_polygon(seg_array_1, seg_array_2, seg_array_3, seg_array_4, shifting_threshold, shift_type, border_eps=1):\n",
    "  polygon_regions = []\n",
    "  num_polygons_1 = len(seg_array_1)\n",
    "  num_polygons_2 = len(seg_array_2)\n",
    "  num_polygons_3 = len(seg_array_3)\n",
    "  num_polygons_4 = len(seg_array_4)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_1):\n",
    "    polygon_1 = seg_array_1[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_1:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x >= math.ceil(shifting_threshold*512) and y >= math.ceil(shifting_threshold*512):\n",
    "              new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "              new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "              new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x <= math.floor((1-shifting_threshold)*512) and y >= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_2):\n",
    "    polygon_2 = seg_array_2[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_2:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x <= math.ceil(shifting_threshold*512) and y >= math.ceil(shifting_threshold*512):\n",
    "              new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "              new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "              new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x >= math.floor((1-shifting_threshold)*512) and y >= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "    \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_3):\n",
    "    polygon_3 = seg_array_3[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_3:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x >= math.ceil(shifting_threshold*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x <= math.floor((1-shifting_threshold)*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_4):\n",
    "    polygon_4 = seg_array_4[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_4:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x <= math.ceil(shifting_threshold*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x >= math.floor((1-shifting_threshold)*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  return polygon_regions\n",
    "\n",
    "def check_polygon_border(pt, border_eps=1):\n",
    "  return pt[0] <= border_eps or pt[0] >= 512-border_eps or pt[1] <= border_eps or pt[1] >= 512-border_eps\n",
    "\n",
    "def single_shift_img(img_1, img_2, shifting_threshold, shift_type):\n",
    "    height, width, _ = img_1.shape\n",
    "    \n",
    "    if shift_type == 'R':\n",
    "      img_1_part = img_1[:, int(math.ceil(shifting_threshold*width)):, :]\n",
    "      img_2_part = img_2[:, :int(math.ceil(shifting_threshold*width)), :]\n",
    "      combined_image = cv2.hconcat([img_1_part, img_2_part])\n",
    "    elif shift_type == 'B':\n",
    "      img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, :, :]\n",
    "      img_2_part = img_2[:int(math.ceil(shifting_threshold*height)), :, :]\n",
    "      combined_image = cv2.vconcat([img_1_part, img_2_part])\n",
    "    else:\n",
    "      img_1_part = img_1[:, :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "      img_2_part = img_2[:, int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "      combined_image = cv2.hconcat([img_2_part, img_1_part])\n",
    "    return combined_image\n",
    "\n",
    "def double_shift_img(img_1, img_2, img_3, img_4, shifting_threshold, shift_type):\n",
    "  height, width, _ = img_1.shape\n",
    "  if shift_type == 'BR':\n",
    "    img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, int(math.ceil(shifting_threshold*width)):, :]\n",
    "    img_2_part = img_2[int(math.ceil(shifting_threshold*height)):, :int(math.ceil(shifting_threshold*width)), :]\n",
    "    img_3_part = img_3[:int(math.ceil(shifting_threshold*height)), int(math.ceil(shifting_threshold*width)):, :]\n",
    "    img_4_part = img_4[:int(math.ceil(shifting_threshold*height)), :int(math.ceil(shifting_threshold*width)), :]\n",
    "    image_top = cv2.hconcat([img_1_part, img_2_part])\n",
    "    image_bottom = cv2.hconcat([img_3_part, img_4_part])\n",
    "    combined_image = cv2.vconcat([image_top, image_bottom])\n",
    "  else:\n",
    "    img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "    img_2_part = img_2[int(math.ceil(shifting_threshold*height)):, int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "    img_3_part = img_3[:int(math.ceil(shifting_threshold*height)), :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "    img_4_part = img_4[:int(math.ceil(shifting_threshold*height)), int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "    image_top = cv2.hconcat([img_2_part, img_1_part])\n",
    "    image_bottom = cv2.hconcat([img_4_part, img_3_part])\n",
    "    combined_image = cv2.vconcat([image_top, image_bottom])\n",
    "  return combined_image\n",
    "\n",
    "def load_img(img_dir, img_id, is_grayscale=False):\n",
    "  if not is_grayscale:\n",
    "    img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  else:\n",
    "    img = cv2.imread(f\"{img_dir}/{img_id}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "  return img\n",
    "\n",
    "def add_border(image, border_size, border_color):\n",
    "    height, width = image.shape[:2]\n",
    "    new_height = height + 2 * border_size\n",
    "    new_width = width + 2 * border_size\n",
    "    bordered_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "    bordered_image[border_size:height + border_size, border_size:width + border_size] = image\n",
    "    cv2.rectangle(bordered_image, (0, 0), (new_width - 1, new_height - 1), border_color, border_size)\n",
    "    return bordered_image\n",
    "\n",
    "def create_coco_annots(all_coords, pair_format=True):\n",
    "  cur_tile_coco_annots = []\n",
    "  for coords in all_coords:\n",
    "#     print('======================')\n",
    "#     print(coords)\n",
    "#     print('======================')\n",
    "    if not pair_format:\n",
    "      coords = [[pt[0], pt[1]] for pt in zip(coords[::2], coords[1::2])]\n",
    "    segmentations = [[pt for pair in coords for pt in pair]]\n",
    "    segmentation_area = calculate_area(coords)\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    segmentation_bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "    category_id = 0\n",
    "    cur_tile_coco_annots.append({\n",
    "      'segmentation': segmentations,\n",
    "      'area': segmentation_area,\n",
    "      'bbox': segmentation_bbox,\n",
    "      'category_id': category_id\n",
    "    })\n",
    "  return cur_tile_coco_annots\n",
    "\n",
    "def save_merged_imgs(input_imgs_dir, output_imgs_dir, base_img_id, base_img_dict, shifting_thresholds):\n",
    "  img_arr_dict = {'base_img': load_img(input_imgs_dir, base_img_id)}\n",
    "  cv2.imwrite(f'{output_imgs_dir}/{base_img_id}.png', img_arr_dict['base_img'])\n",
    "  for shift_type in base_img_dict.keys():\n",
    "    if base_img_dict[shift_type] is not None:\n",
    "      img_arr_dict[shift_type] = load_img(input_imgs_dir, base_img_dict[shift_type])\n",
    "    else:\n",
    "      img_arr_dict[shift_type] = None\n",
    "  for shifting_threshold in shifting_thresholds:\n",
    "    for shift_type in img_arr_dict:\n",
    "      if img_arr_dict[shift_type] is not None:\n",
    "        if shift_type in ['R', 'B']:\n",
    "          shifted_img = single_shift_img(img_arr_dict['base_img'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type} and shifting threshold: {shifting_threshold}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "        elif shift_type == 'BR' and img_arr_dict['B'] is not None and img_arr_dict['R'] is not None:\n",
    "          shifted_img = double_shift_img(img_arr_dict['base_img'], img_arr_dict['R'], img_arr_dict['B'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "        elif shift_type == 'BL' and img_arr_dict['B'] is not None and img_arr_dict['L'] is not None:\n",
    "          shifted_img = double_shift_img(img_arr_dict['base_img'], img_arr_dict['L'], img_arr_dict['B'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "\n",
    "def save_merged_annotations(output_annots_dir, base_img_id, base_img_dict, shifting_thresholds, tgt_tile_dicts):\n",
    "  print(f'base image id: {base_img_id}')\n",
    "  cur_tile_annots = create_coco_annots(tgt_tile_dicts[base_img_id])\n",
    "  with open(f'{output_annots_dir}/{base_img_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(cur_tile_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  for shifting_threshold in shifting_thresholds:\n",
    "    for shift_type in base_img_dict:\n",
    "      if base_img_dict[shift_type] is not None:\n",
    "        if shift_type in ['R', 'B']:\n",
    "          polygon_regions = single_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "#           print(f'===========after single shift - {len(polygon_regions)}============')\n",
    "#           print(polygon_regions)\n",
    "#           print('===========after single shift============')\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========after polyon merge - {len(shifted_coords)}============')\n",
    "#           print(shifted_coords)\n",
    "#           print('===========after polyon merge============')\n",
    "#           print(f'===========merged coords shift type R B===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type R B===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "#           print(f'===========after coco - {len(shifted_coords)}============')\n",
    "#           print(shifted_annots)\n",
    "#           print('===========after coco============')\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        elif shift_type == 'BR' and base_img_dict['B'] is not None and base_img_dict['R'] is not None:\n",
    "          polygon_regions = double_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict['R']], tgt_tile_dicts[base_img_dict['B']], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========merged coords shift type BR===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type BR===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        elif shift_type == 'BL' and base_img_dict['B'] is not None and base_img_dict['L'] is not None:\n",
    "          polygon_regions = double_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict['L']], tgt_tile_dicts[base_img_dict['B']], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========merged coords shift type BL===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type BL===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_annotated_img(imgs_dir, annots_dir, base_img_id):\n",
    "  eps = 1\n",
    "  annotated_image_coco = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = annotated_image_coco.shape\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  for tgt_annot in tgt_annots:\n",
    "    coords = [[x, y] for x, y in zip(tgt_annot['segmentation'][0][::2], tgt_annot['segmentation'][0][1::2])]\n",
    "    min_x, min_y, width, height = tgt_annot['bbox']\n",
    "    cv2.fillPoly(annotated_image_coco, pts=[np.array(coords)], color=(0,255,0))\n",
    "    top_left = (int(tgt_annot['bbox'][0]), int(tgt_annot['bbox'][1]))\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    bottom_right = (int(tgt_annot['bbox'][0]+tgt_annot['bbox'][2]), int(tgt_annot['bbox'][1]+tgt_annot['bbox'][3]))\n",
    "#     if min_x <= eps or max_x >= img_width-eps or min_y <= eps or max_y >= img_height-eps:\n",
    "#       annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "    annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "  annotated_image_coco = add_border(annotated_image_coco, 5, (0,0,255))\n",
    "  return annotated_image_coco\n",
    "\n",
    "def get_polygon_merged_annotated_img(imgs_dir, annots_dir, base_img_id):\n",
    "  eps = 1\n",
    "  annotated_image_coco = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = annotated_image_coco.shape\n",
    "  annotated_image_mask = np.zeros((img_height,img_width))\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  all_polygons = [x for tgt_annot in tgt_annots for x in tgt_annot['segmentation']]\n",
    "#   all_polygons = merge_connected_polygons(all_polygons, 1)\n",
    "  for polygon in all_polygons:\n",
    "    coords = [[x, y] for x, y in zip(polygon[::2], polygon[1::2])]\n",
    "    cv2.fillPoly(annotated_image_mask, pts=[np.array(coords)], color=255)\n",
    "  merged_polygons = get_segmentation_coordinates(annotated_image_mask)\n",
    "  for merged_polygon in merged_polygons:\n",
    "    coords = [[x, y] for x, y in zip(merged_polygon[::2], merged_polygon[1::2])]\n",
    "    cv2.fillPoly(annotated_image_coco, pts=[np.array(coords)], color=(0,255,0))\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    top_left = (int(min_x), int(min_y))\n",
    "    bottom_right = (int(max_x), int(max_y))\n",
    "#     if min_x <= eps or max_x >= img_width-eps or min_y <= eps or max_y >= img_height-eps:\n",
    "#       annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "    annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "  annotated_image_coco = add_border(annotated_image_coco, 5, (0,0,255))\n",
    "  return annotated_image_coco\n",
    "\n",
    "def get_polygon_merged_coords(polygons_regions, epsilon=1):\n",
    "  merged_polygons = group_merged_polygons(polygons_regions, epsilon=epsilon)\n",
    "  final_segmentation_coords = []\n",
    "  \n",
    "  for merged_polygon in merged_polygons:\n",
    "    annotated_image_mask = np.zeros((512,512))\n",
    "    for coords in merged_polygon:\n",
    "      cv2.fillPoly(annotated_image_mask, pts=[np.array(coords)], color=255)\n",
    "#     plt.imshow(annotated_image_mask)\n",
    "#     plt.show()\n",
    "    final_segmentation_coords += get_segmentation_coordinates(annotated_image_mask)\n",
    "  \n",
    "  return final_segmentation_coords\n",
    "  \n",
    "import math\n",
    "\n",
    "def group_merged_polygons(regions, epsilon):\n",
    "    merged_groups = []\n",
    "    \n",
    "    def merge_polygons(poly1, poly2):\n",
    "        return poly1 + poly2\n",
    "    \n",
    "    def distance(point1, point2):\n",
    "        return math.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "    \n",
    "    def are_polygons_close(poly1, poly2):\n",
    "        for p1 in poly1:\n",
    "            for p2 in poly2:\n",
    "                if distance(p1, p2) <= epsilon:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    for region_index, region in enumerate(regions):\n",
    "        for polygon in region:\n",
    "            merged = False\n",
    "            for group in merged_groups:\n",
    "                if (not any(region_index == group_region_idx for group_region_idx, _ in group)) and any(are_polygons_close(polygon, poly) for _, poly in group):\n",
    "                    group.append([region_index, polygon])\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_groups.append([[region_index, polygon]])\n",
    "    \n",
    "    merged_polygons = []\n",
    "    for group in merged_groups:\n",
    "        polygon_group = []\n",
    "        for _, polygon in group:\n",
    "          polygon_group.append(polygon)\n",
    "        merged_polygons.append(polygon_group)\n",
    "    return merged_polygons\n",
    "\n",
    "\n",
    "def get_segmentation_coordinates(mask):\n",
    "    mask = np.uint8(mask)\n",
    "    \n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Extract segmentation coordinates from the contours\n",
    "    segmentation_coords = []\n",
    "    for contour in contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        coords = contour.flatten().tolist()\n",
    "        segmentation_coords.append(coords)\n",
    "\n",
    "    return segmentation_coords\n",
    "\n",
    "def save_merged_img_id_with_annot(output_imgs_dir, output_annots_dir, vis_output_imgs_dir, base_img_id, base_img_dict, shifting_thresholds):\n",
    "  img_arr_dict = {'base_image': get_annotated_img(output_imgs_dir, output_annots_dir, base_img_id)}\n",
    "  for shift_type in base_img_dict.keys():\n",
    "    if base_img_dict[shift_type] is not None:\n",
    "      img_arr_dict[shift_type] = get_annotated_img(output_imgs_dir, output_annots_dir, base_img_dict[shift_type])\n",
    "    else:\n",
    "      img_arr_dict[shift_type] = add_border((np.zeros((512, 512, 3), dtype=\"uint8\")), 5, (0,0,255))\n",
    "  image_top = cv2.hconcat([img_arr_dict['L'], img_arr_dict['base_image'], img_arr_dict['R']])\n",
    "  print(img_arr_dict['BL'].shape, img_arr_dict['B'].shape, img_arr_dict['BR'].shape)\n",
    "  image_bottom = cv2.hconcat([img_arr_dict['BL'], img_arr_dict['B'], img_arr_dict['BR']])\n",
    "  image_full = cv2.vconcat([image_top, image_bottom])\n",
    "  cv2.imwrite(f'{vis_output_imgs_dir}/{base_img_id}_full_annotated.png', image_full)\n",
    "  all_merged_img_ids = [x.split('.png')[0] for x in os.listdir(output_imgs_dir) if base_img_id in x and x != f'{base_img_id}.png']\n",
    "  for merged_img_id in all_merged_img_ids:\n",
    "    merged_annotated_img = get_annotated_img(output_imgs_dir, output_annots_dir, merged_img_id)\n",
    "    cv2.imwrite(f'{vis_output_imgs_dir}/{merged_img_id}_full_annotated.png', merged_annotated_img)\n",
    "#     polygon_merged_annotated_img = get_polygon_merged_annotated_img(output_imgs_dir, output_annots_dir, merged_img_id)\n",
    "#     cv2.imwrite(f'{vis_output_imgs_dir}/{merged_img_id}_full_annotated_polygon_merged.png', polygon_merged_annotated_img)\n",
    "\n",
    "def get_layered_img(input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, num_layers, is_mask=False, is_train=True):\n",
    "  is_grayscale = True if is_mask else False\n",
    "  top_left_i = img_i - num_layers*512\n",
    "  top_left_j = img_j - num_layers*512\n",
    "  cur_img_full = []\n",
    "  for img_row in range(num_layers*2+1):\n",
    "    cur_img_row = []\n",
    "    cur_img_j = top_left_j + img_row*512\n",
    "    for img_col in range(num_layers*2+1):\n",
    "      cur_img_i = top_left_i + img_col*512\n",
    "      if (cur_img_i, cur_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(cur_img_i, cur_img_j)]\n",
    "        if (not is_mask) or (is_train or cur_img_id==img_id):\n",
    "          cur_img = load_img(input_imgs_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        else:\n",
    "          cur_img = np.zeros((512, 512, 3), dtype=\"uint8\") if not is_mask else np.zeros((512, 512), dtype=\"uint8\")\n",
    "      else:\n",
    "        cur_img = np.zeros((512, 512, 3), dtype=\"uint8\") if not is_mask else np.zeros((512, 512), dtype=\"uint8\")\n",
    "      cur_img_row.append(cur_img)\n",
    "    cur_img_full.append(cv2.hconcat(cur_img_row))\n",
    "    cur_img_row = []\n",
    "  layered_img = cv2.vconcat(cur_img_full)\n",
    "  return layered_img\n",
    "\n",
    "def get_adjacent_img_ids(dataset_pos_dict, img_id, img_i, img_j, num_layers):\n",
    "  top_left_i = img_i - num_layers*512\n",
    "  top_left_j = img_j - num_layers*512\n",
    "  adjacent_img_ids = []\n",
    "  for img_row in range(num_layers*2+1):\n",
    "    cur_img_j = top_left_j + img_row*512\n",
    "    for img_col in range(num_layers*2+1):\n",
    "      cur_img_i = top_left_i + img_col*512\n",
    "      if (cur_img_i, cur_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(cur_img_i, cur_img_j)]\n",
    "        adjacent_img_ids.append(cur_img_id)\n",
    "  return adjacent_img_ids\n",
    "\n",
    "def save_layered_imgs(output_imgs_dir, input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, num_layers, is_train):\n",
    "  layered_img = get_layered_img(input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, num_layers, is_train=is_train)\n",
    "  cv2.imwrite(f'{output_imgs_dir}/{img_id}_layered_{num_layers}.png', layered_img)\n",
    "\n",
    "def save_layered_annots(output_annots_dir, input_masks_dir, img_id, img_i, img_j, dataset_pos_dict, num_layers, is_train):\n",
    "  layered_mask = get_layered_img(input_masks_dir, img_id, img_i, img_j, dataset_pos_dict, num_layers, is_mask=True, is_train=is_train)\n",
    "  layered_mask_coords = get_segmentation_coordinates(layered_mask)\n",
    "  layered_mask_annots = create_coco_annots(layered_mask_coords, pair_format=False)\n",
    "  with open(f'{output_annots_dir}/{img_id}_layered_{num_layers}.pkl', 'wb') as f:\n",
    "    pickle.dump(layered_mask_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_validation_tiles(dataset_pos_dict, reverse_dataset_pos_dict, img_ids, num_folds, num_layers):\n",
    "  all_validation_tiles = []\n",
    "  for i in range(num_folds):\n",
    "    img_id = random.choice(img_ids)\n",
    "    adjacent_img_ids = get_adjacent_img_ids(dataset_pos_dict, img_id, reverse_dataset_pos_dict[img_id][0], reverse_dataset_pos_dict[img_id][1], num_layers)\n",
    "    all_validation_tiles += [adjacent_img_ids]\n",
    "    img_ids = list(set(img_ids) - set(adjacent_img_ids))\n",
    "  return all_validation_tiles\n",
    "\n",
    "def create_train_valid_pos_dicts(reverse_pos_dict, validation_tiles):\n",
    "  train_reverse_pos_dict = dict()\n",
    "  validation_reverse_pos_dict = dict()\n",
    "  for key in reverse_pos_dict.keys():\n",
    "    if key in validation_tiles:\n",
    "      validation_reverse_pos_dict[key] = reverse_pos_dict[key]\n",
    "    else:\n",
    "      train_reverse_pos_dict[key] = reverse_pos_dict[key]\n",
    "  train_pos_dict = {v:k for k,v in train_reverse_pos_dict.items()}\n",
    "  validation_pos_dict = {v:k for k,v in validation_reverse_pos_dict.items()}\n",
    "  return train_pos_dict, validation_pos_dict, train_reverse_pos_dict, validation_reverse_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7452b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_1_pos_dict = {**dataset_1_wsi_1_pos_dict}\n",
    "wsi_2_pos_dict = {**dataset_1_wsi_2_pos_dict}\n",
    "reverse_wsi_1_pos_dict = {v:k for k,v in wsi_1_pos_dict.items()}\n",
    "reverse_wsi_2_pos_dict = {v:k for k,v in wsi_2_pos_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270906a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "validation_tiles_wsi_1 = get_validation_tiles(wsi_1_pos_dict, reverse_wsi_1_pos_dict, list(reverse_dataset_1_wsi_1_pos_dict.keys()), num_folds, num_layers)\n",
    "validation_tiles_wsi_2 = get_validation_tiles(wsi_2_pos_dict, reverse_wsi_2_pos_dict, list(reverse_dataset_1_wsi_2_pos_dict.keys()), num_folds, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset1_files/validation_wsi_1_fold_img_ids.pkl', 'wb') as f:\n",
    "  pickle.dump(validation_tiles_wsi_1, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('../dataset1_files/validation_wsi_2_fold_img_ids.pkl', 'wb') as f:\n",
    "  pickle.dump(validation_tiles_wsi_2, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../dataset1_files/validation_wsi_1_fold_img_ids.pkl', 'rb') as f:\n",
    "  validation_tiles_wsi_1 = pickle.load(f)\n",
    "with open('../dataset1_files/validation_wsi_2_fold_img_ids.pkl', 'rb') as f:\n",
    "  validation_tiles_wsi_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e5c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation_tiles_wsi_2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1817ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_layers = 1\n",
    "for i in range(num_folds):\n",
    "  start_time = time.time()\n",
    "  wsi_1_validation_tiles = validation_tiles_wsi_1[i]\n",
    "  wsi_2_validation_tiles = validation_tiles_wsi_2[i]\n",
    "  train_wsi_1_pos_dict, validation_wsi_1_pos_dict, train_wsi_1_reverse_pos_dict, validation_wsi_1_reverse_pos_dict = create_train_valid_pos_dicts(reverse_wsi_1_pos_dict, wsi_1_validation_tiles)\n",
    "  train_wsi_2_pos_dict, validation_wsi_2_pos_dict, train_wsi_2_reverse_pos_dict, validation_wsi_2_reverse_pos_dict = create_train_valid_pos_dicts(reverse_wsi_2_pos_dict, wsi_2_validation_tiles)\n",
    "  modes = ['train', 'validation', 'validation_custom']\n",
    "  pos_dicts = [(train_wsi_1_pos_dict, train_wsi_2_pos_dict), (validation_wsi_1_pos_dict, validation_wsi_2_pos_dict), (validation_wsi_1_pos_dict, validation_wsi_2_pos_dict)]\n",
    "  reverse_pos_dicts = [(train_wsi_1_reverse_pos_dict, train_wsi_2_reverse_pos_dict), (validation_wsi_1_reverse_pos_dict, validation_wsi_2_reverse_pos_dict), (validation_wsi_1_reverse_pos_dict, validation_wsi_2_reverse_pos_dict)]\n",
    "  \n",
    "  for j in range(len(modes)):\n",
    "    mode = modes[j]\n",
    "    is_train = True if mode=='train' or mode=='validation' else False\n",
    "    wsi_1_pos_dict, wsi_2_pos_dict = pos_dicts[j]\n",
    "    wsi_1_reverse_pos_dict, wsi_2_reverse_pos_dict = reverse_pos_dicts[j]\n",
    "    output_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_{mode}_imgs_context_fold_{i}' if mode != 'validation_custom' else f'{base_path}/dataset1_files/all_dataset1_validation_imgs_context_fold_{i}'\n",
    "    output_annots_dir = f'{base_path}/dataset1_files/all_dataset1_{mode}_annotations_context_fold_{i}'\n",
    "    cur_wsi_1_ids = set(dataset_1_tile_ids).intersection(set(list(wsi_1_reverse_pos_dict.keys())))\n",
    "    cur_wsi_2_ids = set(dataset_1_tile_ids).intersection(set(list(wsi_2_reverse_pos_dict.keys())))\n",
    "    if mode != 'validation_custom':\n",
    "        for img_id in cur_wsi_1_ids:\n",
    "          save_layered_imgs(output_imgs_dir, input_imgs_dir, img_id, wsi_1_reverse_pos_dict[img_id][0], wsi_1_reverse_pos_dict[img_id][1], wsi_1_pos_dict, num_layers, is_train)\n",
    "        for img_id in cur_wsi_2_ids:\n",
    "          save_layered_imgs(output_imgs_dir, input_imgs_dir, img_id, wsi_2_reverse_pos_dict[img_id][0], wsi_2_reverse_pos_dict[img_id][1], wsi_2_pos_dict, num_layers, is_train)\n",
    "    for img_id in cur_wsi_1_ids:\n",
    "      save_layered_annots(output_annots_dir, input_masks_dir, img_id, wsi_1_reverse_pos_dict[img_id][0], wsi_1_reverse_pos_dict[img_id][1], wsi_1_pos_dict, num_layers, is_train)\n",
    "    for img_id in cur_wsi_2_ids:\n",
    "      save_layered_annots(output_annots_dir, input_masks_dir, img_id, wsi_2_reverse_pos_dict[img_id][0], wsi_2_reverse_pos_dict[img_id][1], wsi_2_pos_dict, num_layers, is_train)\n",
    "  print(f'Finished fold {i} in {float(time.time()-start_time)/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53aa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tile_dicts = [x for x in tiles_dicts if x['id'] in dataset_1_tile_ids]\n",
    "tgt_tile_dicts = get_relevant_annots(tgt_tile_dicts)\n",
    "print(len(tgt_tile_dicts.keys()))\n",
    "adjacent_tile_dict = dict()\n",
    "for i,j in dataset_1_wsi_1_pos_dict.keys():\n",
    "  adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_1_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_1_pos_dict)\n",
    "for i,j in dataset_1_wsi_2_pos_dict.keys():\n",
    "  adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_2_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_2_pos_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2321d0fb53f7\n",
    "bordering_dataset2 = [x for x in adjacent_tile_dict if adjacent_tile_dict[x]['B'] is None]\n",
    "print(set(bordering_dataset2).intersection(set([x for sublist in validation_tiles_wsi_1 for x in sublist])))\n",
    "print(adjacent_tile_dict['733296a59c9b'])\n",
    "for i in range(num_folds):\n",
    "    if '733296a59c9b' in validation_tiles_wsi_1[i]:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img_id = '733296a59c9b'\n",
    "mode = 'validation'\n",
    "fold = 0\n",
    "num_layers = 1\n",
    "base_img = load_img(input_imgs_dir, tgt_img_id)\n",
    "layered_img = load_img(f'../dataset1_files/all_dataset1_{mode}_imgs_context_fold_{fold}', f'{tgt_img_id}_layered_{num_layers}')\n",
    "tgt_img_dict = {'layered_img': layered_img, 'base_img': base_img}\n",
    "tgt_adjacent_tile_dict = adjacent_tile_dict[tgt_img_id]\n",
    "for direction in tgt_adjacent_tile_dict:\n",
    "  cur_img_id = tgt_adjacent_tile_dict[direction]\n",
    "  if cur_img_id is None:\n",
    "    cur_img = np.zeros((512, 512, 3), dtype=\"uint8\")\n",
    "  else:\n",
    "    cur_img = load_img(input_imgs_dir, cur_img_id)\n",
    "  tgt_img_dict[direction] = cur_img\n",
    "visualize(**tgt_img_dict)\n",
    "plt.show()\n",
    "plt.imshow(layered_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd702ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img_id = '733296a59c9b'\n",
    "mode = 'validation'\n",
    "fold = 0\n",
    "num_layers = 1\n",
    "base_img = get_annotated_img(input_imgs_dir, input_annots_dir, tgt_img_id)\n",
    "layered_img = get_annotated_img(f'../dataset1_files/all_dataset1_{mode}_imgs_context_fold_{fold}' if mode != 'validation_custom' else f'../dataset1_files/all_dataset1_validation_imgs_context_fold_{fold}', f'../dataset1_files/all_dataset1_{mode}_annotations_context_fold_{fold}', f'{tgt_img_id}_layered_{num_layers}')\n",
    "tgt_img_dict = {'layered_img': layered_img, 'base_img': base_img}\n",
    "tgt_adjacent_tile_dict = adjacent_tile_dict[tgt_img_id]\n",
    "for direction in tgt_adjacent_tile_dict:\n",
    "  cur_img_id = tgt_adjacent_tile_dict[direction]\n",
    "  if cur_img_id is None:\n",
    "    cur_img = np.zeros((512, 512, 3), dtype=\"uint8\")\n",
    "  else:\n",
    "    cur_img = get_annotated_img(input_imgs_dir, input_annots_dir, cur_img_id)\n",
    "  tgt_img_dict[direction] = cur_img\n",
    "visualize(**tgt_img_dict)\n",
    "plt.show()\n",
    "plt.imshow(layered_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cfd2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d8220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb79da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4526d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img_id = 'bb488d9b931e'\n",
    "num_layers = 1\n",
    "base_img = get_annotated_img(input_imgs_dir, input_annots_dir, tgt_img_id)\n",
    "layered_img = get_annotated_img(output_imgs_dir, output_annots_dir, f'{tgt_img_id}_layered_{num_layers}')\n",
    "tgt_img_dict = {'layered_img': layered_img, 'base_img': base_img}\n",
    "tgt_adjacent_tile_dict = adjacent_tile_dict[tgt_img_id]\n",
    "for direction in tgt_adjacent_tile_dict:\n",
    "  cur_img_id = tgt_adjacent_tile_dict[direction]\n",
    "  if cur_img_id is None:\n",
    "    cur_img = np.zeros((512, 512, 3), dtype=\"uint8\")\n",
    "  else:\n",
    "    cur_img = get_annotated_img(input_imgs_dir, input_annots_dir, cur_img_id)\n",
    "  tgt_img_dict[direction] = cur_img\n",
    "visualize(**tgt_img_dict)\n",
    "plt.show()\n",
    "plt.imshow(layered_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b92bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(adjacent_tile_dict.keys())[200:220])\n",
    "print(list(adjacent_tile_dict.keys()).index('cb96f7b681f8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "shifting_thresholds = [0.15,0.30,0.45,0.60,0.75,0.90]\n",
    "print(f'Saving merged imgs and annots for {len(adjacent_tile_dict)} images...')\n",
    "start_time = time.time()\n",
    "for idx, img_id in enumerate(list(adjacent_tile_dict.keys())):\n",
    "  save_merged_imgs(input_imgs_dir, output_imgs_dir, img_id, adjacent_tile_dict[img_id], shifting_thresholds)\n",
    "  save_merged_annotations(output_annots_dir, img_id, adjacent_tile_dict[img_id], shifting_thresholds, tgt_tile_dicts)\n",
    "  if (idx+1) % 50 == 0:\n",
    "    print(f'Took {float(time.time()-start_time)} seconds to finish saving data for {idx+1} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d0bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_id = 'e7473674d813'\n",
    "shifting_thresholds = [0.15,0.30,0.45,0.60,0.75,0.90]\n",
    "save_merged_img_id_with_annot(output_imgs_dir, cleaned_output_annots_dir, vis_output_imgs_dir, base_img_id, adjacent_tile_dict[base_img_id], shifting_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bceb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img = load_img(vis_output_imgs_dir, f'{base_img_id}_full_annotated')\n",
    "plt.imshow(base_img)\n",
    "plt.show()\n",
    "img = load_img(vis_output_imgs_dir, f'{base_img_id}_R_0.6_full_annotated')\n",
    "# img_polygon_merged = load_img(vis_output_imgs_dir, f'{base_img_id}_BR_0.6_full_annotated_polygon_merged')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "# plt.imshow(img_polygon_merged)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3882c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find polygons with less than 3 pairs of coordinates and remove them from the annotations\n",
    "annot_files = os.listdir(output_annots_dir)\n",
    "cleaned_output_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_cleaned'\n",
    "if not os.path.exists(cleaned_output_annots_dir):\n",
    "    os.mkdir(cleaned_output_annots_dir)\n",
    "for annot_file in annot_files:\n",
    "  with open(f'{output_annots_dir}/{annot_file}', 'rb') as f:\n",
    "    annots = pickle.load(f)\n",
    "  cleaned_annots = [annot for annot in annots if len(annot['segmentation'][0]) >= 6]\n",
    "  with open(f'{cleaned_output_annots_dir}/{annot_file}', 'wb') as f:\n",
    "    pickle.dump(cleaned_annots, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find polygons with less than 3 pairs of coordinates and remove them from the annotations\n",
    "cleaned_output_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_cleaned'\n",
    "annot_files = os.listdir(cleaned_output_annots_dir)\n",
    "for annot_file in annot_files:\n",
    "    with open(f'{cleaned_output_annots_dir}/{annot_file}', 'rb') as f:\n",
    "        annots = pickle.load(f)\n",
    "    img_id = annot_file.split('.pkl')[0]\n",
    "    for annot in annots:\n",
    "        segmentation = annot['segmentation'][0]\n",
    "        new_segmentation = [[pt[0], pt[1]] for pt in zip(segmentation[::2], segmentation[1::2])]\n",
    "        if len(new_segmentation) < 3:\n",
    "            print(f'Segmentation error for img is {img_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae66b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464d19b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b63c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_id = '0033bbc76b6b'\n",
    "img_dir = f'{base_path}/dataset1_files/all_dataset1_imgs'\n",
    "shifting_threshold = 0.15\n",
    "img_id_1 = base_img_id\n",
    "img_1 = cv2.imread(f'{img_dir}/{img_id_1}.png')\n",
    "print(img_1.shape)\n",
    "img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "vis_dict = {'base_image': img_1}\n",
    "for k in adjacent_tile_dict[base_img_id]:\n",
    "  img_id_2 = adjacent_tile_dict[base_img_id][k]\n",
    "  if img_id_2 is not None:\n",
    "    img_2 = cv2.imread(f'{img_dir}/{img_id_2}.png')\n",
    "    img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)\n",
    "    vis_dict[f'shift_image_{k}_orig'] = img_2\n",
    "    if k in ['R', 'B', 'L']:\n",
    "      shifted_image = single_shift_img(img_1, img_2, shifting_threshold, k)\n",
    "      print(shifted_image.shape, k)\n",
    "      vis_dict[f'shift_image_{k}_shifted'] = shifted_image\n",
    "    else:\n",
    "      if k == 'BL' and adjacent_tile_dict[base_img_id]['B'] is not None and adjacent_tile_dict[base_img_id]['L'] is not None:\n",
    "        img_2 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['L']}.png\")\n",
    "        img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)\n",
    "        img_3 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['B']}.png\")\n",
    "        img_3 = cv2.cvtColor(img_3, cv2.COLOR_BGR2RGB)\n",
    "        img_4 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id][k]}.png\")\n",
    "        img_4 = cv2.cvtColor(img_4, cv2.COLOR_BGR2RGB)\n",
    "        shifted_image = double_shift_img(img_1, img_2, img_3, img_4, shifting_threshold, k)\n",
    "        print(shifted_image.shape)\n",
    "        vis_dict[f'shift_image_{k}_shifted'] = shifted_image\n",
    "      elif k == 'BR' and adjacent_tile_dict[base_img_id]['B'] is not None and adjacent_tile_dict[base_img_id]['R'] is not None:\n",
    "        img_2 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['R']}.png\")\n",
    "        img_2 = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)\n",
    "        img_3 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['B']}.png\")\n",
    "        img_3 = cv2.cvtColor(img_3, cv2.COLOR_BGR2RGB)\n",
    "        img_4 = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id][k]}.png\")\n",
    "        img_4 = cv2.cvtColor(img_4, cv2.COLOR_BGR2RGB)\n",
    "        shifted_image = double_shift_img(img_1, img_2, img_3, img_4, shifting_threshold, k)\n",
    "        print(shifted_image.shape)\n",
    "        vis_dict[f'shift_image_{k}_shifted'] = shifted_image\n",
    "visualize(**vis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83f4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_id = '0033bbc76b6b'\n",
    "img_dir = f'{base_path}/dataset1_files/all_dataset1_imgs'\n",
    "shifting_threshold = 0.25\n",
    "img_id_1 = base_img_id\n",
    "img_1 = cv2.imread(f'{img_dir}/{img_id_1}.png')\n",
    "img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "bottom_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['B']}.png\")\n",
    "bottom_img = cv2.cvtColor(bottom_img, cv2.COLOR_BGR2RGB)\n",
    "left_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['L']}.png\")\n",
    "left_img = cv2.cvtColor(left_img, cv2.COLOR_BGR2RGB)\n",
    "bottom_left_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['BL']}.png\")\n",
    "bottom_left_img = cv2.cvtColor(bottom_left_img, cv2.COLOR_BGR2RGB)\n",
    "image_top = cv2.hconcat([left_img, img_1])\n",
    "image_bottom = cv2.hconcat([bottom_left_img, bottom_img])\n",
    "final_img = cv2.vconcat([image_top, image_bottom])\n",
    "plt.imshow(final_img)\n",
    "plt.show()\n",
    "shifted_image = double_shift_img(img_1, left_img, bottom_img, bottom_left_img, shifting_threshold, 'BL')\n",
    "plt.imshow(shifted_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0f60d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_img_id = '0033bbc76b6b'\n",
    "img_dir = f'{base_path}/dataset1_files/all_dataset1_imgs'\n",
    "shifting_threshold = 0.5\n",
    "img_id_1 = base_img_id\n",
    "img_1 = cv2.imread(f'{img_dir}/{img_id_1}.png')\n",
    "img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "bottom_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['B']}.png\")\n",
    "bottom_img = cv2.cvtColor(bottom_img, cv2.COLOR_BGR2RGB)\n",
    "right_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['R']}.png\")\n",
    "right_img = cv2.cvtColor(right_img, cv2.COLOR_BGR2RGB)\n",
    "bottom_right_img = cv2.imread(f\"{img_dir}/{adjacent_tile_dict[base_img_id]['BR']}.png\")\n",
    "bottom_right_img = cv2.cvtColor(bottom_right_img, cv2.COLOR_BGR2RGB)\n",
    "image_top = cv2.hconcat([img_1, right_img])\n",
    "image_bottom = cv2.hconcat([bottom_img, bottom_right_img])\n",
    "final_img = cv2.vconcat([image_top, image_bottom])\n",
    "plt.imshow(final_img)\n",
    "plt.show()\n",
    "shifted_image = double_shift_img(img_1, right_img, bottom_img, bottom_right_img, shifting_threshold, 'BR')\n",
    "plt.imshow(shifted_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c9056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
