{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c82b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93399e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "num_folds = 5\n",
    "generate_masks = True\n",
    "get_whole_dataset_into_fold = True\n",
    "pick_validation_from_file = False\n",
    "input_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged'\n",
    "input_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_cleaned'\n",
    "vis_output_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_vis'\n",
    "if not os.path.exists(vis_output_imgs_dir):\n",
    "    os.mkdir(vis_output_imgs_dir)\n",
    "\n",
    "for i in range(num_folds):\n",
    "    train_modes = ['train', 'validation']\n",
    "    for train_mode in train_modes:\n",
    "        output_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged_{train_mode}_{i}'\n",
    "        output_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_{train_mode}_{i}'\n",
    "        output_masks_dir = f'{base_path}/dataset1_files/all_dataset1_masks_merged_{train_mode}_{i}'\n",
    "        if not os.path.exists(output_imgs_dir):\n",
    "            os.mkdir(output_imgs_dir)\n",
    "        if not os.path.exists(output_annots_dir):\n",
    "            os.mkdir(output_annots_dir)\n",
    "        if generate_masks and not os.path.exists(output_masks_dir):\n",
    "          os.mkdir(output_masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02cfe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coordinates):\n",
    "    num_points = len(coordinates)\n",
    "    if num_points < 3:\n",
    "        return 0\n",
    "\n",
    "    area = 0\n",
    "    for i in range(num_points - 1):\n",
    "        x_i, y_i = coordinates[i]\n",
    "        x_iplus1, y_iplus1 = coordinates[i + 1]\n",
    "        area += (x_i * y_iplus1) - (x_iplus1 * y_i)\n",
    "\n",
    "    x_n, y_n = coordinates[-1]\n",
    "    x_0, y_0 = coordinates[0]\n",
    "    area += (x_n * y_0) - (x_0 * y_n)\n",
    "\n",
    "    area = abs(area / 2)\n",
    "    return area\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0746f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "772e29f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>blood_vessel</th>\n",
       "      <th>glomerulus</th>\n",
       "      <th>unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ff2aa7cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16896</td>\n",
       "      <td>16420</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00168d1b7522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14848</td>\n",
       "      <td>14884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0033bbc76b6b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>43008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003504460b3a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8192</td>\n",
       "      <td>11776</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004daf1cbe75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6144</td>\n",
       "      <td>11264</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j  blood_vessel  glomerulus  \\\n",
       "0  0006ff2aa7cd           2        2  16896  16420             8           1   \n",
       "1  00168d1b7522           2        2  14848  14884             1           1   \n",
       "2  0033bbc76b6b           1        1  10240  43008             3           0   \n",
       "3  003504460b3a           3        2   8192  11776             7           0   \n",
       "4  004daf1cbe75           3        2   6144  11264            10           1   \n",
       "\n",
       "   unsure  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bf90c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "## Below is the code to create variability by merging adjacent tiles\n",
    "def get_relevant_annots(tgt_tile_dicts):\n",
    "  final_tile_dicts = dict()\n",
    "  for tile_dict in tgt_tile_dicts:\n",
    "    img_id = tile_dict['id']\n",
    "    final_annots = []\n",
    "    for annot in tile_dict['annotations']:\n",
    "      if annot['type'] == 'blood_vessel':\n",
    "        final_annots.append(annot['coordinates'][0])\n",
    "    final_tile_dicts[img_id] = final_annots\n",
    "  return final_tile_dicts\n",
    "def get_adjacent_tiles(i, j, img_id, adjacent_tile_dict, dataset_1_pos_dict):\n",
    "  adjacent_tile_dict[img_id] = dict()\n",
    "  keys = ['B', 'L', 'R', 'BL', 'BR']\n",
    "  for k in keys:\n",
    "    tgt_img_id = None\n",
    "    if k == 'B':\n",
    "      pos_to_check = (i, j+512)\n",
    "    elif k == 'L':\n",
    "      pos_to_check = (i-512, j)\n",
    "    elif k == 'R':\n",
    "      pos_to_check = (i+512, j)\n",
    "    elif k == 'BL':\n",
    "      pos_to_check = (i-512, j+512)\n",
    "    elif k == 'BR':\n",
    "      pos_to_check = (i+512, j+512)\n",
    "    if pos_to_check in dataset_1_pos_dict:\n",
    "      tgt_img_id = dataset_1_pos_dict[pos_to_check]\n",
    "    adjacent_tile_dict[img_id][k] = tgt_img_id\n",
    "  return adjacent_tile_dict\n",
    "def single_shift_polygon(seg_array_1, seg_array_2, shifting_threshold, shift_type, border_eps=1):\n",
    "    polygon_regions = []\n",
    "    num_polygons_1 = len(seg_array_1)\n",
    "    num_polygons_2 = len(seg_array_2)\n",
    "    \n",
    "    combined_array_1 = []\n",
    "    combined_array_2 = []\n",
    "    for i in range(num_polygons_1):\n",
    "        polygon_1 = seg_array_1[i]\n",
    "        new_polygon = []\n",
    "        for point in polygon_1:\n",
    "            x, y = point\n",
    "            if shift_type == 'R':\n",
    "              if x >= math.ceil(shifting_threshold*512):\n",
    "                  new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "                  new_y = y\n",
    "                  new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'B':\n",
    "              if y >= math.ceil(shifting_threshold*512):\n",
    "                new_x = x\n",
    "                new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'L':\n",
    "              if x <= math.floor((1-shifting_threshold)*512):\n",
    "                new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "                new_y = y\n",
    "                new_polygon.append([new_x, new_y])\n",
    "        if len(new_polygon) > 0:\n",
    "          combined_array_1.append(new_polygon)\n",
    "    \n",
    "    polygon_regions.append(combined_array_1)\n",
    "    \n",
    "    for i in range(num_polygons_2):\n",
    "        polygon_2 = seg_array_2[i]\n",
    "        new_polygon = []\n",
    "        for point in polygon_2:\n",
    "            x, y = point\n",
    "            if shift_type == 'R':\n",
    "              if x <= math.ceil(shifting_threshold*512):\n",
    "                new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "                new_y = y\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'B':\n",
    "              if y <= math.ceil(shifting_threshold*512):\n",
    "                new_x = x\n",
    "                new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "                new_polygon.append([new_x, new_y])\n",
    "            elif shift_type == 'L':\n",
    "              if x >= math.floor((1-shifting_threshold)*512):\n",
    "                  new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "                  new_y = y\n",
    "                  new_polygon.append([new_x, new_y])\n",
    "        if len(new_polygon) > 0:\n",
    "          combined_array_2.append(new_polygon)\n",
    "    \n",
    "    polygon_regions.append(combined_array_2)\n",
    "    \n",
    "    return polygon_regions\n",
    "\n",
    "def double_shift_polygon(seg_array_1, seg_array_2, seg_array_3, seg_array_4, shifting_threshold, shift_type, border_eps=1):\n",
    "  polygon_regions = []\n",
    "  num_polygons_1 = len(seg_array_1)\n",
    "  num_polygons_2 = len(seg_array_2)\n",
    "  num_polygons_3 = len(seg_array_3)\n",
    "  num_polygons_4 = len(seg_array_4)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_1):\n",
    "    polygon_1 = seg_array_1[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_1:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x >= math.ceil(shifting_threshold*512) and y >= math.ceil(shifting_threshold*512):\n",
    "              new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "              new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "              new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x <= math.floor((1-shifting_threshold)*512) and y >= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_2):\n",
    "    polygon_2 = seg_array_2[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_2:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x <= math.ceil(shifting_threshold*512) and y >= math.ceil(shifting_threshold*512):\n",
    "              new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "              new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "              new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x >= math.floor((1-shifting_threshold)*512) and y >= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y - int(math.ceil(shifting_threshold*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "    \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_3):\n",
    "    polygon_3 = seg_array_3[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_3:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x >= math.ceil(shifting_threshold*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x <= math.floor((1-shifting_threshold)*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.ceil(shifting_threshold*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  combined_array = []\n",
    "  for i in range(num_polygons_4):\n",
    "    polygon_4 = seg_array_4[i]\n",
    "    new_polygon = []\n",
    "    for point in polygon_4:\n",
    "        x, y = point\n",
    "        if shift_type == 'BR':\n",
    "          if x <= math.ceil(shifting_threshold*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "        elif shift_type == 'BL':\n",
    "          if x >= math.floor((1-shifting_threshold)*512) and y <= math.ceil(shifting_threshold*512):\n",
    "            new_x = x - int(math.floor((1-shifting_threshold)*512))\n",
    "            new_y = y + int(math.floor((1-shifting_threshold)*512))\n",
    "            new_polygon.append([new_x, new_y])\n",
    "    if len(new_polygon) > 0:\n",
    "      combined_array.append(new_polygon)\n",
    "  \n",
    "  polygon_regions.append(combined_array)\n",
    "  \n",
    "  return polygon_regions\n",
    "\n",
    "def check_polygon_border(pt, border_eps=1):\n",
    "  return pt[0] <= border_eps or pt[0] >= 512-border_eps or pt[1] <= border_eps or pt[1] >= 512-border_eps\n",
    "\n",
    "def single_shift_img(img_1, img_2, shifting_threshold, shift_type):\n",
    "    height, width, _ = img_1.shape\n",
    "    \n",
    "    if shift_type == 'R':\n",
    "      img_1_part = img_1[:, int(math.ceil(shifting_threshold*width)):, :]\n",
    "      img_2_part = img_2[:, :int(math.ceil(shifting_threshold*width)), :]\n",
    "      combined_image = cv2.hconcat([img_1_part, img_2_part])\n",
    "    elif shift_type == 'B':\n",
    "      img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, :, :]\n",
    "      img_2_part = img_2[:int(math.ceil(shifting_threshold*height)), :, :]\n",
    "      combined_image = cv2.vconcat([img_1_part, img_2_part])\n",
    "    else:\n",
    "      img_1_part = img_1[:, :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "      img_2_part = img_2[:, int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "      combined_image = cv2.hconcat([img_2_part, img_1_part])\n",
    "    return combined_image\n",
    "\n",
    "def double_shift_img(img_1, img_2, img_3, img_4, shifting_threshold, shift_type):\n",
    "  height, width, _ = img_1.shape\n",
    "  if shift_type == 'BR':\n",
    "    img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, int(math.ceil(shifting_threshold*width)):, :]\n",
    "    img_2_part = img_2[int(math.ceil(shifting_threshold*height)):, :int(math.ceil(shifting_threshold*width)), :]\n",
    "    img_3_part = img_3[:int(math.ceil(shifting_threshold*height)), int(math.ceil(shifting_threshold*width)):, :]\n",
    "    img_4_part = img_4[:int(math.ceil(shifting_threshold*height)), :int(math.ceil(shifting_threshold*width)), :]\n",
    "    image_top = cv2.hconcat([img_1_part, img_2_part])\n",
    "    image_bottom = cv2.hconcat([img_3_part, img_4_part])\n",
    "    combined_image = cv2.vconcat([image_top, image_bottom])\n",
    "  else:\n",
    "    img_1_part = img_1[int(math.ceil(shifting_threshold*height)):, :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "    img_2_part = img_2[int(math.ceil(shifting_threshold*height)):, int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "    img_3_part = img_3[:int(math.ceil(shifting_threshold*height)), :int(math.floor((1-shifting_threshold)*width)), :]\n",
    "    img_4_part = img_4[:int(math.ceil(shifting_threshold*height)), int(math.floor((1-shifting_threshold)*width)):, :]\n",
    "    image_top = cv2.hconcat([img_2_part, img_1_part])\n",
    "    image_bottom = cv2.hconcat([img_4_part, img_3_part])\n",
    "    combined_image = cv2.vconcat([image_top, image_bottom])\n",
    "  return combined_image\n",
    "\n",
    "def load_img(img_dir, img_id):\n",
    "  img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "\n",
    "def add_border(image, border_size, border_color):\n",
    "    height, width = image.shape[:2]\n",
    "    new_height = height + 2 * border_size\n",
    "    new_width = width + 2 * border_size\n",
    "    bordered_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "    bordered_image[border_size:height + border_size, border_size:width + border_size] = image\n",
    "    cv2.rectangle(bordered_image, (0, 0), (new_width - 1, new_height - 1), border_color, border_size)\n",
    "    return bordered_image\n",
    "\n",
    "def create_coco_annots(all_coords, pair_format=True):\n",
    "  cur_tile_coco_annots = []\n",
    "  for coords in all_coords:\n",
    "#     print('======================')\n",
    "#     print(coords)\n",
    "#     print('======================')\n",
    "    if not pair_format:\n",
    "      coords = [[pt[0], pt[1]] for pt in zip(coords[::2], coords[1::2])]\n",
    "    segmentations = [[pt for pair in coords for pt in pair]]\n",
    "    segmentation_area = calculate_area(coords)\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    segmentation_bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "    category_id = 0\n",
    "    cur_tile_coco_annots.append({\n",
    "      'segmentation': segmentations,\n",
    "      'area': segmentation_area,\n",
    "      'bbox': segmentation_bbox,\n",
    "      'category_id': category_id\n",
    "    })\n",
    "  return cur_tile_coco_annots\n",
    "\n",
    "def save_merged_imgs(input_imgs_dir, output_imgs_dir, base_img_id, base_img_dict, shifting_thresholds):\n",
    "  img_arr_dict = {'base_img': load_img(input_imgs_dir, base_img_id)}\n",
    "  cv2.imwrite(f'{output_imgs_dir}/{base_img_id}.png', img_arr_dict['base_img'])\n",
    "  for shift_type in base_img_dict.keys():\n",
    "    if base_img_dict[shift_type] is not None:\n",
    "      img_arr_dict[shift_type] = load_img(input_imgs_dir, base_img_dict[shift_type])\n",
    "    else:\n",
    "      img_arr_dict[shift_type] = None\n",
    "  for shifting_threshold in shifting_thresholds:\n",
    "    for shift_type in img_arr_dict:\n",
    "      if img_arr_dict[shift_type] is not None:\n",
    "        if shift_type in ['R', 'B']:\n",
    "          shifted_img = single_shift_img(img_arr_dict['base_img'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type} and shifting threshold: {shifting_threshold}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "        elif shift_type == 'BR' and img_arr_dict['B'] is not None and img_arr_dict['R'] is not None:\n",
    "          shifted_img = double_shift_img(img_arr_dict['base_img'], img_arr_dict['R'], img_arr_dict['B'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "        elif shift_type == 'BL' and img_arr_dict['B'] is not None and img_arr_dict['L'] is not None:\n",
    "          shifted_img = double_shift_img(img_arr_dict['base_img'], img_arr_dict['L'], img_arr_dict['B'], img_arr_dict[shift_type], shifting_threshold, shift_type)\n",
    "          if shifted_img.shape[0] != 512 or shifted_img.shape[1] != 512 or shifted_img.shape[2] != 3:\n",
    "            print(f'Error!!! Got an odd combined shape: {shifted_img.shape} for image id: {base_img_id} and shift type: {shift_type}')\n",
    "          cv2.imwrite(f'{output_imgs_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.png', shifted_img)\n",
    "\n",
    "def save_merged_annotations(output_annots_dir, base_img_id, base_img_dict, shifting_thresholds, tgt_tile_dicts):\n",
    "  print(f'base image id: {base_img_id}')\n",
    "  cur_tile_annots = create_coco_annots(tgt_tile_dicts[base_img_id])\n",
    "  with open(f'{output_annots_dir}/{base_img_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(cur_tile_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "  for shifting_threshold in shifting_thresholds:\n",
    "    for shift_type in base_img_dict:\n",
    "      if base_img_dict[shift_type] is not None:\n",
    "        if shift_type in ['R', 'B']:\n",
    "          polygon_regions = single_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "#           print(f'===========after single shift - {len(polygon_regions)}============')\n",
    "#           print(polygon_regions)\n",
    "#           print('===========after single shift============')\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========after polyon merge - {len(shifted_coords)}============')\n",
    "#           print(shifted_coords)\n",
    "#           print('===========after polyon merge============')\n",
    "#           print(f'===========merged coords shift type R B===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type R B===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "#           print(f'===========after coco - {len(shifted_coords)}============')\n",
    "#           print(shifted_annots)\n",
    "#           print('===========after coco============')\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        elif shift_type == 'BR' and base_img_dict['B'] is not None and base_img_dict['R'] is not None:\n",
    "          polygon_regions = double_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict['R']], tgt_tile_dicts[base_img_dict['B']], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========merged coords shift type BR===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type BR===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        elif shift_type == 'BL' and base_img_dict['B'] is not None and base_img_dict['L'] is not None:\n",
    "          polygon_regions = double_shift_polygon(tgt_tile_dicts[base_img_id], tgt_tile_dicts[base_img_dict['L']], tgt_tile_dicts[base_img_dict['B']], tgt_tile_dicts[base_img_dict[shift_type]], shifting_threshold, shift_type)\n",
    "          shifted_coords = get_polygon_merged_coords(polygon_regions)\n",
    "#           print(f'===========merged coords shift type BL===========')\n",
    "#           print(shifted_coords)\n",
    "#           print(f'===========merged coords shift type BL===========')\n",
    "          shifted_annots = create_coco_annots(shifted_coords, pair_format=False)\n",
    "          with open(f'{output_annots_dir}/{base_img_id}_{shift_type}_{shifting_threshold}.pkl', 'wb') as f:\n",
    "            pickle.dump(shifted_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def get_annotated_img(imgs_dir, annots_dir, base_img_id):\n",
    "  eps = 1\n",
    "  annotated_image_coco = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = annotated_image_coco.shape\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  for tgt_annot in tgt_annots:\n",
    "    coords = [[x, y] for x, y in zip(tgt_annot['segmentation'][0][::2], tgt_annot['segmentation'][0][1::2])]\n",
    "    min_x, min_y, width, height = tgt_annot['bbox']\n",
    "    cv2.fillPoly(annotated_image_coco, pts=[np.array(coords)], color=(0,255,0))\n",
    "    top_left = (int(tgt_annot['bbox'][0]), int(tgt_annot['bbox'][1]))\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    bottom_right = (int(tgt_annot['bbox'][0]+tgt_annot['bbox'][2]), int(tgt_annot['bbox'][1]+tgt_annot['bbox'][3]))\n",
    "    print(max_x-min_x, max_y-min_y, tgt_annot['bbox'])\n",
    "#     if min_x <= eps or max_x >= img_width-eps or min_y <= eps or max_y >= img_height-eps:\n",
    "#       annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "    annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "  annotated_image_coco = add_border(annotated_image_coco, 5, (0,0,255))\n",
    "  return annotated_image_coco\n",
    "\n",
    "def get_polygon_merged_annotated_img(imgs_dir, annots_dir, base_img_id):\n",
    "  eps = 1\n",
    "  annotated_image_coco = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = annotated_image_coco.shape\n",
    "  annotated_image_mask = np.zeros((img_height,img_width))\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  all_polygons = [x for tgt_annot in tgt_annots for x in tgt_annot['segmentation']]\n",
    "#   all_polygons = merge_connected_polygons(all_polygons, 1)\n",
    "  for polygon in all_polygons:\n",
    "    coords = [[x, y] for x, y in zip(polygon[::2], polygon[1::2])]\n",
    "    cv2.fillPoly(annotated_image_mask, pts=[np.array(coords)], color=255)\n",
    "  merged_polygons = get_segmentation_coordinates(annotated_image_mask)\n",
    "  for merged_polygon in merged_polygons:\n",
    "    coords = [[x, y] for x, y in zip(merged_polygon[::2], merged_polygon[1::2])]\n",
    "    cv2.fillPoly(annotated_image_coco, pts=[np.array(coords)], color=(0,255,0))\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    top_left = (int(min_x), int(min_y))\n",
    "    bottom_right = (int(max_x), int(max_y))\n",
    "#     if min_x <= eps or max_x >= img_width-eps or min_y <= eps or max_y >= img_height-eps:\n",
    "#       annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "    annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "  annotated_image_coco = add_border(annotated_image_coco, 5, (0,0,255))\n",
    "  return annotated_image_coco\n",
    "\n",
    "def get_polygon_merged_coords(polygons_regions, epsilon=1):\n",
    "  merged_polygons = group_merged_polygons(polygons_regions, epsilon=epsilon)\n",
    "  final_segmentation_coords = []\n",
    "  \n",
    "  for merged_polygon in merged_polygons:\n",
    "    annotated_image_mask = np.zeros((512,512))\n",
    "    for coords in merged_polygon:\n",
    "      cv2.fillPoly(annotated_image_mask, pts=[np.array(coords)], color=255)\n",
    "#     plt.imshow(annotated_image_mask)\n",
    "#     plt.show()\n",
    "    final_segmentation_coords += get_segmentation_coordinates(annotated_image_mask)\n",
    "  \n",
    "  return final_segmentation_coords\n",
    "  \n",
    "import math\n",
    "\n",
    "def group_merged_polygons(regions, epsilon):\n",
    "    merged_groups = []\n",
    "    \n",
    "    def merge_polygons(poly1, poly2):\n",
    "        return poly1 + poly2\n",
    "    \n",
    "    def distance(point1, point2):\n",
    "        return math.sqrt((point2[0] - point1[0]) ** 2 + (point2[1] - point1[1]) ** 2)\n",
    "    \n",
    "    def are_polygons_close(poly1, poly2):\n",
    "        for p1 in poly1:\n",
    "            for p2 in poly2:\n",
    "                if distance(p1, p2) <= epsilon:\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    for region_index, region in enumerate(regions):\n",
    "        for polygon in region:\n",
    "            merged = False\n",
    "            for group in merged_groups:\n",
    "                if (not any(region_index == group_region_idx for group_region_idx, _ in group)) and any(are_polygons_close(polygon, poly) for _, poly in group):\n",
    "                    group.append([region_index, polygon])\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_groups.append([[region_index, polygon]])\n",
    "    \n",
    "    merged_polygons = []\n",
    "    for group in merged_groups:\n",
    "        polygon_group = []\n",
    "        for _, polygon in group:\n",
    "          polygon_group.append(polygon)\n",
    "        merged_polygons.append(polygon_group)\n",
    "    return merged_polygons\n",
    "\n",
    "\n",
    "def get_segmentation_coordinates(mask):\n",
    "    mask = np.uint8(mask)\n",
    "    \n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Extract segmentation coordinates from the contours\n",
    "    segmentation_coords = []\n",
    "    for contour in contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        coords = contour.flatten().tolist()\n",
    "        segmentation_coords.append(coords)\n",
    "\n",
    "    return segmentation_coords\n",
    "\n",
    "def save_merged_img_id_with_annot(output_imgs_dir, output_annots_dir, vis_output_imgs_dir, base_img_id, base_img_dict, shifting_thresholds):\n",
    "  img_arr_dict = {'base_image': get_annotated_img(output_imgs_dir, output_annots_dir, base_img_id)}\n",
    "  for shift_type in base_img_dict.keys():\n",
    "    if base_img_dict[shift_type] is not None:\n",
    "      img_arr_dict[shift_type] = get_annotated_img(output_imgs_dir, output_annots_dir, base_img_dict[shift_type])\n",
    "    else:\n",
    "      img_arr_dict[shift_type] = add_border((np.zeros((512, 512, 3), dtype=\"uint8\")), 5, (0,0,255))\n",
    "  image_top = cv2.hconcat([img_arr_dict['L'], img_arr_dict['base_image'], img_arr_dict['R']])\n",
    "  print(img_arr_dict['BL'].shape, img_arr_dict['B'].shape, img_arr_dict['BR'].shape)\n",
    "  image_bottom = cv2.hconcat([img_arr_dict['BL'], img_arr_dict['B'], img_arr_dict['BR']])\n",
    "  image_full = cv2.vconcat([image_top, image_bottom])\n",
    "  cv2.imwrite(f'{vis_output_imgs_dir}/{base_img_id}_full_annotated.png', image_full)\n",
    "  all_merged_img_ids = [x.split('.png')[0] for x in os.listdir(output_imgs_dir) if base_img_id in x and x != f'{base_img_id}.png']\n",
    "  for merged_img_id in all_merged_img_ids:\n",
    "    merged_annotated_img = get_annotated_img(output_imgs_dir, output_annots_dir, merged_img_id)\n",
    "    cv2.imwrite(f'{vis_output_imgs_dir}/{merged_img_id}_full_annotated.png', merged_annotated_img)\n",
    "#     polygon_merged_annotated_img = get_polygon_merged_annotated_img(output_imgs_dir, output_annots_dir, merged_img_id)\n",
    "#     cv2.imwrite(f'{vis_output_imgs_dir}/{merged_img_id}_full_annotated_polygon_merged.png', polygon_merged_annotated_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77980b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "dataset_1 = tile_df_annotated.loc[tile_df_annotated['dataset']==1]\n",
    "dataset_1_tile_ids = sorted(list(dataset_1.loc[:, 'id'].values))\n",
    "wsi_1_ids = list(dataset_1.loc[dataset_1['source_wsi']==1, 'id'])\n",
    "wsi_2_ids = list(dataset_1.loc[dataset_1['source_wsi']==2, 'id'])\n",
    "tgt_tile_dicts = [x for x in tiles_dicts if x['id'] in dataset_1_tile_ids]\n",
    "tgt_tile_dicts = get_relevant_annots(tgt_tile_dicts)\n",
    "print(len(tgt_tile_dicts.keys()))\n",
    "random.shuffle(dataset_1_tile_ids)\n",
    "random.shuffle(wsi_1_ids)\n",
    "random.shuffle(wsi_2_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199d9284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b4d457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ef7f5d12b1ff',\n",
       " '07bdbe578ded',\n",
       " 'd2378fe9bcbd',\n",
       " 'c66de2904503',\n",
       " '91858313a40e',\n",
       " 'd953fe03e1d0',\n",
       " '1a785cc0d167',\n",
       " '0067d5ad2250',\n",
       " '7e97ecdac5d2',\n",
       " '327dcb16a7ef']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1_tile_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde38677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098a03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89267e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size is 85\n",
      "Fold size: 85\n",
      "Saving validation images and annotations...\n",
      "Creating adjacent tile dict for the current training set...\n",
      "Saving training images and annotations...\n"
     ]
    }
   ],
   "source": [
    "fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds))\n",
    "print(f'Fold size is {fold_size}')\n",
    "shifting_thresholds = [0.15,0.30,0.45,0.60,0.75,0.90]\n",
    "print(f'Fold size: {fold_size}')\n",
    "for i in range(1):\n",
    "  validation_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged_validation_{i}'\n",
    "  validation_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_validation_{i}'\n",
    "  train_imgs_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged_train_{i}'\n",
    "  train_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_train_{i}'\n",
    "  \n",
    "  if pick_validation_from_file:\n",
    "    with open(f'{base_path}/dataset1_files/validation_wsi_1_fold_img_ids.pkl', 'rb') as f:\n",
    "        wsi_1_validation_img_ids = pickle.load(f)\n",
    "    with open(f'{base_path}/dataset1_files/validation_wsi_2_fold_img_ids.pkl', 'rb') as f:\n",
    "        wsi_2_validation_img_ids = pickle.load(f)\n",
    "    wsi_validation_img_ids = wsi_1_validation_img_ids[i] + wsi_2_validation_img_ids[i]\n",
    "    cur_validaton_slice = wsi_validation_img_ids\n",
    "    cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice))\n",
    "    print(len(cur_validaton_slice), len(cur_training_slice))\n",
    "    print(cur_validaton_slice, cur_training_slice)\n",
    "  else:\n",
    "#     cur_validaton_slice = dataset_1_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(dataset_1_tile_ids))]\n",
    "#     cur_training_slice = dataset_1_tile_ids[:int(i*fold_size)] + dataset_1_tile_ids[min(int((i+1)*fold_size), len(dataset_1_tile_ids)):]\n",
    "    if get_whole_dataset_into_fold:\n",
    "        cur_validaton_slice = wsi_1_ids + wsi_2_ids\n",
    "        cur_training_slice = wsi_1_ids + wsi_2_ids\n",
    "    else:\n",
    "        cur_validaton_slice = wsi_1_ids[int(i*(fold_size/2)):min(int((i+1)*(fold_size/2)), len(wsi_1_ids))] + wsi_2_ids[int(i*(fold_size/2)):min(int((i+1)*(fold_size/2)), len(wsi_2_ids))]\n",
    "        cur_training_slice = list(set(wsi_1_ids+wsi_2_ids) - set(cur_validaton_slice))\n",
    "  \n",
    "  print('Saving validation images and annotations...')\n",
    "  for validation_img_id in cur_validaton_slice:\n",
    "      shutil.copy(f'{input_imgs_dir}/{validation_img_id}.png', f'{validation_imgs_dir}/{validation_img_id}.png')\n",
    "      shutil.copy(f'{input_annots_dir}/{validation_img_id}.pkl', f'{validation_annots_dir}/{validation_img_id}.pkl')\n",
    "  \n",
    "#   print('Creating adjacent tile dict for the current validation set...')\n",
    "#   dataset_1_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==1) & (dataset_1['id'].isin(cur_validaton_slice)), ['i', 'j', 'id']].values}\n",
    "#   dataset_1_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==2) & (dataset_1['id'].isin(cur_validaton_slice)), ['i', 'j', 'id']].values}\n",
    "#   reverse_dataset_1_wsi_1_pos_dict = {v:k for k,v in dataset_1_wsi_1_pos_dict.items()}\n",
    "#   reverse_dataset_1_wsi_2_pos_dict = {v:k for k,v in dataset_1_wsi_2_pos_dict.items()}\n",
    "#   adjacent_tile_dict = dict()\n",
    "#   for i,j in dataset_1_wsi_1_pos_dict.keys():\n",
    "#     adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_1_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_1_pos_dict)\n",
    "#   for i,j in dataset_1_wsi_2_pos_dict.keys():\n",
    "#     adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_2_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_2_pos_dict)\n",
    "  \n",
    "#   print('Saving validation images and annotations...')\n",
    "#   for validation_img_id in adjacent_tile_dict.keys():\n",
    "#     shutil.copy(f'{input_imgs_dir}/{validation_img_id}.png', f'{validation_imgs_dir}/{validation_img_id}.png')\n",
    "#     shutil.copy(f'{input_annots_dir}/{validation_img_id}.pkl', f'{validation_annots_dir}/{validation_img_id}.pkl')\n",
    "#     validation_adjacent_tiles = adjacent_tile_dict[validation_img_id]\n",
    "#     valid_shifts = []\n",
    "#     if validation_adjacent_tiles['R'] is not None:\n",
    "#       valid_shifts.append('R')\n",
    "#     if validation_adjacent_tiles['B'] is not None:\n",
    "#       valid_shifts.append('B')\n",
    "#     if validation_adjacent_tiles['B'] is not None and validation_adjacent_tiles['R'] is not None and validation_adjacent_tiles['BR'] is not None:\n",
    "#       valid_shifts.append('BR')\n",
    "#     if validation_adjacent_tiles['B'] is not None and validation_adjacent_tiles['L'] is not None and validation_adjacent_tiles['BL'] is not None:\n",
    "#       valid_shifts.append('BL')\n",
    "#     for valid_shift in valid_shifts:\n",
    "#       for shifting_threshold in shifting_thresholds:\n",
    "#         shutil.copy(f'{input_imgs_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.png', f'{validation_imgs_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.png')\n",
    "#         shutil.copy(f'{input_annots_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.pkl', f'{validation_annots_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.pkl')\n",
    "  \n",
    "  print('Creating adjacent tile dict for the current training set...')\n",
    "  dataset_1_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==1) & (dataset_1['id'].isin(cur_training_slice)), ['i', 'j', 'id']].values}\n",
    "  dataset_1_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==2) & (dataset_1['id'].isin(cur_training_slice)), ['i', 'j', 'id']].values}\n",
    "  reverse_dataset_1_wsi_1_pos_dict = {v:k for k,v in dataset_1_wsi_1_pos_dict.items()}\n",
    "  reverse_dataset_1_wsi_2_pos_dict = {v:k for k,v in dataset_1_wsi_2_pos_dict.items()}\n",
    "  adjacent_tile_dict = dict()\n",
    "  for i,j in dataset_1_wsi_1_pos_dict.keys():\n",
    "    adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_1_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_1_pos_dict)\n",
    "  for i,j in dataset_1_wsi_2_pos_dict.keys():\n",
    "    adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_2_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_2_pos_dict)\n",
    "  \n",
    "  print('Saving training images and annotations...')\n",
    "  for train_img_id in adjacent_tile_dict.keys():\n",
    "    shutil.copy(f'{input_imgs_dir}/{train_img_id}.png', f'{train_imgs_dir}/{train_img_id}.png')\n",
    "    shutil.copy(f'{input_annots_dir}/{train_img_id}.pkl', f'{train_annots_dir}/{train_img_id}.pkl')\n",
    "    train_adjacent_tiles = adjacent_tile_dict[train_img_id]\n",
    "    valid_shifts = []\n",
    "    if train_adjacent_tiles['R'] is not None:\n",
    "      valid_shifts.append('R')\n",
    "    if train_adjacent_tiles['B'] is not None:\n",
    "      valid_shifts.append('B')\n",
    "    if train_adjacent_tiles['B'] is not None and train_adjacent_tiles['R'] is not None and train_adjacent_tiles['BR'] is not None:\n",
    "      valid_shifts.append('BR')\n",
    "    if train_adjacent_tiles['B'] is not None and train_adjacent_tiles['L'] is not None and train_adjacent_tiles['BL'] is not None:\n",
    "      valid_shifts.append('BL')\n",
    "    for valid_shift in valid_shifts:\n",
    "      for shifting_threshold in shifting_thresholds:\n",
    "        shutil.copy(f'{input_imgs_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.png', f'{train_imgs_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.png')\n",
    "        shutil.copy(f'{input_annots_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.pkl', f'{train_annots_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32149e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 42\n"
     ]
    }
   ],
   "source": [
    "validation_imgs = os.listdir(f'{base_path}/dataset1_files/all_dataset1_imgs_merged_validation_0')\n",
    "wsi_1_validation_imgs = 0\n",
    "wsi_2_validation_imgs = 0\n",
    "for img in validation_imgs:\n",
    "    if img.split('.png')[0] in wsi_1_ids:\n",
    "        wsi_1_validation_imgs += 1\n",
    "    else:\n",
    "        wsi_2_validation_imgs += 1\n",
    "print(wsi_1_validation_imgs, wsi_2_validation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_id):\n",
    "  img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "def get_annotated_mask(imgs_dir, annots_dir, base_img_id):\n",
    "  orig_img = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = orig_img.shape\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  img_mask = np.zeros((img_height, img_width))\n",
    "  for tgt_annot in tgt_annots:\n",
    "    coords = [[x, y] for x, y in zip(tgt_annot['segmentation'][0][::2], tgt_annot['segmentation'][0][1::2])]\n",
    "    cv2.fillPoly(img_mask, pts=[np.array(coords)], color=1)\n",
    "  return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6befc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "if generate_masks:\n",
    "  train_modes = ['train', 'validation']\n",
    "  for i in range(1):\n",
    "    start_time = time.time()\n",
    "    for train_mode in train_modes:\n",
    "      orig_img_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged_{train_mode}_{i}'\n",
    "      orig_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_{train_mode}_{i}'\n",
    "      output_mask_dir = f'{base_path}/dataset1_files/all_dataset1_masks_merged_{train_mode}_{i}'\n",
    "      all_orig_imgs = os.listdir(orig_img_dir)\n",
    "      for orig_img in all_orig_imgs:\n",
    "        orig_img_id = orig_img.split('.png')[0]\n",
    "        annotated_mask = get_annotated_mask(orig_img_dir, orig_annots_dir, orig_img_id)\n",
    "        cv2.imwrite(f'{output_mask_dir}/{orig_img_id}.png', annotated_mask)\n",
    "    print(f'Finished generating masks for fold {i} in {float(time.time()-start_time)/60} minutes')\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9630da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img_id = 'b8db704134ac_BR_0.75'\n",
    "train_mode = 'train'\n",
    "i = 0\n",
    "orig_img = get_annotated_img(f'{base_path}/dataset1_files/all_dataset1_imgs_merged_{train_mode}_{i}', f'{base_path}/dataset1_files/all_dataset1_annotations_merged_{train_mode}_{i}', tgt_img_id)\n",
    "# img_mask = cv2.imread(f'{base_path}/dataset1_files/all_dataset1_masks_merged_{train_mode}_{i}/{tgt_img_id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(orig_img)\n",
    "plt.show()\n",
    "# plt.imshow(img_mask)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/bd090bb1b654.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5501a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_files = os.listdir('/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0')\n",
    "no_mask_annots = []\n",
    "for annot_file in annot_files:\n",
    "    with open(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{annot_file}', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    if len(data)==0:\n",
    "        no_mask_annots.append(annot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_mask_annot in no_mask_annots:\n",
    "    img_id = no_mask_annot.split('.pkl')[0]\n",
    "    if os.path.exists(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{img_id}.pkl'):\n",
    "        os.remove(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{img_id}.pkl')\n",
    "    if os.path.exists(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_imgs_merged_train_0/{img_id}.png'):\n",
    "        os.remove(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_imgs_merged_train_0/{img_id}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e395f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HubMapEnv",
   "language": "python",
   "name": "hubmapenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
