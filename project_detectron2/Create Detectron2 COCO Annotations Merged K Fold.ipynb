{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c82b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93399e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "num_folds = 5\n",
    "generate_masks = False\n",
    "should_dilate = False\n",
    "use_merged_dataset = False\n",
    "generate_all_datset_annots = True\n",
    "base_data_dir = 'dataset1_files' if not generate_all_datset_annots else 'all_dataset_files'\n",
    "base_data_name = 'all_dataset1' if not generate_all_datset_annots else 'all_dataset'\n",
    "get_whole_dataset_into_fold = False\n",
    "pick_validation_from_file = False\n",
    "input_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs'\n",
    "input_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_cleaned' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations'\n",
    "vis_output_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_vis'\n",
    "\n",
    "if os.path.exists(vis_output_imgs_dir):\n",
    "    shutil.rmtree(vis_output_imgs_dir)\n",
    "os.mkdir(vis_output_imgs_dir)\n",
    "\n",
    "for i in range(num_folds):\n",
    "    train_modes = ['train', 'validation']\n",
    "    for train_mode in train_modes:\n",
    "        output_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged_{train_mode}_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs_{train_mode}_{i}'\n",
    "        output_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_{train_mode}_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_{train_mode}_{i}'\n",
    "        output_masks_dir = f'{base_path}/{base_data_dir}/{base_data_name}_masks_merged_{train_mode}_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_masks_{train_mode}_{i}'\n",
    "        if os.path.exists(output_imgs_dir):\n",
    "            shutil.rmtree(output_imgs_dir)\n",
    "        os.mkdir(output_imgs_dir)\n",
    "        if os.path.exists(output_annots_dir):\n",
    "            shutil.rmtree(output_annots_dir)\n",
    "        os.mkdir(output_annots_dir)\n",
    "        if generate_masks:\n",
    "            if os.path.exists(output_masks_dir):\n",
    "                shutil.rmtree(output_masks_dir)\n",
    "            os.mkdir(output_masks_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02cfe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0746f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "772e29f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>blood_vessel</th>\n",
       "      <th>glomerulus</th>\n",
       "      <th>unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ff2aa7cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16896</td>\n",
       "      <td>16420</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00168d1b7522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14848</td>\n",
       "      <td>14884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0033bbc76b6b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>43008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003504460b3a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8192</td>\n",
       "      <td>11776</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004daf1cbe75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6144</td>\n",
       "      <td>11264</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j  blood_vessel  glomerulus  \\\n",
       "0  0006ff2aa7cd           2        2  16896  16420             8           1   \n",
       "1  00168d1b7522           2        2  14848  14884             1           1   \n",
       "2  0033bbc76b6b           1        1  10240  43008             3           0   \n",
       "3  003504460b3a           3        2   8192  11776             7           0   \n",
       "4  004daf1cbe75           3        2   6144  11264            10           1   \n",
       "\n",
       "   unsure  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bf90c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def load_img(img_dir, img_id):\n",
    "  img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "\n",
    "def add_border(image, border_size, border_color):\n",
    "    height, width = image.shape[:2]\n",
    "    new_height = height + 2 * border_size\n",
    "    new_width = width + 2 * border_size\n",
    "    bordered_image = np.zeros((new_height, new_width, 3), dtype=np.uint8)\n",
    "    bordered_image[border_size:height + border_size, border_size:width + border_size] = image\n",
    "    cv2.rectangle(bordered_image, (0, 0), (new_width - 1, new_height - 1), border_color, border_size)\n",
    "    return bordered_image\n",
    "\n",
    "def create_coco_annots(all_coords, pair_format=True):\n",
    "  cur_tile_coco_annots = []\n",
    "  for coords in all_coords:\n",
    "    if not pair_format:\n",
    "      coords = [[pt[0], pt[1]] for pt in zip(coords[::2], coords[1::2])]\n",
    "    segmentations = [[pt for pair in coords for pt in pair]]\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    segmentation_bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "    category_id = 0\n",
    "    cur_tile_coco_annots.append({\n",
    "      'segmentation': segmentations,\n",
    "      'bbox': segmentation_bbox,\n",
    "      'category_id': category_id\n",
    "    })\n",
    "  return cur_tile_coco_annots\n",
    "\n",
    "def get_annotated_img(imgs_dir, annots_dir, base_img_id, is_yolo=False):\n",
    "  eps = 1\n",
    "  annotated_image_coco = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = annotated_image_coco.shape\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  for tgt_annot in tgt_annots:\n",
    "    coords = [[x, y] for x, y in zip(tgt_annot['segmentation'][0][::2], tgt_annot['segmentation'][0][1::2])]\n",
    "    min_x, min_y, width, height = tgt_annot['bbox']\n",
    "    cv2.fillPoly(annotated_image_coco, pts=[np.array(coords)], color=(0,255,0))\n",
    "    top_left = (int(tgt_annot['bbox'][0]), int(tgt_annot['bbox'][1]))\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    bottom_right = (int(tgt_annot['bbox'][0]+tgt_annot['bbox'][2]), int(tgt_annot['bbox'][1]+tgt_annot['bbox'][3]))\n",
    "    print(max_x-min_x, max_y-min_y, tgt_annot['bbox'])\n",
    "#     if min_x <= eps or max_x >= img_width-eps or min_y <= eps or max_y >= img_height-eps:\n",
    "#       annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "    annotated_image_coco = cv2.rectangle(annotated_image_coco, top_left, bottom_right, (255,0,0), 2)\n",
    "  annotated_image_coco = add_border(annotated_image_coco, 5, (0,0,255))\n",
    "  return annotated_image_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db2eff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "dataset_1_tile_ids = sorted(list(tile_df_annotated.loc[tile_df_annotated['dataset']==1, 'id'].values))\n",
    "all_dataset_tile_ids = sorted(list(tile_df_annotated.loc[:, 'id'].values))\n",
    "tgt_wsis = [1,2,3,4]\n",
    "wsi_tile_ids = []\n",
    "for tgt_wsi in tgt_wsis:\n",
    "    if generate_all_datset_annots:\n",
    "        wsi_ids = list(tile_df_annotated.loc[tile_df_annotated['source_wsi']==tgt_wsi, 'id'].values)\n",
    "    else:\n",
    "        wsi_ids = list(tile_df_annotated.loc[(tile_df_annotated['dataset']==1) & (tile_df_annotated['source_wsi']==tgt_wsi), 'id'].values)\n",
    "    random.shuffle(wsi_ids)\n",
    "    wsi_tile_ids.append(wsi_ids)\n",
    "random.shuffle(dataset_1_tile_ids)\n",
    "random.shuffle(all_dataset_tile_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0a3431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1633, 422, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_dataset_tile_ids), len(dataset_1_tile_ids), len(wsi_tile_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c1e445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['61f8b27a48e6',\n",
       " '44c66d51c40e',\n",
       " '3e01bb974a1b',\n",
       " 'e3c41ad419a2',\n",
       " '7e97ecdac5d2',\n",
       " 'a373ae26f4f0',\n",
       " 'fc6def641612',\n",
       " '4ca084aec87b',\n",
       " '936f9bfb3966',\n",
       " 'da774b6f9cd1']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1_tile_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde38677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../all_dataset_files/all_dataset_imgs',\n",
       " '../all_dataset_files/all_dataset_annotations')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_imgs_dir, input_annots_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9c5cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size is 85\n",
      "Creating validation from wsi tiles...\n",
      "85 1548\n",
      "Saving validation images and annotations...\n",
      "Saving training images and annotations...\n",
      "Creating validation from wsi tiles...\n",
      "85 1548\n",
      "Saving validation images and annotations...\n",
      "Saving training images and annotations...\n",
      "Creating validation from wsi tiles...\n",
      "85 1548\n",
      "Saving validation images and annotations...\n",
      "Saving training images and annotations...\n",
      "Creating validation from wsi tiles...\n",
      "85 1548\n",
      "Saving validation images and annotations...\n",
      "Saving training images and annotations...\n",
      "Creating validation from wsi tiles...\n",
      "82 1551\n",
      "Saving validation images and annotations...\n",
      "Saving training images and annotations...\n"
     ]
    }
   ],
   "source": [
    "# fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds)) if not generate_all_datset_annots else int(math.ceil(len(all_dataset_tile_ids) / num_folds))\n",
    "fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds))\n",
    "print(f'Fold size is {fold_size}')\n",
    "shifting_thresholds = [0.15,0.30,0.45,0.60,0.75,0.90]\n",
    "for i in range(num_folds):\n",
    "  validation_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged_validation_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs_validation_{i}'\n",
    "  validation_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_validation_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_validation_{i}'\n",
    "  train_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged_train_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs_train_{i}'\n",
    "  train_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_train_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_train_{i}'\n",
    "  \n",
    "  if pick_validation_from_file:\n",
    "    with open(f'{base_path}/{base_data_dir}/validation_img_ids_fold_{i}.pkl', 'rb') as f:\n",
    "        cur_validation_slice = pickle.load(f)\n",
    "    with open(f'{base_path}/{base_data_dir}/train_img_ids_fold_{i}.pkl', 'rb') as f:\n",
    "        cur_training_slice = pickle.load(f)\n",
    "    print(len(cur_validation_slice), len(cur_training_slice))\n",
    "  else:\n",
    "    if get_whole_dataset_into_fold:\n",
    "        cur_validaton_slice = wsi_1_ids + wsi_2_ids\n",
    "        cur_training_slice = wsi_1_ids + wsi_2_ids\n",
    "    else:\n",
    "        print('Creating validation from wsi tiles...')\n",
    "#         cur_validaton_slice = dataset_1_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(dataset_1_tile_ids))] if not generate_all_datset_annots else all_dataset_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(all_dataset_tile_ids))]\n",
    "        cur_validaton_slice = dataset_1_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(dataset_1_tile_ids))]\n",
    "#         cur_validaton_slice = []    \n",
    "#         num_wsis = float(len(wsi_tile_ids))\n",
    "#         for wsi_tile_id in wsi_tile_ids:\n",
    "#             cur_validaton_slice += wsi_tile_id[int(i*(fold_size/num_wsis)):min(int((i+1)*(fold_size/num_wsis)), len(wsi_tile_id))]\n",
    "        cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice)) if not generate_all_datset_annots else list(set(all_dataset_tile_ids) - set(cur_validaton_slice))\n",
    "        print(len(cur_validaton_slice), len(cur_training_slice))\n",
    "  \n",
    "  print('Saving validation images and annotations...')\n",
    "  for validation_img_id in cur_validaton_slice:\n",
    "      shutil.copy(f'{input_imgs_dir}/{validation_img_id}.png', f'{validation_imgs_dir}/{validation_img_id}.png')\n",
    "      shutil.copy(f'{input_annots_dir}/{validation_img_id}.pkl', f'{validation_annots_dir}/{validation_img_id}.pkl')\n",
    "    \n",
    "  print('Saving training images and annotations...')\n",
    "  for train_img_id in cur_training_slice:\n",
    "    shutil.copy(f'{input_imgs_dir}/{train_img_id}.png', f'{train_imgs_dir}/{train_img_id}.png')\n",
    "    shutil.copy(f'{input_annots_dir}/{train_img_id}.pkl', f'{train_annots_dir}/{train_img_id}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cc98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "validation_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_validation_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_validation_{i}'\n",
    "train_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_train_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_train_{i}'\n",
    "files = os.listdir(train_annots_dir)\n",
    "wsi_counts = [0]*len(wsi_tile_ids)\n",
    "categories = set()\n",
    "for fi in files:\n",
    "    with open(f'{train_annots_dir}/{fi}', 'rb') as f:\n",
    "        val_annots = pickle.load(f)\n",
    "    categories = categories.union(set([ann['category_id'] for ann in val_annots]))\n",
    "    img_id = fi.split('.pkl')[0]\n",
    "    for idx, wsi_tile_id in enumerate(wsi_tile_ids):\n",
    "        if img_id in wsi_tile_id:\n",
    "            wsi_counts[idx] += 1\n",
    "wsi_counts, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e5ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d3ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164efbc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f36f86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bd6c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89267e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds))\n",
    "print(f'Fold size is {fold_size}')\n",
    "shifting_thresholds = [0.15,0.30,0.45,0.60,0.75,0.90]\n",
    "print(f'Fold size: {fold_size}')\n",
    "for i in range(1):\n",
    "  validation_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged_validation_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs_validation_{i}'\n",
    "  validation_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_validation_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_validation_{i}'\n",
    "  train_imgs_dir = f'{base_path}/{base_data_dir}/{base_data_name}_imgs_merged_train_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_imgs_train_{i}'\n",
    "  train_annots_dir = f'{base_path}/{base_data_dir}/{base_data_name}_annotations_merged_train_{i}' if use_merged_dataset else f'{base_path}/{base_data_dir}/{base_data_name}_annotations_train_{i}'\n",
    "  \n",
    "  if pick_validation_from_file:\n",
    "    with open(f'{base_path}/dataset1_files/validation_wsi_1_fold_img_ids.pkl', 'rb') as f:\n",
    "        wsi_1_validation_img_ids = pickle.load(f)\n",
    "    with open(f'{base_path}/dataset1_files/validation_wsi_2_fold_img_ids.pkl', 'rb') as f:\n",
    "        wsi_2_validation_img_ids = pickle.load(f)\n",
    "    wsi_validation_img_ids = wsi_1_validation_img_ids[i] + wsi_2_validation_img_ids[i]\n",
    "    cur_validaton_slice = wsi_validation_img_ids\n",
    "    cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice))\n",
    "    print(len(cur_validaton_slice), len(cur_training_slice))\n",
    "    print(cur_validaton_slice, cur_training_slice)\n",
    "  else:\n",
    "#     cur_validaton_slice = dataset_1_tile_ids[int(i*fold_size):min(int((i+1)*fold_size), len(dataset_1_tile_ids))]\n",
    "#     cur_training_slice = dataset_1_tile_ids[:int(i*fold_size)] + dataset_1_tile_ids[min(int((i+1)*fold_size), len(dataset_1_tile_ids)):]\n",
    "    if get_whole_dataset_into_fold:\n",
    "        cur_validaton_slice = wsi_1_ids + wsi_2_ids\n",
    "        cur_training_slice = wsi_1_ids + wsi_2_ids\n",
    "    else:\n",
    "#         cur_validaton_slice = wsi_1_ids[int(i*(fold_size/2)):min(int((i+1)*(fold_size/2)), len(wsi_1_ids))] + wsi_2_ids[int(i*(fold_size/2)):min(int((i+1)*(fold_size/2)), len(wsi_2_ids))]\n",
    "#         cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice)) if not generate_all_datset_annots else list(set(all_dataset_tile_ids) - set(cur_validaton_slice))\n",
    "        # Temporary changes below\n",
    "        cur_validaton_slice = []\n",
    "        num_wsis = float(len(wsi_tile_ids))\n",
    "        for wsi_tile_id in wsi_tile_ids:\n",
    "            cur_validaton_slice += wsi_tile_id[int(i*(fold_size/num_wsis)):min(int((i+1)*(fold_size/num_wsis)), len(wsi_tile_id))]\n",
    "        cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice)) if not generate_all_datset_annots else list(set(all_dataset_tile_ids) - set(cur_validaton_slice))\n",
    "  \n",
    "  print('Saving validation images and annotations...')\n",
    "  for validation_img_id in cur_validaton_slice:\n",
    "      shutil.copy(f'{input_imgs_dir}/{validation_img_id}.png', f'{validation_imgs_dir}/{validation_img_id}.png')\n",
    "      shutil.copy(f'{input_annots_dir}/{validation_img_id}.pkl', f'{validation_annots_dir}/{validation_img_id}.pkl')\n",
    "  \n",
    "#   print('Creating adjacent tile dict for the current validation set...')\n",
    "#   dataset_1_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==1) & (dataset_1['id'].isin(cur_validaton_slice)), ['i', 'j', 'id']].values}\n",
    "#   dataset_1_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==2) & (dataset_1['id'].isin(cur_validaton_slice)), ['i', 'j', 'id']].values}\n",
    "#   reverse_dataset_1_wsi_1_pos_dict = {v:k for k,v in dataset_1_wsi_1_pos_dict.items()}\n",
    "#   reverse_dataset_1_wsi_2_pos_dict = {v:k for k,v in dataset_1_wsi_2_pos_dict.items()}\n",
    "#   adjacent_tile_dict = dict()\n",
    "#   for i,j in dataset_1_wsi_1_pos_dict.keys():\n",
    "#     adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_1_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_1_pos_dict)\n",
    "#   for i,j in dataset_1_wsi_2_pos_dict.keys():\n",
    "#     adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_2_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_2_pos_dict)\n",
    "  \n",
    "#   print('Saving validation images and annotations...')\n",
    "#   for validation_img_id in adjacent_tile_dict.keys():\n",
    "#     shutil.copy(f'{input_imgs_dir}/{validation_img_id}.png', f'{validation_imgs_dir}/{validation_img_id}.png')\n",
    "#     shutil.copy(f'{input_annots_dir}/{validation_img_id}.pkl', f'{validation_annots_dir}/{validation_img_id}.pkl')\n",
    "#     validation_adjacent_tiles = adjacent_tile_dict[validation_img_id]\n",
    "#     valid_shifts = []\n",
    "#     if validation_adjacent_tiles['R'] is not None:\n",
    "#       valid_shifts.append('R')\n",
    "#     if validation_adjacent_tiles['B'] is not None:\n",
    "#       valid_shifts.append('B')\n",
    "#     if validation_adjacent_tiles['B'] is not None and validation_adjacent_tiles['R'] is not None and validation_adjacent_tiles['BR'] is not None:\n",
    "#       valid_shifts.append('BR')\n",
    "#     if validation_adjacent_tiles['B'] is not None and validation_adjacent_tiles['L'] is not None and validation_adjacent_tiles['BL'] is not None:\n",
    "#       valid_shifts.append('BL')\n",
    "#     for valid_shift in valid_shifts:\n",
    "#       for shifting_threshold in shifting_thresholds:\n",
    "#         shutil.copy(f'{input_imgs_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.png', f'{validation_imgs_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.png')\n",
    "#         shutil.copy(f'{input_annots_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.pkl', f'{validation_annots_dir}/{validation_img_id}_{valid_shift}_{shifting_threshold}.pkl')\n",
    "  \n",
    "  print('Creating adjacent tile dict for the current training set...')\n",
    "  dataset_1_wsi_1_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==1) & (dataset_1['id'].isin(cur_training_slice)), ['i', 'j', 'id']].values}\n",
    "  dataset_1_wsi_2_pos_dict = {(x[0], x[1]): x[-1] for x in dataset_1.loc[(dataset_1['source_wsi']==2) & (dataset_1['id'].isin(cur_training_slice)), ['i', 'j', 'id']].values}\n",
    "  reverse_dataset_1_wsi_1_pos_dict = {v:k for k,v in dataset_1_wsi_1_pos_dict.items()}\n",
    "  reverse_dataset_1_wsi_2_pos_dict = {v:k for k,v in dataset_1_wsi_2_pos_dict.items()}\n",
    "  adjacent_tile_dict = dict()\n",
    "  for i,j in dataset_1_wsi_1_pos_dict.keys():\n",
    "    adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_1_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_1_pos_dict)\n",
    "  for i,j in dataset_1_wsi_2_pos_dict.keys():\n",
    "    adjacent_tile_dict = get_adjacent_tiles(i, j, dataset_1_wsi_2_pos_dict[(i,j)], adjacent_tile_dict, dataset_1_wsi_2_pos_dict)\n",
    "  \n",
    "  print('Saving training images and annotations...')\n",
    "  for train_img_id in cur_training_slice:\n",
    "    shutil.copy(f'{input_imgs_dir}/{train_img_id}.png', f'{train_imgs_dir}/{train_img_id}.png')\n",
    "    if should_dilate:\n",
    "        with open(f'{input_annots_dir}/{train_img_id}.pkl', 'rb') as f:\n",
    "            annotations = pickle.load(f)\n",
    "        cur_tile_coco_annots = []\n",
    "        for annot in annotations:\n",
    "            coords = [[x,y] for x,y in zip(annot['segmentation'][0][::2], annot['segmentation'][0][1::2])]\n",
    "            mask = np.zeros((512,512), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, pts=[np.array(coords)], color=1)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "            dilated_mask = cv2.dilate(mask, kernel, iterations=2)\n",
    "            contours, _ = cv2.findContours(dilated_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            dilated_coords = contours[0].reshape(-1, 2)\n",
    "            coords = dilated_coords\n",
    "            segmentations = [[pt for pair in coords for pt in pair]]\n",
    "            segmentation_area = calculate_area(coords)\n",
    "            min_x = min(coords, key=lambda x: x[0])[0]\n",
    "            max_x = max(coords, key=lambda x: x[0])[0]\n",
    "            min_y = min(coords, key=lambda x: x[1])[1]\n",
    "            max_y = max(coords, key=lambda x: x[1])[1]\n",
    "            segmentation_bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "            category_id = annot['category_id']\n",
    "            cur_tile_coco_annots.append({\n",
    "              'segmentation': segmentations,\n",
    "              'area': segmentation_area,\n",
    "              'bbox': segmentation_bbox,\n",
    "              'category_id': category_id\n",
    "            })\n",
    "        with open(f'{train_annots_dir}/{train_img_id}.pkl', 'wb') as f:\n",
    "            pickle.dump(cur_tile_coco_annots, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        shutil.copy(f'{input_annots_dir}/{train_img_id}.pkl', f'{train_annots_dir}/{train_img_id}.pkl')\n",
    "    if use_merged_dataset:\n",
    "        train_adjacent_tiles = adjacent_tile_dict[train_img_id]\n",
    "        valid_shifts = []\n",
    "        if train_adjacent_tiles['R'] is not None:\n",
    "          valid_shifts.append('R')\n",
    "        if train_adjacent_tiles['B'] is not None:\n",
    "          valid_shifts.append('B')\n",
    "        if train_adjacent_tiles['B'] is not None and train_adjacent_tiles['R'] is not None and train_adjacent_tiles['BR'] is not None:\n",
    "          valid_shifts.append('BR')\n",
    "        if train_adjacent_tiles['B'] is not None and train_adjacent_tiles['L'] is not None and train_adjacent_tiles['BL'] is not None:\n",
    "          valid_shifts.append('BL')\n",
    "        for valid_shift in valid_shifts:\n",
    "          for shifting_threshold in shifting_thresholds:\n",
    "            shutil.copy(f'{input_imgs_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.png', f'{train_imgs_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.png')\n",
    "            shutil.copy(f'{input_annots_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.pkl', f'{train_annots_dir}/{train_img_id}_{valid_shift}_{shifting_threshold}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32149e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_imgs = os.listdir(f'{base_path}/dataset1_files/all_dataset1_imgs_validation_0')\n",
    "wsi_1_validation_imgs = 0\n",
    "wsi_2_validation_imgs = 0\n",
    "for img in validation_imgs:\n",
    "    if img.split('.png')[0] in wsi_1_ids:\n",
    "        wsi_1_validation_imgs += 1\n",
    "    else:\n",
    "        wsi_2_validation_imgs += 1\n",
    "print(wsi_1_validation_imgs, wsi_2_validation_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959ef85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_id):\n",
    "  img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "def get_annotated_mask(imgs_dir, annots_dir, base_img_id):\n",
    "  orig_img = load_img(imgs_dir, base_img_id)\n",
    "  img_height, img_width, _ = orig_img.shape\n",
    "  with open(f'{annots_dir}/{base_img_id}.pkl', 'rb') as f:\n",
    "    tgt_annots = pickle.load(f)\n",
    "  img_mask = np.zeros((img_height, img_width))\n",
    "  for tgt_annot in tgt_annots:\n",
    "    coords = [[x, y] for x, y in zip(tgt_annot['segmentation'][0][::2], tgt_annot['segmentation'][0][1::2])]\n",
    "    cv2.fillPoly(img_mask, pts=[np.array(coords)], color=1)\n",
    "  return img_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6befc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "if generate_masks:\n",
    "  train_modes = ['train', 'validation']\n",
    "  for i in range(1):\n",
    "    start_time = time.time()\n",
    "    for train_mode in train_modes:\n",
    "      orig_img_dir = f'{base_path}/dataset1_files/all_dataset1_imgs_merged_{train_mode}_{i}'\n",
    "      orig_annots_dir = f'{base_path}/dataset1_files/all_dataset1_annotations_merged_{train_mode}_{i}'\n",
    "      output_mask_dir = f'{base_path}/dataset1_files/all_dataset1_masks_merged_{train_mode}_{i}'\n",
    "      all_orig_imgs = os.listdir(orig_img_dir)\n",
    "      for orig_img in all_orig_imgs:\n",
    "        orig_img_id = orig_img.split('.png')[0]\n",
    "        annotated_mask = get_annotated_mask(orig_img_dir, orig_annots_dir, orig_img_id)\n",
    "        cv2.imwrite(f'{output_mask_dir}/{orig_img_id}.png', annotated_mask)\n",
    "    print(f'Finished generating masks for fold {i} in {float(time.time()-start_time)/60} minutes')\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9630da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_img_id = 'b8db704134ac_BR_0.75'\n",
    "train_mode = 'train'\n",
    "i = 0\n",
    "orig_img = get_annotated_img(f'{base_path}/dataset1_files/all_dataset1_imgs_merged_{train_mode}_{i}', f'{base_path}/dataset1_files/all_dataset1_annotations_merged_{train_mode}_{i}', tgt_img_id)\n",
    "# img_mask = cv2.imread(f'{base_path}/dataset1_files/all_dataset1_masks_merged_{train_mode}_{i}/{tgt_img_id}.png', cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(orig_img)\n",
    "plt.show()\n",
    "# plt.imshow(img_mask)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c5035",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/bd090bb1b654.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5501a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_files = os.listdir('/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0')\n",
    "no_mask_annots = []\n",
    "for annot_file in annot_files:\n",
    "    with open(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{annot_file}', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    if len(data)==0:\n",
    "        no_mask_annots.append(annot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_mask_annot in no_mask_annots:\n",
    "    img_id = no_mask_annot.split('.pkl')[0]\n",
    "    if os.path.exists(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{img_id}.pkl'):\n",
    "        os.remove(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_annotations_merged_train_0/{img_id}.pkl')\n",
    "    if os.path.exists(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_imgs_merged_train_0/{img_id}.png'):\n",
    "        os.remove(f'/home/ec2-user/hubmap-hacking-the-human-vasculature/dataset1_files/all_dataset1_imgs_merged_train_0/{img_id}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e395f04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
