{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdbc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebf7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "generate_all_datset_annots = True\n",
    "num_folds = 5\n",
    "input_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs'\n",
    "input_annots_path = f'{base_path}/dataset1_files/all_dataset1_annotations' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_annotations'\n",
    "validation_imgs = set()\n",
    "\n",
    "for i in range(num_folds):\n",
    "    output_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs_margins_{i}'\n",
    "    temp_input_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs_margins_temp_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs_margins_temp_{i}'\n",
    "    output_annots_path = f'{base_path}/dataset1_files/all_dataset1_annotations_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_annotations_margins_{i}'\n",
    "    if os.path.exists(output_imgs_path):\n",
    "      shutil.rmtree(output_imgs_path)\n",
    "    if os.path.exists(temp_input_imgs_path):\n",
    "      shutil.rmtree(temp_input_imgs_path)\n",
    "    if os.path.exists(output_annots_path):\n",
    "      shutil.rmtree(output_annots_path)\n",
    "    os.mkdir(output_imgs_path)\n",
    "    os.mkdir(temp_input_imgs_path)\n",
    "    os.mkdir(output_annots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3113355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coordinates):\n",
    "    num_points = len(coordinates)\n",
    "    if num_points < 3:\n",
    "        return 0\n",
    "\n",
    "    area = 0\n",
    "    for i in range(num_points - 1):\n",
    "        x_i, y_i = coordinates[i]\n",
    "        x_iplus1, y_iplus1 = coordinates[i + 1]\n",
    "        area += (x_i * y_iplus1) - (x_iplus1 * y_i)\n",
    "\n",
    "    x_n, y_n = coordinates[-1]\n",
    "    x_0, y_0 = coordinates[0]\n",
    "    area += (x_n * y_0) - (x_0 * y_n)\n",
    "\n",
    "    area = abs(area / 2)\n",
    "    return area\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe82a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abb9b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>blood_vessel</th>\n",
       "      <th>glomerulus</th>\n",
       "      <th>unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ff2aa7cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16896</td>\n",
       "      <td>16420</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00168d1b7522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14848</td>\n",
       "      <td>14884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0033bbc76b6b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>43008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003504460b3a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8192</td>\n",
       "      <td>11776</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004daf1cbe75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6144</td>\n",
       "      <td>11264</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j  blood_vessel  glomerulus  \\\n",
       "0  0006ff2aa7cd           2        2  16896  16420             8           1   \n",
       "1  00168d1b7522           2        2  14848  14884             1           1   \n",
       "2  0033bbc76b6b           1        1  10240  43008             3           0   \n",
       "3  003504460b3a           3        2   8192  11776             7           0   \n",
       "4  004daf1cbe75           3        2   6144  11264            10           1   \n",
       "\n",
       "   unsure  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9b58a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "tgt_wsis = [1,2,3,4]\n",
    "wsi_dicts = []\n",
    "wsi_tile_ids = []\n",
    "for cur_tgt_wsi in tgt_wsis:\n",
    "    if generate_all_datset_annots:\n",
    "        pos_dict = {(x[0], x[1]): x[-1] for x in tile_df_annotated.loc[tile_df_annotated['source_wsi']==cur_tgt_wsi, ['i', 'j', 'id']].values}\n",
    "        wsi_ids = list(tile_df_annotated.loc[tile_df_annotated['source_wsi']==cur_tgt_wsi, 'id'].values)\n",
    "    else:\n",
    "        pos_dict = {(x[0], x[1]): x[-1] for x in tile_df_annotated.loc[(tile_df_annotated['dataset']==1) & (tile_df_annotated['source_wsi']==cur_tgt_wsi), ['i', 'j', 'id']].values}\n",
    "        wsi_ids = list(tile_df_annotated.loc[(tile_df_annotated['dataset']==1) & (tile_df_annotated['source_wsi']==cur_tgt_wsi), 'id'].values)\n",
    "    random.shuffle(wsi_ids)\n",
    "    wsi_tile_ids.append(wsi_ids)\n",
    "    reverse_pos_dict = {v:k for k,v in pos_dict.items()}\n",
    "    wsi_dicts.append((pos_dict, reverse_pos_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8b7830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_tile_ids = sorted(list(tile_df_annotated.loc[tile_df_annotated['dataset']==1, 'id'].values))\n",
    "all_dataset_tile_ids = sorted(list(tile_df_annotated.loc[:, 'id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d901b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_id, is_grayscale=False):\n",
    "    if not is_grayscale:\n",
    "        img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        img = cv2.imread(f\"{img_dir}/{img_id}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "def create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_top, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    \n",
    "    left_img_i = img_i - 512\n",
    "    left_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    left_piece = np.zeros((margin_size, margin_size), dtype='uint8') if is_grayscale else np.zeros((margin_size, margin_size, 3), dtype='uint8')\n",
    "    if (left_img_i, left_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(left_img_i, left_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        left_piece = cur_img[-margin_size:, -margin_size:]\n",
    "    \n",
    "    middle_img_i = img_i\n",
    "    middle_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    middle_piece = np.zeros((margin_size, 512), dtype='uint8') if is_grayscale else np.zeros((margin_size, 512, 3), dtype='uint8')\n",
    "    if (middle_img_i, middle_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(middle_img_i, middle_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        middle_piece = cur_img[-margin_size:]\n",
    "    \n",
    "    right_img_i = img_i + 512\n",
    "    right_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    right_piece = np.zeros((margin_size, margin_size), dtype='uint8') if is_grayscale else np.zeros((margin_size, margin_size, 3), dtype='uint8')\n",
    "    if (right_img_i, right_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(right_img_i, right_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        right_piece = cur_img[-margin_size:, :margin_size]\n",
    "    \n",
    "    return cv2.hconcat([left_piece, middle_piece, right_piece])\n",
    "\n",
    "def create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_left, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    \n",
    "    middle_img_i = img_i - 512 if is_left else img_i + 512\n",
    "    middle_img_j = img_j\n",
    "    middle_piece = np.zeros((512, margin_size), dtype='uint8') if is_grayscale else np.zeros((512, margin_size, 3), dtype='uint8')\n",
    "    if (middle_img_i, middle_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(middle_img_i, middle_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        middle_piece = cur_img[:, -margin_size:]\n",
    "    return middle_piece\n",
    "\n",
    "def get_layered_img(input_imgs_dir, temp_input_imgs_dir, img, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    \n",
    "    top_margin = create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, True, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    bottom_margin = create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, False, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    left_margin = create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, True, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    right_margin = create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, False, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    print(left_margin.shape, img.shape, right_margin.shape, left_margin.dtype, img.dtype, right_margin.dtype)\n",
    "    middle_piece = cv2.hconcat([left_margin, img, right_margin])\n",
    "    return cv2.vconcat([top_margin, middle_piece, bottom_margin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "269eccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "fold_size = int(math.ceil(len(all_dataset_tile_ids) / num_folds))\n",
    "fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c945c8b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fold_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m cur_validaton_slice \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wsi_tile_id \u001b[38;5;129;01min\u001b[39;00m wsi_tile_ids:\n\u001b[0;32m----> 4\u001b[0m   cur_validaton_slice \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m wsi_tile_id[\u001b[38;5;28mint\u001b[39m(i\u001b[38;5;241m*\u001b[39m(\u001b[43mfold_size\u001b[49m\u001b[38;5;241m/\u001b[39mnum_wsis)):\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mint\u001b[39m((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m(fold_size\u001b[38;5;241m/\u001b[39mnum_wsis)), \u001b[38;5;28mlen\u001b[39m(wsi_tile_id))]\n\u001b[1;32m      5\u001b[0m cur_training_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(dataset_1_tile_ids) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(cur_validaton_slice)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m generate_all_datset_annots \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_dataset_tile_ids) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(cur_validaton_slice))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# for idx, cur_tgt_wsi in enumerate(tgt_wsis):\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     pos_dict, reverse_pos_dict = wsi_dicts[idx]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     for img_id in reverse_pos_dict.keys():\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fold_size' is not defined"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "cur_validaton_slice = []\n",
    "for wsi_tile_id in wsi_tile_ids:\n",
    "  cur_validaton_slice += wsi_tile_id[int(i*(fold_size/num_wsis)):min(int((i+1)*(fold_size/num_wsis)), len(wsi_tile_id))]\n",
    "cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validaton_slice)) if not generate_all_datset_annots else list(set(all_dataset_tile_ids) - set(cur_validaton_slice))\n",
    "# for idx, cur_tgt_wsi in enumerate(tgt_wsis):\n",
    "#     pos_dict, reverse_pos_dict = wsi_dicts[idx]\n",
    "#     for img_id in reverse_pos_dict.keys():\n",
    "print(cur_validaton_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf29ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
