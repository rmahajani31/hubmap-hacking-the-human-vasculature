{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bdbc5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebf7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '..'\n",
    "generate_all_datset_annots = True\n",
    "pick_validation_from_file = True\n",
    "num_folds = 5\n",
    "base_data_dir = 'dataset1_files' if not generate_all_datset_annots else 'all_dataset_files'\n",
    "input_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs'\n",
    "input_masks_path = f'{base_path}/dataset1_files/all_dataset1_masks' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_masks'\n",
    "input_annots_path = f'{base_path}/dataset1_files/all_dataset1_annotations' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_annotations'\n",
    "modes = ['train', 'validation']\n",
    "validation_imgs = set()\n",
    "validation_masks = set()\n",
    "\n",
    "\n",
    "for i in range(num_folds):\n",
    "    temp_input_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs_margins_temp_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs_margins_temp_{i}'\n",
    "    temp_input_masks_path = f'{base_path}/dataset1_files/all_dataset1_masks_margins_temp_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_masks_margins_temp_{i}'\n",
    "    if os.path.exists(temp_input_imgs_path):\n",
    "      shutil.rmtree(temp_input_imgs_path)\n",
    "    if os.path.exists(temp_input_masks_path):\n",
    "      shutil.rmtree(temp_input_masks_path)\n",
    "    os.mkdir(temp_input_imgs_path)\n",
    "    os.mkdir(temp_input_masks_path)\n",
    "    for mode in modes:\n",
    "      output_imgs_path = f'{base_path}/dataset1_files/all_dataset1_{mode}_imgs_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_{mode}_imgs_margins_{i}'\n",
    "      output_annots_path = f'{base_path}/dataset1_files/all_dataset1_{mode}_annotations_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_{mode}_annotations_margins_{i}'\n",
    "      if os.path.exists(output_imgs_path):\n",
    "        shutil.rmtree(output_imgs_path)\n",
    "      if os.path.exists(output_annots_path):\n",
    "        shutil.rmtree(output_annots_path)\n",
    "      os.mkdir(output_imgs_path)\n",
    "      os.mkdir(output_annots_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3113355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_type(tiles_dict):\n",
    "  ids_with_info = []\n",
    "  for tile in tiles_dict:\n",
    "    cur_dict = {'id': tile['id'], 'blood_vessel': 0, 'glomerulus': 0, 'unsure': 0}\n",
    "    for annot in tile['annotations']:\n",
    "      cur_dict[annot['type']] += 1\n",
    "    ids_with_info.append(cur_dict)\n",
    "  return ids_with_info\n",
    "def calculate_area(coordinates):\n",
    "    num_points = len(coordinates)\n",
    "    if num_points < 3:\n",
    "        return 0\n",
    "\n",
    "    area = 0\n",
    "    for i in range(num_points - 1):\n",
    "        x_i, y_i = coordinates[i]\n",
    "        x_iplus1, y_iplus1 = coordinates[i + 1]\n",
    "        area += (x_i * y_iplus1) - (x_iplus1 * y_i)\n",
    "\n",
    "    x_n, y_n = coordinates[-1]\n",
    "    x_0, y_0 = coordinates[0]\n",
    "    area += (x_n * y_0) - (x_0 * y_n)\n",
    "\n",
    "    area = abs(area / 2)\n",
    "    return area\n",
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(30, 30))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe82a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{base_path}/polygons.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "tiles_dicts = []\n",
    "for json_str in json_list:\n",
    "    tiles_dicts.append(json.loads(json_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb9b8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_wsi</th>\n",
       "      <th>dataset</th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>blood_vessel</th>\n",
       "      <th>glomerulus</th>\n",
       "      <th>unsure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0006ff2aa7cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16896</td>\n",
       "      <td>16420</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00168d1b7522</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14848</td>\n",
       "      <td>14884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0033bbc76b6b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10240</td>\n",
       "      <td>43008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003504460b3a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8192</td>\n",
       "      <td>11776</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004daf1cbe75</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6144</td>\n",
       "      <td>11264</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  source_wsi  dataset      i      j  blood_vessel  glomerulus  \\\n",
       "0  0006ff2aa7cd           2        2  16896  16420             8           1   \n",
       "1  00168d1b7522           2        2  14848  14884             1           1   \n",
       "2  0033bbc76b6b           1        1  10240  43008             3           0   \n",
       "3  003504460b3a           3        2   8192  11776             7           0   \n",
       "4  004daf1cbe75           3        2   6144  11264            10           1   \n",
       "\n",
       "   unsure  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df = pd.read_csv(f'{base_path}/tile_meta.csv')\n",
    "# Find the same stats as the above cell for annotated images\n",
    "annotated_ids_with_info = get_count_type(tiles_dicts)\n",
    "annotated_ids_with_info_df = pd.DataFrame.from_dict(annotated_ids_with_info)\n",
    "tile_df_annotated = pd.merge(tile_df, annotated_ids_with_info_df, on='id', how='inner')\n",
    "tile_df_annotated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9b58a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "tgt_wsis = [1,2,3,4]\n",
    "wsi_dicts = dict()\n",
    "wsi_tile_ids = []\n",
    "tile_id_to_wsi_dict = dict()\n",
    "for cur_tgt_wsi in tgt_wsis:\n",
    "    if generate_all_datset_annots:\n",
    "        pos_dict = {(x[0], x[1]): x[-1] for x in tile_df_annotated.loc[tile_df_annotated['source_wsi']==cur_tgt_wsi, ['i', 'j', 'id']].values}\n",
    "        wsi_ids = list(tile_df_annotated.loc[tile_df_annotated['source_wsi']==cur_tgt_wsi, 'id'].values)\n",
    "    else:\n",
    "        pos_dict = {(x[0], x[1]): x[-1] for x in tile_df_annotated.loc[(tile_df_annotated['dataset']==1) & (tile_df_annotated['source_wsi']==cur_tgt_wsi), ['i', 'j', 'id']].values}\n",
    "        wsi_ids = list(tile_df_annotated.loc[(tile_df_annotated['dataset']==1) & (tile_df_annotated['source_wsi']==cur_tgt_wsi), 'id'].values)\n",
    "    random.shuffle(wsi_ids)\n",
    "    wsi_tile_ids.append(wsi_ids)\n",
    "    reverse_pos_dict = {v:k for k,v in pos_dict.items()}\n",
    "    wsi_dicts[cur_tgt_wsi] = (pos_dict, reverse_pos_dict)\n",
    "    tile_id_to_wsi_dict.update({wsi_id: cur_tgt_wsi for wsi_id in wsi_ids})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2840fdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1_tile_ids = sorted(list(tile_df_annotated.loc[tile_df_annotated['dataset']==1, 'id'].values))\n",
    "all_dataset_tile_ids = sorted(list(tile_df_annotated.loc[:, 'id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7fa52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segmentation_coordinates(mask):\n",
    "    mask = np.uint8(mask)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    segmentation_coords = []\n",
    "    for contour in contours:\n",
    "        contour = np.squeeze(contour)\n",
    "        coords = contour.flatten().tolist()\n",
    "        segmentation_coords.append(coords)\n",
    "    return segmentation_coords\n",
    "\n",
    "def create_coco_annots(all_coords, pair_format=True):\n",
    "  cur_tile_coco_annots = []\n",
    "  for coords in all_coords:\n",
    "    if not pair_format:\n",
    "      coords = [[pt[0], pt[1]] for pt in zip(coords[::2], coords[1::2])]\n",
    "    segmentations = [[pt for pair in coords for pt in pair]]\n",
    "    segmentation_area = calculate_area(coords)\n",
    "    min_x = min(coords, key=lambda x: x[0])[0]\n",
    "    max_x = max(coords, key=lambda x: x[0])[0]\n",
    "    min_y = min(coords, key=lambda x: x[1])[1]\n",
    "    max_y = max(coords, key=lambda x: x[1])[1]\n",
    "    segmentation_bbox = [min_x, min_y, max_x-min_x, max_y-min_y]\n",
    "    category_id = 0\n",
    "    cur_tile_coco_annots.append({\n",
    "      'segmentation': segmentations,\n",
    "      'area': segmentation_area,\n",
    "      'bbox': segmentation_bbox,\n",
    "      'category_id': category_id\n",
    "    })\n",
    "  return cur_tile_coco_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d901b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(img_dir, img_id, is_grayscale=False):\n",
    "    if not is_grayscale:\n",
    "        img = cv2.imread(f\"{img_dir}/{img_id}.png\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        img = cv2.imread(f\"{img_dir}/{img_id}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    return img\n",
    "\n",
    "def create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_top, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    cur_validation_imgs = validation_imgs if not is_mask else validation_masks\n",
    "    \n",
    "    left_img_i = img_i - 512\n",
    "    left_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    left_piece = np.zeros((margin_size, margin_size), dtype='uint8') if is_grayscale else np.zeros((margin_size, margin_size, 3), dtype='uint8')\n",
    "    if (left_img_i, left_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(left_img_i, left_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in cur_validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        left_piece = cur_img[-margin_size:, -margin_size:] if is_top else cur_img[:margin_size, -margin_size:]\n",
    "        if not is_train:\n",
    "          validation_load_dir = temp_input_imgs_dir if cur_img_id in cur_validation_imgs else input_imgs_dir\n",
    "          validation_img = load_img(validation_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "#           print('======')\n",
    "#           print(validation_load_dir)\n",
    "#           print(cur_img_id)\n",
    "#           print('======')\n",
    "          if is_top:\n",
    "            validation_img[-margin_size:, -margin_size:] = 0\n",
    "          else:\n",
    "            validation_img[:margin_size, -margin_size:] = 0\n",
    "          cv2.imwrite(f'{temp_input_imgs_dir}/{cur_img_id}.png', validation_img)\n",
    "          cur_validation_imgs.add(cur_img_id)\n",
    "    \n",
    "    middle_img_i = img_i\n",
    "    middle_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    middle_piece = np.zeros((margin_size, 512), dtype='uint8') if is_grayscale else np.zeros((margin_size, 512, 3), dtype='uint8')\n",
    "    if (middle_img_i, middle_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(middle_img_i, middle_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in cur_validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        middle_piece = cur_img[-margin_size:] if is_top else cur_img[:margin_size]\n",
    "        if not is_train:\n",
    "          validation_load_dir = temp_input_imgs_dir if cur_img_id in cur_validation_imgs else input_imgs_dir\n",
    "          validation_img = load_img(validation_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "#           print('======')\n",
    "#           print(validation_load_dir)\n",
    "#           print(cur_img_id)\n",
    "#           print('======')\n",
    "          if is_top:\n",
    "            validation_img[-margin_size:] = 0\n",
    "          else:\n",
    "            validation_img[:margin_size] = 0\n",
    "          cv2.imwrite(f'{temp_input_imgs_dir}/{cur_img_id}.png', validation_img)\n",
    "          cur_validation_imgs.add(cur_img_id)\n",
    "    \n",
    "    right_img_i = img_i + 512\n",
    "    right_img_j = img_j - 512 if is_top else img_j + 512\n",
    "    right_piece = np.zeros((margin_size, margin_size), dtype='uint8') if is_grayscale else np.zeros((margin_size, margin_size, 3), dtype='uint8')\n",
    "    if (right_img_i, right_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(right_img_i, right_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in cur_validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        right_piece = cur_img[-margin_size:, :margin_size] if is_top else cur_img[:margin_size, :margin_size]\n",
    "        if not is_train:\n",
    "          validation_load_dir = temp_input_imgs_dir if cur_img_id in cur_validation_imgs else input_imgs_dir\n",
    "          validation_img = load_img(validation_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "#           print('======')\n",
    "#           print(validation_load_dir)\n",
    "#           print(cur_img_id)\n",
    "#           print('======')\n",
    "          if is_top:\n",
    "            validation_img[-margin_size:, :margin_size] = 0\n",
    "          else:\n",
    "            validation_img[:margin_size, :margin_size] = 0\n",
    "          cv2.imwrite(f'{temp_input_imgs_dir}/{cur_img_id}.png', validation_img)\n",
    "          cur_validation_imgs.add(cur_img_id)\n",
    "    \n",
    "    return cv2.hconcat([left_piece, middle_piece, right_piece])\n",
    "\n",
    "def create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_left, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    cur_validation_imgs = validation_imgs if not is_mask else validation_masks\n",
    "    \n",
    "    middle_img_i = img_i - 512 if is_left else img_i + 512\n",
    "    middle_img_j = img_j\n",
    "    middle_piece = np.zeros((512, margin_size), dtype='uint8') if is_grayscale else np.zeros((512, margin_size, 3), dtype='uint8')\n",
    "    if (middle_img_i, middle_img_j) in dataset_pos_dict:\n",
    "        cur_img_id = dataset_pos_dict[(middle_img_i, middle_img_j)]\n",
    "        img_load_dir = temp_input_imgs_dir if (is_train and cur_img_id in cur_validation_imgs) else input_imgs_dir\n",
    "        cur_img = load_img(img_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "        middle_piece = cur_img[:, -margin_size:] if is_left else cur_img[:, :margin_size]\n",
    "        if not is_train:\n",
    "          validation_load_dir = temp_input_imgs_dir if cur_img_id in cur_validation_imgs else input_imgs_dir\n",
    "          validation_img = load_img(validation_load_dir, cur_img_id, is_grayscale=is_grayscale)\n",
    "          if is_left:\n",
    "            validation_img[:, -margin_size:] = 0\n",
    "          else:\n",
    "            validation_img[:, :margin_size] = 0\n",
    "          cv2.imwrite(f'{temp_input_imgs_dir}/{cur_img_id}.png', validation_img)\n",
    "          cur_validation_imgs.add(cur_img_id)\n",
    "    return middle_piece\n",
    "\n",
    "def get_layered_img(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=32, is_mask=False):\n",
    "    is_grayscale = True if is_mask else False\n",
    "    cur_validation_imgs = validation_imgs if not is_mask else validation_masks\n",
    "    \n",
    "    img_load_dir = temp_input_imgs_dir if (is_train and img_id in cur_validation_imgs) else input_imgs_dir\n",
    "    img = load_img(img_load_dir, img_id, is_grayscale=is_grayscale)\n",
    "    \n",
    "    top_margin = create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, True, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    bottom_margin = create_hor_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, False, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    left_margin = create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, True, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "    right_margin = create_vert_margins(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, False, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "#     print(left_margin.shape, img.shape, right_margin.shape, left_margin.dtype, img.dtype, right_margin.dtype)\n",
    "    middle_piece = cv2.hconcat([left_margin, img, right_margin])\n",
    "    \n",
    "    if not is_train:\n",
    "      validation_img = load_img(input_imgs_dir, img_id, is_grayscale=is_grayscale)\n",
    "      validation_img = np.zeros_like(validation_img, dtype='uint8')\n",
    "      cv2.imwrite(f'{temp_input_imgs_dir}/{img_id}.png', validation_img)\n",
    "      cur_validation_imgs.add(img_id)\n",
    "    \n",
    "    return cv2.vconcat([top_margin, middle_piece, bottom_margin])\n",
    "\n",
    "def save_margin_imgs(input_imgs_dir, temp_input_imgs_dir, output_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=32, is_mask=False):\n",
    "  img = get_layered_img(input_imgs_dir, temp_input_imgs_dir, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "  cv2.imwrite(f'{output_imgs_dir}/{img_id}.png', img)\n",
    "\n",
    "def save_margin_annots(input_masks_dir, temp_input_masks_dir, output_annots_dir, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=32, is_mask=True):\n",
    "  mask = get_layered_img(input_masks_dir, temp_input_masks_dir, img_id, img_i, img_j, dataset_pos_dict, is_train, margin_size=margin_size, is_mask=is_mask)\n",
    "  mask_coords = get_segmentation_coordinates(mask)\n",
    "  mask_annots = create_coco_annots(mask_coords, pair_format=False)\n",
    "  with open(f'{output_annots_dir}/{img_id}.pkl', 'wb') as f:\n",
    "    pickle.dump(mask_annots, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7b9ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "fold_size = int(math.ceil(len(all_dataset_tile_ids) / num_folds))\n",
    "fold_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945c8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold size is 327\n",
      "324 1309\n",
      "['cfb0bd617652', '678c51bde237', '2519a0f1b867', '523a3912a7ee', '9a70c2d9e4f4', 'ca081412bad8', 'd9547a630fab', '5384b927f5b3', '2d2093e38e39', '3e248be7dd4c', '39b8aafd630b', '578c8b32057e', '4c058755d597', '23c30a541c7a', '9f999c74b67e', '0e8aed930dc6', '03d335057db3', '328a651a4ca7', '55b07829e888', '4cf2563142f4', '6d1315ab9ef7', '7483bb77d145', 'e506a133c873', '18be061202ea', 'f1af97caff9d', 'db8adbc51c82', '13aa34ced90d', '8f6f3e18eda5', '033a656390b2', '5ed62676da45', '76e5b8a1caa1', '415a900f7a89', '9ed941a933d0', 'ac68833641fe', '1c0295c1d01d', '4a1b99c7ab16', 'f6b0c55c34c7', '15ed954c0cdf', '0a993633aa5e', 'd6529e6e8602', '242db333c452', '8e90e6189c6b', '783e8f735476', '4b197545ea0e', '45d6f53ececf', '5a89c7f7ad05', '9b95807e6b23', '30ad648e36a2', 'cb96f7b681f8', '4e8b6849684d', '303b72a38e29', '41225437e33e', 'ac8f685801d0', 'abbacf024cb5', '95c077870f91', 'dcea4e9d6726', '7392e21e0fe2', 'e1647f94f1f9', '1a54cda8f32d', '1f0d3cd4b621', 'f40804ea84e6', '664fdc3e5dca', '88d349bebe86', 'da2863316247', 'e5ac1caaadd8', '56b724dc963a', 'aad30f930d6d', '8ebea8a23178', '01a7fca6263b', '43b4654b4c3d', 'dfcea0f4ef63', '8047c43b1cb2', '733296a59c9b', '951d7a241936', 'b454fe1b98f8', '62bc683d8c8a', '6443bced36cd', 'bf610d0dd510', '31195284c86e', '8a100f8a780f', '611aee20c207', '0a43459733e7', '611fb542b810', '4db8491f1494', 'b275b8536362', 'd8ce65cbe4b5', '4aa434181421', 'c71a1602289a', '8b3a92f16728', '76a3142ef6ee', 'd030717228ae', '2be23bada1e8', 'dfe0f68f1f43', '11b7125c2fc2', 'd463ac727d6b', '368660921c18', '0717863ca2cb', 'fb5faa60f9d0', '7514d946ca86', '6ba77a9f7fea', '2296c77d5059', '1c10c781495b', 'b0ec2900ed72', '3ad70040eeeb', '92394add7fb2', '2f9a34bfa69f', '6a2cec1c97bc', '312bb1ba445f', '56e1ccd094f2', '6a5db683c6e5', '5dcc3cda10ef', 'a9fa67774c7a', 'b3e1b3925d24', '69dc0b37915e', '8f4c08f55c0f', 'f73b7aca41d4', '1ed324bad445', '65549f6e79ba', '4bdc0ba604d8', '41c6e0692ca1', '413fa0675bdf', 'd811739e1ef2', '3395ffa824a2', '60fc71767907', '06b972c417e7', '2befa0c506b5', 'd2f339b5ffb4', 'd6b73b44e334', '68e0e9974b36', '97dce4548ae2', '66e60e98c001', '8d60ccc783c1', '9abb800898c5', '895973fae879', '61409556c001', '0ab9d193fcf6', '12d8b41d1c0e', 'a418cbf4e695', '1bb52a550a23', '60e20dd6aca9', '8034004a9385', '5ab182e75656', '85c2d78dbbc0', '7e090fce7bd8', 'a43242dec225', '91ba77e94fd3', 'b898dccf7911', '5232ba7fa001', '1423b40ad0dc', 'af9c61e40ff5', '0a152cf103e4', '65500e3e3c73', 'f69c378f6f4f', '5aae1d92e0af', '89696d0f1623', '24bc5d5889b4', '9ba29448632b', '669d50eb831a', 'd35b6634f6e9', '7e97ecdac5d2', '15d12fd18a57', '2a127f0ae506', 'b66b9bbbf167', '89c406905e08', '2aaf9e8db9d8', '8b135754e695', '96edf6531f2d', 'cde801aaf517', 'bac629dabbe6', 'aa9ee3d2ac2d', '1a4ab6091fe5', '6071f2eb2163', 'eb9b9ee6043a', '22a8a59ba8a8', 'f6cec0d06534', '38738b2f9b55', '2ff87855e80d', 'e9c9c5fb7aef', '3dbff16df8b4', 'bcd16bd04b1c', 'ed23179ac692', '2673eb939bf8', '748b86c5cebc', '72cdbbaeef56', '09d736c55365', '31c233373597', '40a486ebdb5a', '764b5512ab63', '93bab06a701e', '79b61f3f4b43', 'b728bb99e6c8', '64c675e5750d', '4142122db8e4', 'e024bc3c9ad8', '1ca1adf074bb', '993a5ac25b94', '7505b0ab7415', 'c2e7dae2437c', '231651227a64', 'a27ffddbba42', 'c701b51b6ece', 'a50f200ad02f', '44b7efeac370', '3c43eee40b44', 'cd9a596eebf1', '8ecc51bb2c9c', 'a681dde5b7de', '338721d693ac', '8f988ab60343', 'cc8d5b6d4975', '0d1cc52aff5f', 'adaa3ee513d9', 'd71686c972e0', '71747eee6354', 'da3180fa5201', 'd1286858fd92', '56bbe99602d3', '634a9a8854a7', 'e2149f3ab975', '1aeae455caeb', '6b538126a8ed', '45938c92d178', '9dfb5b38e36e', 'ab454ea36b63', '041ad8166762', '5c04198743a5', '0f960d864969', 'c9b86706da8d', 'd82695d80caf', '3de83b01dfad', 'f4fc628c4249', 'f08e624dbf3f', 'e868c30b2af7', '00f560a6a72b', '977159da60e3', 'cc59866d42be', '02cf5c2db152', '08ed99cd1c93', '6a576a079947', 'fc7f3e900a45', '12989675c0b5', '19c5c6803ac1', '7f446ed19c5e', '8d6b0ed78fb9', '9e1b8de22598', 'b133a9ebd9c3', '6909603ea7ab', '3962d1284da9', '019390572feb', '2cad7b97ea7e', 'b2106c522f46', '52ef4341cfd5', '12040bd8cd09', 'e477bfef1e06', 'dd359ed041b4', '719eabbda1cf', '3b0d08f3e37a', '22db9740ba20', '590f64bf82a6', 'c1595cb65d3b', '3a6612dd0d76', '29a3a48d6fee', '90e10df06c46', 'e52415e02d69', 'bc7b984d5230', '5715f8aaf551', '74a7eaee8279', '3ef978f2c262', '1803b93469e4', '5c67b0b835d2', '5d3e158def53', '2bb6adc62561', 'bc395209b187', 'b063f7a3829b', 'daf9beac4413', '96b92a29ecbe', '2000408010ab', '319c978054dd', '60c150d85e6f', '3ca506a3f4bb', 'fbe4539bc60f', '8471cf1e3e72', '98a235b69354', 'd0ba005fd935', 'bee3838707f4', '84d6716c6ea9', '106e8a3e8dcd', 'c07f9e30d860', '1508ea9334c0', '7c0205439a44', '46a58335b3c8', 'c32a82f01c6a', 'd2dec3865693', 'defd2cb5fd9b', '014b60dfe193', '21e0f12ec94b', '440b33550916', 'da5cca9855f5', 'bfb0250dabd4', 'e4321d033f15', 'e6dc33ae1abe', 'c7e22a624fc5', '08e2fa7b08f0', '9d417eed72a8', 'ba796d42add5', 'cbce5b55f5bb', '7a5c7224d687', '243169fcefaf', '530867f65ca0', 'ff99cdef0f2a', 'e17868b94f7e', 'b68a2e3b48bd', '1cf437f790aa', 'f17c0bbf7b72', '3e38a14cb10f', 'fd1a6972f9cd', 'f64eb576e78d', '989936714cf5', 'ba8d36715d6d', '1daf55f162a1', '0be9b14718b9', 'b3ee5e7bcf74', '7ec06208a352', 'f66cf535672b']\n"
     ]
    }
   ],
   "source": [
    "fold_size = int(math.ceil(len(dataset_1_tile_ids) / num_folds)) if not generate_all_datset_annots else int(math.ceil(len(all_dataset_tile_ids) / num_folds))\n",
    "print(f'Fold size is {fold_size}')\n",
    "for i in range(1):\n",
    "  temp_input_imgs_path = f'{base_path}/dataset1_files/all_dataset1_imgs_margins_temp_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_imgs_margins_temp_{i}'\n",
    "  temp_input_masks_path = f'{base_path}/dataset1_files/all_dataset1_masks_margins_temp_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_masks_margins_temp_{i}'\n",
    "  \n",
    "  output_imgs_train_path = f'{base_path}/dataset1_files/all_dataset1_train_imgs_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_train_imgs_margins_{i}'\n",
    "  output_annots_train_path = f'{base_path}/dataset1_files/all_dataset1_train_annotations_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_train_annotations_margins_{i}'\n",
    "  output_imgs_validation_path = f'{base_path}/dataset1_files/all_dataset1_validation_imgs_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_validation_imgs_margins_{i}'\n",
    "  output_annots_validation_path = f'{base_path}/dataset1_files/all_dataset1_validation_annotations_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_validation_annotations_margins_{i}'\n",
    "  \n",
    "  if pick_validation_from_file:\n",
    "    with open(f'{base_path}/{base_data_dir}/validation_img_ids_fold_{i}.pkl', 'rb') as f:\n",
    "        cur_validation_slice = pickle.load(f)\n",
    "    with open(f'{base_path}/{base_data_dir}/train_img_ids_fold_{i}.pkl', 'rb') as f:\n",
    "        cur_training_slice = pickle.load(f)\n",
    "    print(len(cur_validation_slice), len(cur_training_slice))\n",
    "    print(cur_validation_slice)\n",
    "  else:\n",
    "    cur_validation_slice = []\n",
    "    num_wsis = float(len(wsi_tile_ids))\n",
    "    for wsi_tile_id in wsi_tile_ids:\n",
    "      cur_validation_slice += wsi_tile_id[int(i*(fold_size/num_wsis)):min(int((i+1)*(fold_size/num_wsis)), len(wsi_tile_id))]\n",
    "    cur_training_slice = list(set(dataset_1_tile_ids) - set(cur_validation_slice)) if not generate_all_datset_annots else list(set(all_dataset_tile_ids) - set(cur_validation_slice))\n",
    "  \n",
    "  for idx, img_id in enumerate(cur_validation_slice):\n",
    "#     print(f'Processing id {img_id}')\n",
    "    source_wsi = tile_id_to_wsi_dict[img_id]\n",
    "    dataset_pos_dict, dataset_reverse_pos_dict = wsi_dicts[source_wsi]\n",
    "    img_i, img_j = dataset_reverse_pos_dict[img_id]\n",
    "    save_margin_imgs(input_imgs_path, temp_input_imgs_path, output_imgs_validation_path, img_id, img_i, img_j, dataset_pos_dict, False, margin_size=64, is_mask=False)\n",
    "  #   print('Finished saving images')\n",
    "    save_margin_annots(input_masks_path, temp_input_masks_path, output_annots_validation_path, img_id, img_i, img_j, dataset_pos_dict, False, margin_size=64, is_mask=True)\n",
    "  #   print('Finished saving annots')\n",
    "  #   print('================')\n",
    "  for idx, img_id in enumerate(cur_training_slice):\n",
    "    source_wsi = tile_id_to_wsi_dict[img_id]\n",
    "    dataset_pos_dict, dataset_reverse_pos_dict = wsi_dicts[source_wsi]\n",
    "    img_i, img_j = dataset_reverse_pos_dict[img_id]\n",
    "    save_margin_imgs(input_imgs_path, temp_input_imgs_path, output_imgs_train_path, img_id, img_i, img_j, dataset_pos_dict, True, margin_size=64, is_mask=False)\n",
    "    save_margin_annots(input_masks_path, temp_input_masks_path, output_annots_train_path, img_id, img_i, img_j, dataset_pos_dict, True, margin_size=64, is_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf29ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 'fcbe5ce12d5f'\n",
    "mode='train'\n",
    "i=0\n",
    "\n",
    "source_wsi = tile_id_to_wsi_dict[img_id]\n",
    "dataset_pos_dict, dataset_reverse_pos_dict = wsi_dicts[source_wsi]\n",
    "img_i, img_j = dataset_reverse_pos_dict[img_id]\n",
    "adjacency_pos_dict = {'TL': (-1,-1), 'U': (0,-1), 'TR': (1,-1), 'L': (-1,0), 'C': (0,0), 'R': (1,0), 'BL': (-1,1), 'B': (0,1), 'BR': (1,1)}\n",
    "keys = ['TL', 'U', 'TR', 'L', 'C', 'R', 'BL', 'B', 'BR']\n",
    "adjacency_dict = dict()\n",
    "vis_dict = dict()\n",
    "imgs = []\n",
    "img_rows = []\n",
    "for idx, k in enumerate(keys):\n",
    "  i_scale, j_scale = adjacency_pos_dict[k]\n",
    "  cur_i = img_i + i_scale * 512\n",
    "  cur_j = img_j + j_scale * 512\n",
    "  cur_img_id = 'NA'\n",
    "  cur_img = np.zeros((512,512), dtype='uint8')\n",
    "  if (cur_i, cur_j) in dataset_pos_dict:\n",
    "    cur_img_id = dataset_pos_dict[(cur_i, cur_j)]\n",
    "    cur_img = load_img(input_imgs_path, cur_img_id)\n",
    "  vis_dict[k] = cur_img\n",
    "  imgs.append(cur_img)\n",
    "  adjacency_dict[k] = cur_img_id\n",
    "  if len(imgs) % 3 == 0:\n",
    "    img_rows.append(cv2.hconcat(imgs))\n",
    "    imgs = []\n",
    "print(adjacency_dict)\n",
    "output_imgs_path = f'{base_path}/dataset1_files/all_dataset1_{mode}_imgs_margins_{i}' if not generate_all_datset_annots else f'{base_path}/all_dataset_files/all_dataset_{mode}_imgs_margins_{i}'\n",
    "margin_img = load_img(output_imgs_path, img_id)\n",
    "# plt.imshow(cv2.vconcat(img_rows))\n",
    "# plt.show()\n",
    "# plt.imshow(cv2.vconcat(img_rows))\n",
    "# plt.show()\n",
    "visualize(**{'margin_img': margin_img, 'full_img':cv2.vconcat(img_rows)})\n",
    "visualize(**vis_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d89a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_env",
   "language": "python",
   "name": "detectron_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
